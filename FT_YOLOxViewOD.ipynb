{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"git clone https://github.com/ultralytics/yolov5  # clone\ncd yolov5\npip install -r requirements.txt  # install","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimport yaml\nfrom sklearn.model_selection import GroupKFold\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"# path per la generazione del file .yalm da utilizzare per il finetuning \ncwd = '/kaggle/working/'\n\ntrain_file = os.path.join(cwd, 'train.txt')\nval_file = os.path.join(cwd, 'val.txt')\nyaml_file = os.path.join(cwd, 'data_dictionary_yaml.yaml')\n\n\n# path per la gestione del modello e dell'addestramento\nmodel_path = \"yolov5s.pt\"\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"markdown","source":"## Scrittura di un dataset yaml che definisce i percorsi treno/val e i nomi delle classi","metadata":{}},{"cell_type":"code","source":"# Creazione del file 'train.txt'\nwith open(train_file, 'w') as f:\n    for path in train_df.image_path.tolist():\n        f.write(path + '\\n')\n\n# Creazione del file 'val.txt'\nwith open(val_file, 'w') as f:\n    for path in valid_df.image_path.tolist():\n        f.write(path + '\\n')\n\n# Dati YAML\ndata = dict(\n    path='/kaggle/working',\n    train=train_file,\n    val=val_file,\n    nc=1,\n    names=['cots'],\n)\n\n# Scrittura del file 'gbr.yaml'\nwith open(yaml_file, 'w') as outfile:\n    yaml.dump(data, outfile, default_flow_style=False)\n\n# Lettura e stampa del contenuto del file 'gbr.yaml'\nwith open(yaml_file, 'r') as f:\n    print('\\nyaml:')\n    print(f.read())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class YoloModel(nn.Module):\n    \"\"\"\n    Classe YOLOv5 per definire il modello e la funzione di forward.\n    \"\"\"\n    def __init__(self, model_path=\"yolov5s.pt\"):\n        \"\"\"\n        Inizializza il modello YOLOv5.\n\n        Args:\n            model_path (str): Percorso ai pesi pre-addestrati YOLOv5.\n        \"\"\"\n        super(YoloModel, self).__init__()\n        self.model_path = model_path\n        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n\n    def forward(self, images):\n        \"\"\"\n        Esegue la predizione sul batch di immagini.\n\n        Args:\n            images (torch.Tensor): Batch di immagini di input.\n\n        Returns:\n            torch.Tensor: Risultati delle predizioni.\n        \"\"\"\n        return self.model(images)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## per addestrare il modello\n### python train.py --img 640 --epochs 3 --data dataset.yaml --weights yolov5s.pt","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    \"\"\"\n    Classe per addestrare un modello YOLOv5.\n    \"\"\"\n    def __init__(self, model, dataset_yaml, img_size=640, batch_size=16, epochs=50, cache=\"ram\"):\n        \"\"\"\n        Inizializza il Trainer per YOLOv5.\n\n        Args:\n            model (YoloModel): Istanza del modello YOLOv5.\n            dataset_yaml (str): Percorso al file di configurazione del dataset.\n            img_size (int): Dimensione delle immagini di input.\n            batch_size (int): Dimensione del batch per l'addestramento.\n            epochs (int): Numero di epoche.\n            cache (str): Tipo di caching ('ram' o 'disk').\n        \"\"\"\n        self.model = model\n        self.dataset_yaml = dataset_yaml\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.cache = cache\n\n    def train(self): \n        \"\"\"\n        Avvia l'addestramento del modello utilizzando YOLOv5.\n        \"\"\"\n        command = (\n            f\"python train.py --img {self.img_size} --batch-size {self.batch_size} \"\n            f\"--epochs {self.epochs} --optimizer {OPTMIZER} \"\n            f\"--data {self.dataset_yaml} \"\n            f\"--weights {self.model.model_path} --cache {self.cache}\"\n        )\n        os.system(command)\n        print(\"Addestramento completato.\")\n\n    def validate(self, weights_path=None):\n        \"\"\"\n        Valida il modello sui dati di test.\n\n        Args:\n            weights_path (str, optional): Percorso ai pesi addestrati. Se None, usa i pesi attuali del modello.\n        \"\"\"\n        weights = weights_path if weights_path else self.model.model_path\n        command = f\"python val.py --data {self.dataset_yaml} --weights {weights} --img {self.img_size}\"\n        os.system(command)\n        print(\"Validazione completata.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}