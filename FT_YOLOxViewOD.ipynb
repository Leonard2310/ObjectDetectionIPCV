{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"code","source":"git clone https://github.com/ultralytics/yolov5  # clone\ncd yolov5\npip install -r requirements.txt  # install","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\nimport yaml\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\nimport torch.nn as nn\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"# path per la generazione del file .yalm da utilizzare per il finetuning \nroot_path =\ntrain_dir = \nval_dir =\ntest_dir = \n\n# path per la gestione del modello e dell'addestramento\nmodel_path=\"yolov5s.pt\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"# il dataset etichettato deve essere elaborato con Roboflow per organizzare i dati ed esportarli in formatoYOLOv5","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Scrivere un dataset.yaml che definisce i percorsi treno/val e i nomi delle classi","metadata":{}},{"cell_type":"code","source":"class DatasetConfigCreator: #rivedere -> è provvisorio\n    \"\"\"\n    Classe per creare un file di configurazione YAML per un dataset YOLO.\n    \"\"\"\n    def __init__(self, root_path, train_dir, val_dir, test_dir=None, class_names=None):\n        \"\"\"\n        Inizializza il DatasetConfigCreator.\n\n        Args:\n            root_path (str): Percorso radice del dataset.\n            train_dir (str): Directory delle immagini di training relative al percorso radice.\n            val_dir (str): Directory delle immagini di validazione relative al percorso radice.\n            test_dir (str, optional): Directory delle immagini di test relative al percorso radice. Default è None.\n            class_names (list, optional): Lista di nomi delle classi. Default è None.\n        \"\"\"\n        self.root_path = root_path\n        self.train_dir = train_dir\n        self.val_dir = val_dir\n        self.test_dir = test_dir\n        self.class_names = class_names if class_names else []\n\n    def create_config(self, output_path=\"dataset.yaml\"):\n        \"\"\"\n        Crea il file YAML di configurazione.\n\n        Args:\n            output_path (str): Percorso del file YAML da generare. Default è \"dataset.yaml\".\n        \"\"\"\n        config = {\n            \"path\": self.root_path,\n            \"train\": self.train_dir,\n            \"val\": self.val_dir,\n        }\n\n        # Aggiungi la sezione test solo se specificata\n        if self.test_dir:\n            config[\"test\"] = self.test_dir\n\n        # Aggiungi le classi\n        config[\"names\"] = {i: name for i, name in enumerate(self.class_names)}\n\n        # Verifica se il file esiste\n        if os.path.exists(output_path):\n            print(f\"Il file '{output_path}' esiste già. Nessuna modifica è stata apportata.\")\n        else:\n            # Scrive il file YAML\n            with open(output_path, \"w\") as file:\n                yaml.dump(config, file, default_flow_style=False)\n            print(f\"File di configurazione creato: {output_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class YoloModel(nn.Module):\n    \"\"\"\n    Classe YOLOv5 per definire il modello e la funzione di forward.\n    \"\"\"\n    def __init__(self, model_path=\"yolov5s.pt\"):\n        \"\"\"\n        Inizializza il modello YOLOv5.\n\n        Args:\n            model_path (str): Percorso ai pesi pre-addestrati YOLOv5.\n        \"\"\"\n        super(YoloModel, self).__init__()\n        self.model_path = model_path\n        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n\n    def forward(self, images):\n        \"\"\"\n        Esegue la predizione sul batch di immagini.\n\n        Args:\n            images (torch.Tensor): Batch di immagini di input.\n\n        Returns:\n            torch.Tensor: Risultati delle predizioni.\n        \"\"\"\n        return self.model(images)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## per addestrare il modello\n### python train.py --img 640 --epochs 3 --data dataset.yaml --weights yolov5s.pt","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    \"\"\"\n    Classe per addestrare un modello YOLOv5.\n    \"\"\"\n    def __init__(self, model, dataset_yaml, img_size=640, batch_size=16, epochs=50, cache=\"ram\"):\n        \"\"\"\n        Inizializza il Trainer per YOLOv5.\n\n        Args:\n            model (YoloModel): Istanza del modello YOLOv5.\n            dataset_yaml (str): Percorso al file di configurazione del dataset.\n            img_size (int): Dimensione delle immagini di input.\n            batch_size (int): Dimensione del batch per l'addestramento.\n            epochs (int): Numero di epoche.\n            cache (str): Tipo di caching ('ram' o 'disk').\n        \"\"\"\n        self.model = model\n        self.dataset_yaml = dataset_yaml\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.epochs = epochs\n        self.cache = cache\n\n    def train(self): \n        \"\"\"\n        Avvia l'addestramento del modello utilizzando YOLOv5.\n        \"\"\"\n        command = (\n            f\"python train.py --img {self.img_size} --batch-size {self.batch_size} \"\n            f\"--epochs {self.epochs} --data {self.dataset_yaml} \"\n            f\"--weights {self.model.model_path} --cache {self.cache}\"\n        )\n        os.system(command)\n        print(\"Addestramento completato.\")\n\n    def validate(self, weights_path=None):\n        \"\"\"\n        Valida il modello sui dati di test.\n\n        Args:\n            weights_path (str, optional): Percorso ai pesi addestrati. Se None, usa i pesi attuali del modello.\n        \"\"\"\n        weights = weights_path if weights_path else self.model.model_path\n        command = f\"python val.py --data {self.dataset_yaml} --weights {weights} --img {self.img_size}\"\n        os.system(command)\n        print(\"Validazione completata.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}