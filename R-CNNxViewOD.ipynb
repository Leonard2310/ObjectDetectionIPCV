{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10118002,"sourceType":"datasetVersion","datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"pip install selectivesearch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:29:51.275785Z","iopub.execute_input":"2024-12-06T12:29:51.276075Z","iopub.status.idle":"2024-12-06T12:30:03.399392Z","shell.execute_reply.started":"2024-12-06T12:29:51.276038Z","shell.execute_reply":"2024-12-06T12:30:03.398351Z"}},"outputs":[{"name":"stdout","text":"Collecting selectivesearch\n  Downloading selectivesearch-0.4.tar.gz (3.8 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from selectivesearch) (1.26.4)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from selectivesearch) (0.23.2)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (1.14.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->selectivesearch) (3.1.2)\nBuilding wheels for collected packages: selectivesearch\n  Building wheel for selectivesearch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for selectivesearch: filename=selectivesearch-0.4-py3-none-any.whl size=4335 sha256=747fd5c055409a45d6d9170a28de56f5fad83aaf0c114b9a3ae4b4ee0d3893b4\n  Stored in directory: /root/.cache/pip/wheels/0e/49/95/01447a4e0f48a135ac91fbdb1dd2a1c0523e40e29957b383a3\nSuccessfully built selectivesearch\nInstalling collected packages: selectivesearch\nSuccessfully installed selectivesearch-0.4\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip uninstall opencv-contrib-python opencv-python --yes\n\n!pip install opencv-contrib-python ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:30:03.401597Z","iopub.execute_input":"2024-12-06T12:30:03.402349Z","iopub.status.idle":"2024-12-06T12:30:17.844809Z","shell.execute_reply.started":"2024-12-06T12:30:03.402303Z","shell.execute_reply":"2024-12-06T12:30:17.843855Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: opencv-contrib-python 4.10.0.84\nUninstalling opencv-contrib-python-4.10.0.84:\n  Successfully uninstalled opencv-contrib-python-4.10.0.84\nFound existing installation: opencv-python 4.10.0.84\nUninstalling opencv-python-4.10.0.84:\n  Successfully uninstalled opencv-python-4.10.0.84\nCollecting opencv-contrib-python\n  Downloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-contrib-python) (1.26.4)\nDownloading opencv_contrib_python-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (68.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.7/68.7 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: opencv-contrib-python\nSuccessfully installed opencv-contrib-python-4.10.0.84\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport imageio.v3 as imageio\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport pandas as pd\nimport cv2\nimport shutil\nimport json\nimport yaml\nimport random\nimport time\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm_notebook\nimport concurrent.futures\nimport multiprocessing as mp\nfrom PIL import Image, ImageOps\nfrom collections import defaultdict, Counter\nfrom torchvision import transforms\nfrom torchvision.transforms import functional as TF\nimport torch.optim as optim\nimport re\nimport selectivesearch\nimport torch.optim as optim\nfrom torchvision import models\nfrom torchvision.models import AlexNet_Weights\nimport matplotlib.patches as mpatches\nimport torch.nn.functional as F\nfrom sklearn.svm import SVC\nfrom concurrent.futures import ProcessPoolExecutor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:45:47.284416Z","iopub.execute_input":"2024-12-06T12:45:47.284802Z","iopub.status.idle":"2024-12-06T12:45:47.292263Z","shell.execute_reply.started":"2024-12-06T12:45:47.284770Z","shell.execute_reply":"2024-12-06T12:45:47.291320Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"#Output folders and file names\nOUT_COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_IMAGE_FLDR_NM = 'images'\nOUT_CFG_FLDR_NM = 'YOLO_cfg'\nOUT_DATAFRAME_NM = 'xview_labels.parquet'\nYAML_NM = 'xview_yolo.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\ncfg_fldr_pth = Path(f'/kaggle/input/our-xview-dataset/{OUT_CFG_FLDR_NM}')\n\nout_data_parquet_pth = in_dataset_pth / OUT_DATAFRAME_NM\ncoco_json_pth = in_dataset_pth / OUT_COCO_JSON_NM\nyolo_yaml_pth = cfg_fldr_pth / YAML_NM\ntrain_txt_pth = cfg_fldr_pth / 'train.txt'\nval_txt_pth = cfg_fldr_pth / 'val.txt'\ntest_txt_pth = cfg_fldr_pth / 'test.txt'\n\n# PROPOSALS\nOUT_PROPOSALS_FLDR_NM = 'proposals'\nprop_fldr = Path(f'/kaggle/working/{OUT_PROPOSALS_FLDR_NM}')\nPROP_COCO_JSON_NM = 'proposals.json'\nproposals_json = out_dataset_pth / PROP_COCO_JSON_NM\n\nrandom.seed(RANDOM_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:30:24.256049Z","iopub.execute_input":"2024-12-06T12:30:24.256465Z","iopub.status.idle":"2024-12-06T12:30:24.262698Z","shell.execute_reply.started":"2024-12-06T12:30:24.256436Z","shell.execute_reply":"2024-12-06T12:30:24.261756Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)\nclean_output(prop_fldr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:30:24.263720Z","iopub.execute_input":"2024-12-06T12:30:24.264020Z","iopub.status.idle":"2024-12-06T12:30:24.280840Z","shell.execute_reply.started":"2024-12-06T12:30:24.263993Z","shell.execute_reply":"2024-12-06T12:30:24.279894Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\nCartella /kaggle/working/proposals non trovata. Nessuna azione necessaria.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"markdown","source":"## Region Proposals Generation","metadata":{}},{"cell_type":"code","source":"from functools import lru_cache\n\n# Ottimizzazione del caricamento delle immagini con cache\n@lru_cache(maxsize=256)\ndef load_image(img_path):\n    \"\"\"Carica e converte l'immagine solo se non è già stata caricata.\"\"\"\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Converti in RGB\n    return image\n\ndef process_single_image(image_data, img_fldr):\n    img_id = image_data['id']\n    img_name = image_data['file_name']\n    img_path = os.path.join(img_fldr, img_name)\n\n    if not os.path.exists(img_path):\n        raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n\n    # Usa la funzione cache per caricare l'immagine\n    image = load_image(img_path)\n    original_height, original_width, _ = image.shape\n\n    # Chiamata alla funzione unificata per generare le proposte\n    processed_proposals = generate_and_process_proposals(image, original_width, original_height)\n\n    image_data = {\n        \"image_id\": img_id,\n        \"file_name\": img_name,\n        \"original_size\": [original_width, original_height],\n        \"proposals\": []\n    }\n\n    # Prepara le proposte per l'output\n    for i, proposal in enumerate(processed_proposals):\n        x_min, y_min, x_max, y_max = proposal\n        image_data[\"proposals\"].append({\n            \"proposal_id\": i,\n            \"coordinates\": [x_min, y_min, x_max, y_max]\n        })\n\n    return image_data\n\ndef generate_dataset_proposals(coco_json, img_fldr, output_dir, output_json):\n    os.makedirs(output_dir, exist_ok=True)\n    all_image_data = []\n\n    # Carica il file JSON di COCO (usiamo ujson per velocità)\n    with open(coco_json, 'r') as f:\n        coco_data = json.load(f)\n\n    image_annotations_map = {}\n    for annotation in coco_data['annotations']:\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_map:\n            image_annotations_map[image_id] = []\n        image_annotations_map[image_id].append(annotation)\n\n    images_with_annotations = [\n        image_data for image_data in coco_data['images'] \n        if image_data['id'] in image_annotations_map and len(image_annotations_map[image_data['id']]) > 0\n    ]\n\n    # Usa ThreadPoolExecutor per velocizzare il caricamento delle immagini\n    max_workers = 8  # Regola il numero di thread in base al tuo ambiente\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        # Parallelizza l'elaborazione delle immagini e mostra il progresso con tqdm\n        results = list(tqdm(executor.map(process_single_image, images_with_annotations, [img_fldr]*len(images_with_annotations)),\n                           total=len(images_with_annotations), \n                           desc=\"Processing images\"))\n        \n    # Scrivi il risultato in JSON usando ujson\n    with open(output_json, 'w') as json_file:\n        json.dump(results, json_file, indent=4)\n\n    print(f\"Creato file JSON con le region proposals: {output_json}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:03:31.212516Z","iopub.execute_input":"2024-12-06T13:03:31.212864Z","iopub.status.idle":"2024-12-06T13:03:31.223553Z","shell.execute_reply.started":"2024-12-06T13:03:31.212834Z","shell.execute_reply":"2024-12-06T13:03:31.222708Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"'''\ndef generate_dataset_proposals(txt_file, dir_name):\n  # prendo i path delle immagini e li memorizzo in una lista\n   with open(txt_file, 'r') as f:\n            image_paths = [line.strip() for line in f.readlines()]\n\n  img_dir = img_dir\n  os.makedirs(img_dir, exist_ok=True)\n\n  for index in range(len(image_paths)):\n    img_name = os.path.basename(image_paths[index]) #prendo il path dell'immagine da self.image_paths in base all'indice fornito\n    img_id = int(img_name.replace('_', '').replace('.jpg', '').replace('img', '')) #ricavo l'id dell'immagine -> non l'ho già fatto nell'init?\n\n    dir_image = os.path.join(dir_name, img_id) #nome della directory che conterrà le region proposals relative all'immagine\n\n    if img_id not in self.image_info: #vedo dal dizionario self.image_info se l'immagine è contenuta nel file COCO\n              raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\n\n    img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell'immagine unendo il path della cartella con il nome.jpg dell'immagine\n    if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\n              raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n\n    image = Image.open(img_path).convert('RGB') #apro l'immagine e ne ricavo le dimensioni\n    original_width, original_height = image.size\n\n     # GESTIONE DELLE REGION PROPOSALS\n     proposals_tensor = generate_region_proposals(image) # image = immagine aperta in formato RGB con la libreria PIL\n     #    produce una lista di proposals nel formato (x_min, y_min, x_max, y_max)\n\n     processed_proposals = process_proposals(image_tensor, proposals_tensor) # image_tensor = image dopo la data agumentation\n     #    produce le immagine = region proposals relative all'immagine di input\n\n     # salvo le region proposals come immagini in una cartella relativa all'immagine di input\n     # - salvataggio in dir_image\n     os.makedirs(dir_image, exist_ok=True)\n\n    # Iterare sulle region proposals e salvarle come immagini\n    for i, proposal_tensor in enumerate(processed_proposals):\n        # Convertire il tensore in immagine PIL (assumendo valori nel range [0, 1])\n        proposal_image = Image.fromarray((proposal_tensor.numpy() * 255).astype('uint8'))\n\n        # Generare un nome file unico\n        proposal_filename = os.path.join(dir_image, f'proposal_{i:04d}.jpg')\n\n        # Salvare l'immagine\n        proposal_image.save(proposal_filename)\n\n        print(f\"Salvata proposal {i+1}/{len(processed_proposals)}: {proposal_filename}\")\n\n        # Aggiungi il path relativo alla lista\n        relative_path = os.path.relpath(proposal_filename, dir_name)  # Path relativo rispetto a dir_name\n        all_proposal_paths.append(relative_path)\n\n    # Scrittura di tutti i path relativi in un unico file .txt\n    with open(output_txt, 'w') as txt_file:\n        for path in all_proposal_paths:\n            txt_file.write(f\"{path}\\n\")\n\n    print(f\"Creato file TXT con i path relativi di tutte le region proposals: {output_txt}\")\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:30:24.294409Z","iopub.execute_input":"2024-12-06T12:30:24.294694Z","iopub.status.idle":"2024-12-06T12:30:24.311507Z","shell.execute_reply.started":"2024-12-06T12:30:24.294670Z","shell.execute_reply":"2024-12-06T12:30:24.310663Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'\\ndef generate_dataset_proposals(txt_file, dir_name):\\n  # prendo i path delle immagini e li memorizzo in una lista\\n   with open(txt_file, \\'r\\') as f:\\n            image_paths = [line.strip() for line in f.readlines()]\\n\\n  img_dir = img_dir\\n  os.makedirs(img_dir, exist_ok=True)\\n\\n  for index in range(len(image_paths)):\\n    img_name = os.path.basename(image_paths[index]) #prendo il path dell\\'immagine da self.image_paths in base all\\'indice fornito\\n    img_id = int(img_name.replace(\\'_\\', \\'\\').replace(\\'.jpg\\', \\'\\').replace(\\'img\\', \\'\\')) #ricavo l\\'id dell\\'immagine -> non l\\'ho già fatto nell\\'init?\\n\\n    dir_image = os.path.join(dir_name, img_id) #nome della directory che conterrà le region proposals relative all\\'immagine\\n\\n    if img_id not in self.image_info: #vedo dal dizionario self.image_info se l\\'immagine è contenuta nel file COCO\\n              raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\\n\\n    img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell\\'immagine unendo il path della cartella con il nome.jpg dell\\'immagine\\n    if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\\n              raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\\n\\n    image = Image.open(img_path).convert(\\'RGB\\') #apro l\\'immagine e ne ricavo le dimensioni\\n    original_width, original_height = image.size\\n\\n     # GESTIONE DELLE REGION PROPOSALS\\n     proposals_tensor = generate_region_proposals(image) # image = immagine aperta in formato RGB con la libreria PIL\\n     #    produce una lista di proposals nel formato (x_min, y_min, x_max, y_max)\\n\\n     processed_proposals = process_proposals(image_tensor, proposals_tensor) # image_tensor = image dopo la data agumentation\\n     #    produce le immagine = region proposals relative all\\'immagine di input\\n\\n     # salvo le region proposals come immagini in una cartella relativa all\\'immagine di input\\n     # - salvataggio in dir_image\\n     os.makedirs(dir_image, exist_ok=True)\\n\\n    # Iterare sulle region proposals e salvarle come immagini\\n    for i, proposal_tensor in enumerate(processed_proposals):\\n        # Convertire il tensore in immagine PIL (assumendo valori nel range [0, 1])\\n        proposal_image = Image.fromarray((proposal_tensor.numpy() * 255).astype(\\'uint8\\'))\\n\\n        # Generare un nome file unico\\n        proposal_filename = os.path.join(dir_image, f\\'proposal_{i:04d}.jpg\\')\\n\\n        # Salvare l\\'immagine\\n        proposal_image.save(proposal_filename)\\n\\n        print(f\"Salvata proposal {i+1}/{len(processed_proposals)}: {proposal_filename}\")\\n\\n        # Aggiungi il path relativo alla lista\\n        relative_path = os.path.relpath(proposal_filename, dir_name)  # Path relativo rispetto a dir_name\\n        all_proposal_paths.append(relative_path)\\n\\n    # Scrittura di tutti i path relativi in un unico file .txt\\n    with open(output_txt, \\'w\\') as txt_file:\\n        for path in all_proposal_paths:\\n            txt_file.write(f\"{path}\\n\")\\n\\n    print(f\"Creato file TXT con i path relativi di tutte le region proposals: {output_txt}\")\\n'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"'''\ndef generate_region_proposals(image, img_width, img_height): #funzione per la generazione delle region proposals per singola immagine\n        img_np = np.array(image) #trasformo l'immagine in un array numpy\n\n        if len(img_np.shape) == 3 and img_np.shape[0] == 3: #porto l'immagine nel formato corretto\n            img_np = np.transpose(img_np, (1, 2, 0))  # Da [C, H, W] a [H, W, C]\n            \n        _, regions = selectivesearch.selective_search(img_np, scale=300, sigma=0.9, min_size=10) #richiamo la funzione di selective search\n        #scale: granularità della ricerca (più alto, meno dettagliato) ; \n        #sigma: Standard deviation per il filtro gaussiano usato per la segmentazione ;\n        #min_size: Dimensione minima di un segmento nell'algoritmo\n        #regions: lista di regioni candidate (proposals).\n        # - regione = dizionario che contiene info. -> incluse le coordinate di un rettangolo delimitante (region['rect'])\n\n        #CHECK SULLA PRODUZIONE DELLE REGION PROPOSALS\n        if len(regions) == 0:\n            print(f\"Warning: Nessuna regione proposta generata per immagine con forma {img_np.shape}.\")\n\n        candidate_proposals = []\n        for region in regions: #per ogni regione nella lista delle regioni candidate\n            x, y, w, h = region['rect'] # prendo le coordinate del rettangolo delimitante\n            if w > 0 and h > 0 and w >= 10 and h >= 10: # prendo solo le regioni con altezza e larghezza >= 10 per evitare che siano molto rumorose\n                area = w * h\n                x_max, y_max = min(x + w, img_np.shape[1]), min(y + h, img_np.shape[0]) # limito la regione alle dimensioni dell'immagine\n                candidate_proposals.append([x, y, x_max, y_max, area]) #inserisco la nuova regione nella lista delle region proposals -> aggiungo un valore in più (area) per facilitare il filtraggio dopo\n\n        unique_proposals = list(set(tuple(p) for p in candidate_proposals)) # converto le proposals in tuple in modo da eliminare i duplicati\n\n        #in questo modo non viene preservata la corrispondenza tra region proposals e labels\n\n        #FILTRO LE PROPOSALS PER PRENDERE SOLO QUELLE UTILI/NECESSARIE\n        min_area = 10\n        max_area_ratio = 0.8\n        proposals = []\n\n        for x_min, y_min, x_max, y_max, area in unique_proposals: #per ogni proposal\n            if area >= min_area and area <= max_area_ratio * (img_width * img_height):\n                proposals.append((x_min, y_min, x_max, y_max))\n\n        return proposals # restituisce le region proposal valide\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:47:04.063272Z","iopub.execute_input":"2024-12-06T12:47:04.063638Z","iopub.status.idle":"2024-12-06T12:47:04.070772Z","shell.execute_reply.started":"2024-12-06T12:47:04.063606Z","shell.execute_reply":"2024-12-06T12:47:04.069911Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"'''\ndef process_proposals(image_tensor, proposals, output_size=(227, 227)):  # la funzione trasforma le proposals trovate in immagini ottenute ritagliando l'immagine originale\n    processed_proposals = []\n    for proposal in proposals:  # per ogni proposal\n        try:\n            _, H, W = image_tensor.shape  # vedo le dimensioni dell'immagine\n            x_min, y_min, x_max, y_max = map(int, proposal)\n            x_min, y_min = max(0, x_min), max(0, y_min)\n            x_max, y_max = min(W, x_max), min(H, y_max)\n\n            # Controlla se la proposal ha dimensioni valide per l'immagine di partenza -> tecnicamente non si potrebbe eliminare l'if?\n            if x_min < x_max and y_min < y_max:\n                cropped_region = image_tensor[:, y_min:y_max, x_min:x_max]  # Ritaglio\n\n                # Controlla che il ritaglio non sia vuoto\n                if cropped_region.size == 0:\n                    print(f\"Ritaglio vuoto per proposal: {proposal}. Salto.\")\n                    continue\n\n                # Controlla che il tensor sia 3D (C, H, W)\n                if cropped_region.ndim != 3:\n                    print(f\"Proposal non valida per il ridimensionamento: {proposal}. Salto.\")\n                    continue\n\n                # Converti cropped_region in un tensore PyTorch\n                cropped_region = torch.tensor(cropped_region).permute(2, 0, 1)  # Cambia il formato da HWC a CHW\n\n                # Ridimensiona la regione proposta\n                resized_region = torch.nn.functional.interpolate(\n                    cropped_region.unsqueeze(0), size=output_size, mode='bilinear', align_corners=False\n                ).squeeze(0)  # Ridimensiona\n\n                processed_proposals.append(resized_region)\n        except Exception as e:\n            print(f\"Errore durante il processamento della proposal: {proposal}. Errore: {e}\")\n\n    return processed_proposals  # Lista di tensori delle region proposals\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:47:05.569591Z","iopub.execute_input":"2024-12-06T12:47:05.570229Z","iopub.status.idle":"2024-12-06T12:47:05.577373Z","shell.execute_reply.started":"2024-12-06T12:47:05.570195Z","shell.execute_reply":"2024-12-06T12:47:05.576408Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"import concurrent.futures\n\ndef generate_and_process_proposals(image, img_width, img_height):\n    # Converto l'immagine in un array numpy solo se necessario\n    img_np = np.array(image)\n\n    # Esegui la selective search per trovare le regioni di interesse (proposals)\n    _, regions = selectivesearch.selective_search(img_np, scale=300, sigma=0.9, min_size=10)\n\n    if len(regions) == 0:\n        print(f\"Warning: Nessuna regione proposta generata per immagine con forma {img_np.shape}.\")\n\n    processed_proposals = []  # Lista per le proposte elaborate\n\n    # Pre-filtraggio delle regioni e raccolta delle coordinate delle proposte\n    for region in regions:\n        x, y, w, h = region['rect']\n        \n        # Controlla se la regione è abbastanza grande senza calcoli inutili\n        area = w * h\n        if w >= 10 and h >= 10 and 10 <= area <= 0.8 * (img_width * img_height):\n            x_max, y_max = x + w, y + h\n            # Aggiungi le coordinate alla lista delle proposte\n            processed_proposals.append([x, y, x_max, y_max])\n\n    return processed_proposals  # Restituisce solo le coordinate delle proposte\n\n# Funzione per elaborare un batch di immagini in parallelo\ndef process_images_in_parallel(images, img_width, img_height):\n    # Utilizza concurrent.futures per elaborare più immagini in parallelo\n    with concurrent.futures.ThreadPoolExecutor() as executor:\n        # La funzione generate_and_process_proposals verrà applicata su ogni immagine\n        results = list(executor.map(lambda image: generate_and_process_proposals(image, img_width, img_height), images))\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:03:35.709357Z","iopub.execute_input":"2024-12-06T13:03:35.709731Z","iopub.status.idle":"2024-12-06T13:03:35.717371Z","shell.execute_reply.started":"2024-12-06T13:03:35.709699Z","shell.execute_reply":"2024-12-06T13:03:35.716459Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"generate_dataset_proposals(coco_json_pth, img_fldr, prop_fldr, proposals_json)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T13:03:37.249710Z","iopub.execute_input":"2024-12-06T13:03:37.250030Z"}},"outputs":[{"name":"stderr","text":"Processing images:   0%|          | 36/32199 [00:36<6:25:48,  1.39it/s] ","output_type":"stream"}],"execution_count":null},{"cell_type":"markdown","source":"## Positive Region Proposals","metadata":{}},{"cell_type":"code","source":"# Funzione IoU per calcolare la sovrapposizione\ndef box_iou(boxes1, boxes2):\n    \"\"\"Calcola la IoU tra due set di bounding boxes.\"\"\"\n    # Espande le dimensioni per il broadcasting\n    boxes1 = boxes1.unsqueeze(1)  # (N, 1, 4)\n    boxes2 = boxes2.unsqueeze(0)  # (1, M, 4)\n    \n    # Calcola gli estremi delle intersezioni\n    inter_min = torch.max(boxes1[:, :, :2], boxes2[:, :, :2])  # (N, M, 2)\n    inter_max = torch.min(boxes1[:, :, 2:], boxes2[:, :, 2:])  # (N, M, 2)\n    inter_sizes = (inter_max - inter_min).clamp(min=0)  # Nessuna area negativa\n    inter_area = inter_sizes[:, :, 0] * inter_sizes[:, :, 1]  # Area dell'intersezione\n    \n    # Calcola le aree delle bounding boxes\n    boxes1_area = (boxes1[:, :, 2] - boxes1[:, :, 0]) * (boxes1[:, :, 3] - boxes1[:, :, 1])\n    boxes2_area = (boxes2[:, :, 2] - boxes2[:, :, 0]) * (boxes2[:, :, 3] - boxes2[:, :, 1])\n    \n    # Calcola l'area dell'unione\n    union_area = boxes1_area + boxes2_area - inter_area\n    return inter_area / union_area  # IoU","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:32:47.736752Z","iopub.status.idle":"2024-12-06T12:32:47.737043Z","shell.execute_reply.started":"2024-12-06T12:32:47.736900Z","shell.execute_reply":"2024-12-06T12:32:47.736915Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def assign_and_save_regions(region_json_path, bbox_json_path, image_dir, output_dir, iou_threshold=0.5):\n    \"\"\"Associa le regioni proposte ai bounding boxes e salva le regioni positive come immagini.\"\"\"\n    # Carica i file JSON\n    with open(region_json_path, 'r') as f:\n        regions = json.load(f)\n\n    with open(bbox_json_path, 'r') as f:\n        bboxes = json.load(f)\n    \n    # Crea un dizionario per cercare annotations per image_id\n    annotations_by_image = {}\n    for annot in bboxes[\"annotations\"]:\n        img_id = annot[\"image_id\"]\n        if img_id not in annotations_by_image:\n            annotations_by_image[img_id] = []\n        annotations_by_image[img_id].append((annot[\"bbox\"], annot[\"category_id\"]))\n    \n    # Crea un dizionario per mappare category_id ai nomi delle categorie\n    category_mapping = {cat_id: name for cat_id, name in enumerate(bboxes[\"categories\"])}\n    \n    # Crea la directory di output se non esiste\n    os.makedirs(output_dir, exist_ok=True)\n    \n    train_images = []  # Per tracciare i percorsi delle immagini salvate\n    train_labels = []  # Etichette corrispondenti (category_id)\n    counter = 0  # Contatore delle immagini salvate\n    \n    # Per ogni immagine nelle regioni\n    for image in regions:\n        image_id = image[\"image_id\"]\n        file_name = image[\"file_name\"]\n        proposals = image[\"proposals\"]\n        \n        # Ottieni bounding boxes ground-truth e categorie per l'immagine corrente\n        gt_data = annotations_by_image.get(image_id, [])\n        if not gt_data:\n            # Se non ci sono bounding boxes ground-truth, salta l'immagine\n            continue\n        \n        gt_bboxes = torch.tensor([item[0] for item in gt_data], dtype=torch.float32)\n        gt_categories = [item[1] for item in gt_data]\n        \n        # Trasforma proposals in tensori\n        proposal_coords = torch.tensor([p[\"coordinates\"] for p in proposals], dtype=torch.float32)\n        \n        # Calcola la matrice IoU\n        iou_matrix = box_iou(proposal_coords, gt_bboxes)\n        \n        # Identifica le regioni positive (IoU >= soglia)\n        max_ious, indices = torch.max(iou_matrix, dim=1)\n        positive_indices = torch.nonzero(max_ious >= iou_threshold).squeeze(1)\n        \n        # Carica l'immagine originale\n        image_path = os.path.join(image_dir, file_name)\n        original_image = cv2.imread(image_path)\n        if original_image is None:\n            print(f\"Immagine non trovata: {image_path}\")\n            continue\n        \n        # Per ogni regione positiva, ritaglia e salva l'immagine\n        for idx in positive_indices:\n            x_min, y_min, x_max, y_max = proposal_coords[idx].int().tolist()\n            cropped = original_image[y_min:y_max, x_min:x_max]\n            \n            # Ridimensiona a 224x224\n            resized = cv2.resize(cropped, (224, 224), interpolation=cv2.INTER_AREA)\n            \n            # Ottieni l'etichetta della categoria dal bounding box assegnato\n            category_id = gt_categories[indices[idx].item()]\n            \n            # Salva l'immagine\n            output_path = os.path.join(output_dir, f\"image_{counter:06d}.jpg\")\n            cv2.imwrite(output_path, resized)\n            \n            # Aggiorna train_images e train_labels\n            train_images.append(output_path)\n            train_labels.append(category_id)\n            \n            counter += 1\n    \n    return train_images, train_labels","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:32:47.738034Z","iopub.status.idle":"2024-12-06T12:32:47.738342Z","shell.execute_reply.started":"2024-12-06T12:32:47.738178Z","shell.execute_reply":"2024-12-06T12:32:47.738193Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, txt_file, img_dir, coco_json_file, aug=False):\n        def generate_id(file_name): #prende il nome.jpg di una immagine e restituisce solo l'identificativo senza prefissi e suffissi\n            return file_name.replace('_', '').replace('.jpg', '').replace('img', '')\n\n        with open(txt_file, 'r') as f: #salva le region proposals in un file txt con direttamente le info della cartella\n            self.image_paths = [line.strip() for line in f.readlines()] #memorizzo i path delle immagini in una lista\n\n        with open(coco_json_file, 'r') as f: #leggo il file .json - contenente (...) - con coco\n            coco_data = json.load(f)\n\n        self.image_annotations = {} #dizionario contenente per ogni immagine una lista di categorie di oggetti presebti\n\n        for annotation in coco_data['annotations']: #uso la sezione annotazioni del file .json per ricavare delle info. sulle immagini del dataset\n            image_id = annotation['image_id']\n            category_id = annotation['category_id'] # lista di category_id = categorie degli oggetti nell'immagine)\n\n            if image_id not in self.image_annotations: #verifico se l'id dell'immagine è già presente nel dizionario\n                self.image_annotations[image_id] = []\n\n            self.image_annotations[image_id].append(category_id)\n\n        self.image_info = {\n            int(generate_id(image['file_name'])): image['file_name']\n            for image in coco_data['images']\n        } #dizionario in cui per ogni nome dell'immagine ottenuta da generate_id(file_name) associa il nome.jpg dell'imagine\n\n        self.base_transform = transforms.Compose([\n            transforms.Resize((320, 320)),\n            transforms.ToTensor(),\n        ]) # trasformazione di base da applicare a tutte le immagini\n\n        # lasciare momentaneamente in caso di aggiornamenti futuri\n        self.aug_transform = transforms.Compose([\n            transforms.Resize((320, 320)),\n            transforms.ToTensor(),\n        ]) # strasformazione per la data agumentation\n\n        self.aug = aug\n\n    def __len__(self): # ritorna il numero di elementi in self.image_paths -> chi è?\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        img_name = os.path.basename(self.image_paths[index]) #prendo il path dell'immagine da self.image_paths in base all'indice fornito\n        img_id = int(img_name.replace('_', '').replace('.jpg', '').replace('img', '')) #ricavo l'id dell'immagine -> non l'ho già fatto nell'init?\n\n        if img_id not in self.image_info: #vedo dal dizionario self.image_info se l'immagine è contenuta nel file COCO\n            raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\n\n        img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell'immagine unendo il path della cartella con il nome.jpg dell'immagine\n        if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\n            raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n\n        image = Image.open(img_path).convert('RGB') #apro l'immagine e ne ricavo le dimensioni\n        #original_width, original_height = image.size\n\n        if self.aug: #se la variabile self.aug è alta allora applico la self.aug_transform altrimenti la self.base_transform _> HA SENSO? LE DUE FUNZIONI SONO = !!\n            image_tensor = self.aug_transform(image)\n        else:\n            image_tensor = self.base_transform(image)\n\n        #POTREBBE ESSERCI UN PROBLEMA NELLA CORRISPONDENZA TRA LABLES E REGION PROPOSALS -> perchè in proposals_tensor non ci sono tutte le region proposals perchè alcune vengono scartate\n        # -> se la corrispondenza è 1 a 1 allora potrebbe convenire dare a _generate_region_proposals(image) sia le labes che l'immagine? -> non è certo perchè\n        # in lables c'è una lista di lable ma non viene specificato dove sono localizzate\n\n        # restituisce un dizionario\n        return {\n            \"regions\": image_tensor  # region proposals elaborate, una lista di tensori che rappresentano regioni candidate per il rilevamento\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T12:32:47.740148Z","iopub.status.idle":"2024-12-06T12:32:47.740464Z","shell.execute_reply.started":"2024-12-06T12:32:47.740315Z","shell.execute_reply":"2024-12-06T12:32:47.740331Z"}},"outputs":[],"execution_count":null}]}