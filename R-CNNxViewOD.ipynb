{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10118002,"sourceType":"datasetVersion","datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"pip install selectivesearch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:39:55.426495Z","iopub.execute_input":"2024-12-06T11:39:55.426927Z","iopub.status.idle":"2024-12-06T11:40:05.531776Z","shell.execute_reply.started":"2024-12-06T11:39:55.426892Z","shell.execute_reply":"2024-12-06T11:40:05.530395Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: selectivesearch in /opt/conda/lib/python3.10/site-packages (0.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from selectivesearch) (1.26.4)\nRequirement already satisfied: scikit-image in /opt/conda/lib/python3.10/site-packages (from selectivesearch) (0.23.2)\nRequirement already satisfied: scipy>=1.9 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (1.14.1)\nRequirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (3.3)\nRequirement already satisfied: pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (10.3.0)\nRequirement already satisfied: imageio>=2.33 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (2.34.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (2024.5.22)\nRequirement already satisfied: packaging>=21 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (21.3)\nRequirement already satisfied: lazy-loader>=0.4 in /opt/conda/lib/python3.10/site-packages (from scikit-image->selectivesearch) (0.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=21->scikit-image->selectivesearch) (3.1.2)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport imageio.v3 as imageio\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport pandas as pd\nimport cv2\nimport shutil\nimport json\nimport yaml\nimport random\nimport time\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm_notebook\nimport concurrent.futures\nimport multiprocessing as mp\nfrom PIL import Image, ImageOps\nfrom collections import defaultdict, Counter\nfrom torchvision import transforms\nfrom torchvision.transforms import functional as TF\nimport torch.optim as optim\nimport re\nimport selectivesearch\nimport torch.optim as optim\nfrom torchvision import models\nfrom torchvision.models import AlexNet_Weights\nimport matplotlib.patches as mpatches\nimport torch.nn.functional as F\nfrom sklearn.svm import SVC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.534730Z","iopub.execute_input":"2024-12-06T11:40:05.535226Z","iopub.status.idle":"2024-12-06T11:40:05.545475Z","shell.execute_reply.started":"2024-12-06T11:40:05.535174Z","shell.execute_reply":"2024-12-06T11:40:05.544350Z"}},"outputs":[],"execution_count":44},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"#Output folders and file names\nOUT_COCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_IMAGE_FLDR_NM = 'images'\nOUT_CFG_FLDR_NM = 'YOLO_cfg'\nOUT_DATAFRAME_NM = 'xview_labels.parquet'\nYAML_NM = 'xview_yolo.yaml'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\ncfg_fldr_pth = Path(f'/kaggle/input/our-xview-dataset/{OUT_CFG_FLDR_NM}')\n\nout_data_parquet_pth = in_dataset_pth / OUT_DATAFRAME_NM\ncoco_json_pth = in_dataset_pth / OUT_COCO_JSON_NM\nyolo_yaml_pth = cfg_fldr_pth / YAML_NM\ntrain_txt_pth = cfg_fldr_pth / 'train.txt'\nval_txt_pth = cfg_fldr_pth / 'val.txt'\ntest_txt_pth = cfg_fldr_pth / 'test.txt'\n\n# PROPOSALS\nOUT_PROPOSALS_FLDR_NM = 'proposals'\nprop_fldr = Path(f'/kaggle/working/{OUT_PROPOSALS_FLDR_NM}')\nPROP_COCO_JSON_NM = 'proposals.json'\nproposals_json = out_dataset_pth / PROP_COCO_JSON_NM\n\nrandom.seed(RANDOM_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.546848Z","iopub.execute_input":"2024-12-06T11:40:05.547156Z","iopub.status.idle":"2024-12-06T11:40:05.565693Z","shell.execute_reply.started":"2024-12-06T11:40:05.547125Z","shell.execute_reply":"2024-12-06T11:40:05.564513Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)\nclean_output(prop_fldr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.568859Z","iopub.execute_input":"2024-12-06T11:40:05.569407Z","iopub.status.idle":"2024-12-06T11:40:05.903824Z","shell.execute_reply.started":"2024-12-06T11:40:05.569334Z","shell.execute_reply":"2024-12-06T11:40:05.902667Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\nCartella /kaggle/working/proposals non trovata. Nessuna azione necessaria.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"markdown","source":"## Region Proposals Generation","metadata":{}},{"cell_type":"code","source":"def generate_dataset_proposals(coco_json, img_fldr, output_dir, output_json):\n    os.makedirs(output_dir, exist_ok=True)  # Nuova cartella per le region proposals (puoi rimuoverla se non necessaria)\n    all_image_data = []  # Lista per contenere i dati di tutte le immagini\n\n    # Carica il file JSON di COCO\n    with open(coco_json, 'r') as f:\n        coco_data = json.load(f)\n\n    for image_data in coco_data['images']:\n        img_id = image_data['id']\n        img_name = image_data['file_name']\n        img_path = os.path.join(img_fldr, img_name)\n\n        # Controlla se il file immagine esiste\n        if not os.path.exists(img_path):\n            raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n\n        # Apri l'immagine\n        image = Image.open(img_path).convert('RGB')\n        original_width, original_height = image.size\n\n        # Genera le region proposals\n        proposals_tensor = generate_region_proposals(image, original_width, original_height)\n        processed_proposals = process_proposals(np.array(image), proposals_tensor)\n\n        image_data = {\n            \"image_id\": img_id,\n            \"file_name\": img_name,  # Aggiungi il nome del file\n            \"original_size\": [original_width, original_height],\n            \"proposals\": []\n        }\n\n        for i, proposal_tensor in enumerate(processed_proposals):\n            # Calcola le coordinate della proposta\n            x_min, y_min, x_max, y_max = proposals_tensor[i]  # Coordinate originali\n\n            # Aggiungi i dettagli della proposta al dizionario\n            image_data[\"proposals\"].append({\n                \"proposal_id\": i,\n                \"coordinates\": [x_min, y_min, x_max, y_max]\n            })\n\n        all_image_data.append(image_data)\n\n    # Salva i dati in un file JSON\n    with open(output_json, 'w') as json_file:\n        json.dump(all_image_data, json_file, indent=4)\n\n    print(f\"Creato file JSON con le region proposals: {output_json}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.905586Z","iopub.execute_input":"2024-12-06T11:40:05.906047Z","iopub.status.idle":"2024-12-06T11:40:05.916947Z","shell.execute_reply.started":"2024-12-06T11:40:05.905998Z","shell.execute_reply":"2024-12-06T11:40:05.915734Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"'''\ndef generate_dataset_proposals(txt_file, dir_name):\n  # prendo i path delle immagini e li memorizzo in una lista\n   with open(txt_file, 'r') as f:\n            image_paths = [line.strip() for line in f.readlines()]\n\n  img_dir = img_dir\n  os.makedirs(img_dir, exist_ok=True)\n\n  for index in range(len(image_paths)):\n    img_name = os.path.basename(image_paths[index]) #prendo il path dell'immagine da self.image_paths in base all'indice fornito\n    img_id = int(img_name.replace('_', '').replace('.jpg', '').replace('img', '')) #ricavo l'id dell'immagine -> non l'ho già fatto nell'init?\n\n    dir_image = os.path.join(dir_name, img_id) #nome della directory che conterrà le region proposals relative all'immagine\n\n    if img_id not in self.image_info: #vedo dal dizionario self.image_info se l'immagine è contenuta nel file COCO\n              raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\n\n    img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell'immagine unendo il path della cartella con il nome.jpg dell'immagine\n    if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\n              raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n\n    image = Image.open(img_path).convert('RGB') #apro l'immagine e ne ricavo le dimensioni\n    original_width, original_height = image.size\n\n     # GESTIONE DELLE REGION PROPOSALS\n     proposals_tensor = generate_region_proposals(image) # image = immagine aperta in formato RGB con la libreria PIL\n     #    produce una lista di proposals nel formato (x_min, y_min, x_max, y_max)\n\n     processed_proposals = process_proposals(image_tensor, proposals_tensor) # image_tensor = image dopo la data agumentation\n     #    produce le immagine = region proposals relative all'immagine di input\n\n     # salvo le region proposals come immagini in una cartella relativa all'immagine di input\n     # - salvataggio in dir_image\n     os.makedirs(dir_image, exist_ok=True)\n\n    # Iterare sulle region proposals e salvarle come immagini\n    for i, proposal_tensor in enumerate(processed_proposals):\n        # Convertire il tensore in immagine PIL (assumendo valori nel range [0, 1])\n        proposal_image = Image.fromarray((proposal_tensor.numpy() * 255).astype('uint8'))\n\n        # Generare un nome file unico\n        proposal_filename = os.path.join(dir_image, f'proposal_{i:04d}.jpg')\n\n        # Salvare l'immagine\n        proposal_image.save(proposal_filename)\n\n        print(f\"Salvata proposal {i+1}/{len(processed_proposals)}: {proposal_filename}\")\n\n        # Aggiungi il path relativo alla lista\n        relative_path = os.path.relpath(proposal_filename, dir_name)  # Path relativo rispetto a dir_name\n        all_proposal_paths.append(relative_path)\n\n    # Scrittura di tutti i path relativi in un unico file .txt\n    with open(output_txt, 'w') as txt_file:\n        for path in all_proposal_paths:\n            txt_file.write(f\"{path}\\n\")\n\n    print(f\"Creato file TXT con i path relativi di tutte le region proposals: {output_txt}\")\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.918417Z","iopub.execute_input":"2024-12-06T11:40:05.918739Z","iopub.status.idle":"2024-12-06T11:40:05.938331Z","shell.execute_reply.started":"2024-12-06T11:40:05.918707Z","shell.execute_reply":"2024-12-06T11:40:05.937219Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"'\\ndef generate_dataset_proposals(txt_file, dir_name):\\n  # prendo i path delle immagini e li memorizzo in una lista\\n   with open(txt_file, \\'r\\') as f:\\n            image_paths = [line.strip() for line in f.readlines()]\\n\\n  img_dir = img_dir\\n  os.makedirs(img_dir, exist_ok=True)\\n\\n  for index in range(len(image_paths)):\\n    img_name = os.path.basename(image_paths[index]) #prendo il path dell\\'immagine da self.image_paths in base all\\'indice fornito\\n    img_id = int(img_name.replace(\\'_\\', \\'\\').replace(\\'.jpg\\', \\'\\').replace(\\'img\\', \\'\\')) #ricavo l\\'id dell\\'immagine -> non l\\'ho già fatto nell\\'init?\\n\\n    dir_image = os.path.join(dir_name, img_id) #nome della directory che conterrà le region proposals relative all\\'immagine\\n\\n    if img_id not in self.image_info: #vedo dal dizionario self.image_info se l\\'immagine è contenuta nel file COCO\\n              raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\\n\\n    img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell\\'immagine unendo il path della cartella con il nome.jpg dell\\'immagine\\n    if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\\n              raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\\n\\n    image = Image.open(img_path).convert(\\'RGB\\') #apro l\\'immagine e ne ricavo le dimensioni\\n    original_width, original_height = image.size\\n\\n     # GESTIONE DELLE REGION PROPOSALS\\n     proposals_tensor = generate_region_proposals(image) # image = immagine aperta in formato RGB con la libreria PIL\\n     #    produce una lista di proposals nel formato (x_min, y_min, x_max, y_max)\\n\\n     processed_proposals = process_proposals(image_tensor, proposals_tensor) # image_tensor = image dopo la data agumentation\\n     #    produce le immagine = region proposals relative all\\'immagine di input\\n\\n     # salvo le region proposals come immagini in una cartella relativa all\\'immagine di input\\n     # - salvataggio in dir_image\\n     os.makedirs(dir_image, exist_ok=True)\\n\\n    # Iterare sulle region proposals e salvarle come immagini\\n    for i, proposal_tensor in enumerate(processed_proposals):\\n        # Convertire il tensore in immagine PIL (assumendo valori nel range [0, 1])\\n        proposal_image = Image.fromarray((proposal_tensor.numpy() * 255).astype(\\'uint8\\'))\\n\\n        # Generare un nome file unico\\n        proposal_filename = os.path.join(dir_image, f\\'proposal_{i:04d}.jpg\\')\\n\\n        # Salvare l\\'immagine\\n        proposal_image.save(proposal_filename)\\n\\n        print(f\"Salvata proposal {i+1}/{len(processed_proposals)}: {proposal_filename}\")\\n\\n        # Aggiungi il path relativo alla lista\\n        relative_path = os.path.relpath(proposal_filename, dir_name)  # Path relativo rispetto a dir_name\\n        all_proposal_paths.append(relative_path)\\n\\n    # Scrittura di tutti i path relativi in un unico file .txt\\n    with open(output_txt, \\'w\\') as txt_file:\\n        for path in all_proposal_paths:\\n            txt_file.write(f\"{path}\\n\")\\n\\n    print(f\"Creato file TXT con i path relativi di tutte le region proposals: {output_txt}\")\\n'"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"def generate_region_proposals(image, img_width, img_height): #funzione per la generazione delle region proposals per singola immagine\n        img_np = np.array(image) #trasformo l'immagine in un array numpy\n\n        if len(img_np.shape) == 3 and img_np.shape[0] == 3: #porto l'immagine nel formato corretto\n            img_np = np.transpose(img_np, (1, 2, 0))  # Da [C, H, W] a [H, W, C]\n\n        _, regions = selectivesearch.selective_search(img_np, scale=500, sigma=0.9, min_size=10) #richiamo la funzione di selective search\n        #scale: granularità della ricerca (più alto, meno dettagliato) ; sigma: Standard deviation per il filtro gaussiano usato per la segmentazione ;\n        #min_size: Dimensione minima di un segmento nell'algoritmo\n        #regions: lista di regioni candidate (proposals).\n        # - regione = dizionario che contiene info. -> incluse le coordinate di un rettangolo delimitante (region['rect'])\n\n        #CHECK SULLA PRODUZIONE DELLE REGION PROPOSALS\n        if len(regions) == 0:\n            print(f\"Warning: Nessuna regione proposta generata per immagine con forma {img_np.shape}.\")\n\n        candidate_proposals = []\n        for region in regions: #per ogni regione nella lista delle regioni candidate\n            x, y, w, h = region['rect'] # prendo le coordinate del rettangolo delimitante\n            if w > 0 and h > 0 and w >= 10 and h >= 10: # prendo solo le regioni con altezza e larghezza >= 10 per evitare che siano molto rumorose\n                area = w * h\n                x_max, y_max = min(x + w, img_np.shape[1]), min(y + h, img_np.shape[0]) # limito la regione alle dimensioni dell'immagine\n                candidate_proposals.append([x, y, x_max, y_max, area]) #inserisco la nuova regione nella lista delle region proposals -> aggiungo un valore in più (area) per facilitare il filtraggio dopo\n\n        unique_proposals = list(set(tuple(p) for p in candidate_proposals)) # converto le proposals in tuple in modo da eliminare i duplicati\n\n        #in questo modo non viene preservata la corrispondenza tra region proposals e labels\n\n        #FILTRO LE PROPOSALS PER PRENDERE SOLO QUELLE UTILI/NECESSARIE\n        min_area = 10\n        max_area_ratio = 0.8\n        proposals = []\n\n        for x_min, y_min, x_max, y_max, area in unique_proposals: #per ogni proposal\n            if area >= min_area and area <= max_area_ratio * (img_width * img_height):\n                proposals.append((x_min, y_min, x_max, y_max))\n\n        return proposals # restituisce le region proposal valide","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.940183Z","iopub.execute_input":"2024-12-06T11:40:05.940673Z","iopub.status.idle":"2024-12-06T11:40:05.956004Z","shell.execute_reply.started":"2024-12-06T11:40:05.940624Z","shell.execute_reply":"2024-12-06T11:40:05.954819Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def process_proposals(image_tensor, proposals, output_size=(227, 227)):  # la funzione trasforma le proposals trovate in immagini ottenute ritagliando l'immagine originale\n    processed_proposals = []\n    for proposal in proposals:  # per ogni proposal\n        try:\n            _, H, W = image_tensor.shape  # vedo le dimensioni dell'immagine\n            x_min, y_min, x_max, y_max = map(int, proposal)\n            x_min, y_min = max(0, x_min), max(0, y_min)\n            x_max, y_max = min(W, x_max), min(H, y_max)\n\n            # Controlla se la proposal ha dimensioni valide per l'immagine di partenza -> tecnicamente non si potrebbe eliminare l'if?\n            if x_min < x_max and y_min < y_max:\n                cropped_region = image_tensor[:, y_min:y_max, x_min:x_max]  # Ritaglio\n\n                # Controlla che il ritaglio non sia vuoto\n                if cropped_region.size == 0:\n                    print(f\"Ritaglio vuoto per proposal: {proposal}. Salto.\")\n                    continue\n\n                # Controlla che il tensor sia 3D (C, H, W)\n                if cropped_region.ndim != 3:\n                    print(f\"Proposal non valida per il ridimensionamento: {proposal}. Salto.\")\n                    continue\n\n                # Converti cropped_region in un tensore PyTorch\n                cropped_region = torch.tensor(cropped_region).permute(2, 0, 1)  # Cambia il formato da HWC a CHW\n\n                # Ridimensiona la regione proposta\n                resized_region = torch.nn.functional.interpolate(\n                    cropped_region.unsqueeze(0), size=output_size, mode='bilinear', align_corners=False\n                ).squeeze(0)  # Ridimensiona\n\n                processed_proposals.append(resized_region)\n        except Exception as e:\n            print(f\"Errore durante il processamento della proposal: {proposal}. Errore: {e}\")\n\n    return processed_proposals  # Lista di tensori delle region proposals","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.957638Z","iopub.execute_input":"2024-12-06T11:40:05.958121Z","iopub.status.idle":"2024-12-06T11:40:05.974458Z","shell.execute_reply.started":"2024-12-06T11:40:05.958067Z","shell.execute_reply":"2024-12-06T11:40:05.973420Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"generate_dataset_proposals(coco_json_pth, img_fldr, prop_fldr, proposals_json)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T11:40:05.975840Z","iopub.execute_input":"2024-12-06T11:40:05.976207Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Positive Region Proposals","metadata":{}},{"cell_type":"code","source":"# Funzione IoU per calcolare la sovrapposizione\ndef box_iou(boxes1, boxes2):\n    \"\"\"Calcola la IoU tra due set di bounding boxes.\"\"\"\n    # Espande le dimensioni per il broadcasting\n    boxes1 = boxes1.unsqueeze(1)  # (N, 1, 4)\n    boxes2 = boxes2.unsqueeze(0)  # (1, M, 4)\n    \n    # Calcola gli estremi delle intersezioni\n    inter_min = torch.max(boxes1[:, :, :2], boxes2[:, :, :2])  # (N, M, 2)\n    inter_max = torch.min(boxes1[:, :, 2:], boxes2[:, :, 2:])  # (N, M, 2)\n    inter_sizes = (inter_max - inter_min).clamp(min=0)  # Nessuna area negativa\n    inter_area = inter_sizes[:, :, 0] * inter_sizes[:, :, 1]  # Area dell'intersezione\n    \n    # Calcola le aree delle bounding boxes\n    boxes1_area = (boxes1[:, :, 2] - boxes1[:, :, 0]) * (boxes1[:, :, 3] - boxes1[:, :, 1])\n    boxes2_area = (boxes2[:, :, 2] - boxes2[:, :, 0]) * (boxes2[:, :, 3] - boxes2[:, :, 1])\n    \n    # Calcola l'area dell'unione\n    union_area = boxes1_area + boxes2_area - inter_area\n    return inter_area / union_area  # IoU","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def assign_and_save_regions(region_json_path, bbox_json_path, image_dir, output_dir, iou_threshold=0.5):\n    \"\"\"Associa le regioni proposte ai bounding boxes e salva le regioni positive come immagini.\"\"\"\n    # Carica i file JSON\n    with open(region_json_path, 'r') as f:\n        regions = json.load(f)\n\n    with open(bbox_json_path, 'r') as f:\n        bboxes = json.load(f)\n    \n    # Crea un dizionario per cercare annotations per image_id\n    annotations_by_image = {}\n    for annot in bboxes[\"annotations\"]:\n        img_id = annot[\"image_id\"]\n        if img_id not in annotations_by_image:\n            annotations_by_image[img_id] = []\n        annotations_by_image[img_id].append((annot[\"bbox\"], annot[\"category_id\"]))\n    \n    # Crea un dizionario per mappare category_id ai nomi delle categorie\n    category_mapping = {cat_id: name for cat_id, name in enumerate(bboxes[\"categories\"])}\n    \n    # Crea la directory di output se non esiste\n    os.makedirs(output_dir, exist_ok=True)\n    \n    train_images = []  # Per tracciare i percorsi delle immagini salvate\n    train_labels = []  # Etichette corrispondenti (category_id)\n    counter = 0  # Contatore delle immagini salvate\n    \n    # Per ogni immagine nelle regioni\n    for image in regions:\n        image_id = image[\"image_id\"]\n        file_name = image[\"file_name\"]\n        proposals = image[\"proposals\"]\n        \n        # Ottieni bounding boxes ground-truth e categorie per l'immagine corrente\n        gt_data = annotations_by_image.get(image_id, [])\n        if not gt_data:\n            # Se non ci sono bounding boxes ground-truth, salta l'immagine\n            continue\n        \n        gt_bboxes = torch.tensor([item[0] for item in gt_data], dtype=torch.float32)\n        gt_categories = [item[1] for item in gt_data]\n        \n        # Trasforma proposals in tensori\n        proposal_coords = torch.tensor([p[\"coordinates\"] for p in proposals], dtype=torch.float32)\n        \n        # Calcola la matrice IoU\n        iou_matrix = box_iou(proposal_coords, gt_bboxes)\n        \n        # Identifica le regioni positive (IoU >= soglia)\n        max_ious, indices = torch.max(iou_matrix, dim=1)\n        positive_indices = torch.nonzero(max_ious >= iou_threshold).squeeze(1)\n        \n        # Carica l'immagine originale\n        image_path = os.path.join(image_dir, file_name)\n        original_image = cv2.imread(image_path)\n        if original_image is None:\n            print(f\"Immagine non trovata: {image_path}\")\n            continue\n        \n        # Per ogni regione positiva, ritaglia e salva l'immagine\n        for idx in positive_indices:\n            x_min, y_min, x_max, y_max = proposal_coords[idx].int().tolist()\n            cropped = original_image[y_min:y_max, x_min:x_max]\n            \n            # Ridimensiona a 224x224\n            resized = cv2.resize(cropped, (224, 224), interpolation=cv2.INTER_AREA)\n            \n            # Ottieni l'etichetta della categoria dal bounding box assegnato\n            category_id = gt_categories[indices[idx].item()]\n            \n            # Salva l'immagine\n            output_path = os.path.join(output_dir, f\"image_{counter:06d}.jpg\")\n            cv2.imwrite(output_path, resized)\n            \n            # Aggiorna train_images e train_labels\n            train_images.append(output_path)\n            train_labels.append(category_id)\n            \n            counter += 1\n    \n    return train_images, train_labels","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Custom Dataset","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, txt_file, img_dir, coco_json_file, aug=False):\n        def generate_id(file_name): #prende il nome.jpg di una immagine e restituisce solo l'identificativo senza prefissi e suffissi\n            return file_name.replace('_', '').replace('.jpg', '').replace('img', '')\n\n        with open(txt_file, 'r') as f: #salva le region proposals in un file txt con direttamente le info della cartella\n            self.image_paths = [line.strip() for line in f.readlines()] #memorizzo i path delle immagini in una lista\n\n        with open(coco_json_file, 'r') as f: #leggo il file .json - contenente (...) - con coco\n            coco_data = json.load(f)\n\n        self.image_annotations = {} #dizionario contenente per ogni immagine una lista di categorie di oggetti presebti\n\n        for annotation in coco_data['annotations']: #uso la sezione annotazioni del file .json per ricavare delle info. sulle immagini del dataset\n            image_id = annotation['image_id']\n            category_id = annotation['category_id'] # lista di category_id = categorie degli oggetti nell'immagine)\n\n            if image_id not in self.image_annotations: #verifico se l'id dell'immagine è già presente nel dizionario\n                self.image_annotations[image_id] = []\n\n            self.image_annotations[image_id].append(category_id)\n\n        self.image_info = {\n            int(generate_id(image['file_name'])): image['file_name']\n            for image in coco_data['images']\n        } #dizionario in cui per ogni nome dell'immagine ottenuta da generate_id(file_name) associa il nome.jpg dell'imagine\n\n        self.base_transform = transforms.Compose([\n            transforms.Resize((320, 320)),\n            transforms.ToTensor(),\n        ]) # trasformazione di base da applicare a tutte le immagini\n\n        # lasciare momentaneamente in caso di aggiornamenti futuri\n        self.aug_transform = transforms.Compose([\n            transforms.Resize((320, 320)),\n            transforms.ToTensor(),\n        ]) # strasformazione per la data agumentation\n\n        self.aug = aug\n\n    def __len__(self): # ritorna il numero di elementi in self.image_paths -> chi è?\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        img_name = os.path.basename(self.image_paths[index]) #prendo il path dell'immagine da self.image_paths in base all'indice fornito\n        img_id = int(img_name.replace('_', '').replace('.jpg', '').replace('img', '')) #ricavo l'id dell'immagine -> non l'ho già fatto nell'init?\n\n        if img_id not in self.image_info: #vedo dal dizionario self.image_info se l'immagine è contenuta nel file COCO\n            raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\n\n        img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell'immagine unendo il path della cartella con il nome.jpg dell'immagine\n        if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\n            raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n\n        image = Image.open(img_path).convert('RGB') #apro l'immagine e ne ricavo le dimensioni\n        #original_width, original_height = image.size\n\n        if self.aug: #se la variabile self.aug è alta allora applico la self.aug_transform altrimenti la self.base_transform _> HA SENSO? LE DUE FUNZIONI SONO = !!\n            image_tensor = self.aug_transform(image)\n        else:\n            image_tensor = self.base_transform(image)\n\n        #POTREBBE ESSERCI UN PROBLEMA NELLA CORRISPONDENZA TRA LABLES E REGION PROPOSALS -> perchè in proposals_tensor non ci sono tutte le region proposals perchè alcune vengono scartate\n        # -> se la corrispondenza è 1 a 1 allora potrebbe convenire dare a _generate_region_proposals(image) sia le labes che l'immagine? -> non è certo perchè\n        # in lables c'è una lista di lable ma non viene specificato dove sono localizzate\n\n        # restituisce un dizionario\n        return {\n            \"regions\": image_tensor  # region proposals elaborate, una lista di tensori che rappresentano regioni candidate per il rilevamento\n        }","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}