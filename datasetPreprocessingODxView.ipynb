{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2571636,"sourceType":"datasetVersion","datasetId":1561333}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Librerie**","metadata":{}},{"cell_type":"code","source":"pip install selectivesearch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:00.471567Z","iopub.execute_input":"2024-12-06T08:01:00.471957Z","iopub.status.idle":"2024-12-06T08:01:14.813498Z","shell.execute_reply.started":"2024-12-06T08:01:00.471912Z","shell.execute_reply":"2024-12-06T08:01:14.812062Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.models as models\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport imageio.v3 as imageio\nfrom torch.utils.data import Dataset, DataLoader\nfrom pathlib import Path\nimport pandas as pd\nimport cv2\nimport shutil\nimport json\nimport yaml\nimport random\nimport time\nfrom tqdm import tqdm\nfrom tqdm.notebook import tqdm_notebook\nimport concurrent.futures\nimport multiprocessing as mp\nfrom PIL import Image, ImageOps\nfrom collections import defaultdict, Counter\nfrom torchvision import transforms\nfrom torchvision.transforms import functional as TF\nimport torch.optim as optim\nimport re\nimport selectivesearch\nimport torch.optim as optim\nfrom torchvision import models\nfrom torchvision.models import AlexNet_Weights\nimport matplotlib.patches as mpatches\nimport torch.nn.functional as F\nfrom sklearn.svm import SVC","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:14.816266Z","iopub.execute_input":"2024-12-06T08:01:14.817145Z","iopub.status.idle":"2024-12-06T08:01:21.265494Z","shell.execute_reply.started":"2024-12-06T08:01:14.817092Z","shell.execute_reply":"2024-12-06T08:01:21.264368Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Dataset Preprocessing**","metadata":{}},{"cell_type":"markdown","source":"Il nostro dataset è xView, un'analisi preliminare del dataset è presente nel [documento](https://medium.com/picterra/the-xview-dataset-and-baseline-results-5ab4a1d0f47f) linkato.\n\n\nQuesto dataset rappresentava il migliore per il benchmarking di visione artificiale satellitare. La documentazione tecnica spiega che i dati sono ottenuti dai satelliti **WorldView-3**, con una distanza di campionamento al suolo uniforme di 0,3 metri. Ciò conferisce una risoluzione più elevata e omogenea rispetto alla maggior parte degli altri dataset satellitari esistenti all'epoca, molti dei quali si basano invece su fotografie aeree. Quest'ultime, infatti, presentano differenze nella distorsione causate dall'angolo di ripresa, poiché sono scattate da velivoli a bassa quota. \n\nIl dataset **xView** offre una copertura geografica ampia e diversificata, includendo anche aree meno sviluppate e urbanizzate, fornendo quindi una maggiore varietà di scenari rispetto a dataset più convenzionali. ","metadata":{}},{"cell_type":"markdown","source":"### Elenco delle categorie del dataset:  \n\n#### 0-3: Velivoli  \n- 0: Fixed-wing Aircraft  \n- 1: Small Aircraft  \n- 2: Passenger/Cargo Plane  \n- 3: Helicopter  \n\n#### 4-15: Veicoli terrestri  \n- 4: Passenger Vehicle  \n- 5: Small Car  \n- 6: Bus  \n- 7: Pickup Truck  \n- 8: Utility Truck  \n- 9: Truck  \n- 10: Cargo Truck  \n- 11: Truck Tractor w/ Box Trailer  \n- 12: Truck Tractor  \n- 13: Trailer  \n- 14: Truck Tractor w/ Flatbed Trailer  \n- 15: Truck Tractor w/ Liquid Tank  \n\n#### 16: Veicoli speciali  \n- 16: Crane Truck  \n\n#### 17-22: Veicoli ferroviari  \n- 17: Railway Vehicle  \n- 18: Passenger Car  \n- 19: Cargo/Container Car  \n- 20: Flat Car  \n- 21: Tank car  \n- 22: Locomotive  \n\n#### 23-32: Imbarcazioni  \n- 23: Maritime Vessel  \n- 24: Motorboat  \n- 25: Sailboat  \n- 26: Tugboat  \n- 27: Barge  \n- 28: Fishing Vessel  \n- 29: Ferry  \n- 30: Yacht  \n- 31: Container Ship  \n- 32: Oil Tanker  \n\n#### 33-45: Veicoli da costruzione/industriali  \n- 33: Engineering Vehicle  \n- 34: Tower crane  \n- 35: Container Crane  \n- 36: Reach Stacker  \n- 37: Straddle Carrier  \n- 38: Mobile Crane  \n- 39: Dump Truck  \n- 40: Haul Truck  \n- 41: Scraper/Tractor  \n- 42: Front loader/Bulldozer  \n- 43: Excavator  \n- 44: Cement Mixer  \n- 45: Ground Grader  \n\n#### 46-51: Edifici e strutture  \n- 46: Hut/Tent  \n- 47: Shed  \n- 48: Building  \n- 49: Aircraft Hangar  \n- 50: Damaged Building  \n- 51: Facility  \n\n#### 52-59: Altre infrastrutture  \n- 52: Construction Site  \n- 53: Vehicle Lot  \n- 54: Helipad  \n- 55: Storage Tank  \n- 56: Shipping container lot  \n- 57: Shipping Container  \n- 58: Pylon  \n- 59: Tower  ","metadata":{}},{"cell_type":"markdown","source":"Utilizziamo un processo di preprocessing per il dataset **xView** seguendo i passi presenti in questo [Notebook (Preprocessing)](https://www.kaggle.com/code/ollypowell/xview-dataset-to-yolo-and-coco-format). L'obiettivo è:\n\n1. **Pulizia e riformattazione**: Si parte dal dataset grezzo e lo si prepara per l'addestramento di modelli di intelligenza artificiale per il rilevamento di oggetti.\n2. **Suddivisione in chunck**: Poiché le immagini satellitari sono molto grandi, vengono suddivise in \"pezzi\" più piccoli (chunck) per facilitare l'elaborazione. I bounding box, che definiscono le posizioni degli oggetti nelle immagini, vengono ridimensionati in modo che corrispondano ai nuovi pezzi.\n3. **Ottimizzazione del formato**: Le immagini TIFF, che occupano molto spazio, vengono convertite in formato JPG, molto più leggero.\n4. **Personalizzazione**: È possibile scegliere la dimensione delle immagini finali e come suddividere i dati per l'addestramento.\n\nQuesto processo riduce significativamente la dimensione del dataset, rendendolo più gestibile, senza sacrificare le informazioni necessarie per l'addestramento di modelli come **YOLOv5**.\n","metadata":{}},{"cell_type":"markdown","source":"Dopo aver analizzato le considerazioni riportate durante l'analisi esplorativa del dataset nel seguente [Notebook (Exploratory Data Analysis)](https://www.kaggle.com/code/ollypowell/xview-1-dataset-eda?scriptVersionId=157247786), abbiamo deciso di apportare alcune modifiche al preprocessing originale descritto nel documento linkato.\n\nIn particolare, abbiamo osservato che circa il 41% delle porzioni (chunk) di immagini con dimensioni comprese tra 600x600 e 640x640 risultavano prive di label. Questo è un problema, poiché il dataset originale è stato costruito raccogliendo immagini contenenti almeno una label. Per migliorare la qualità del dataset, abbiamo scelto di suddividere le immagini originali in chunk più piccoli, di dimensioni 320x320, ed eliminare il 66% delle immagini prive di label. Questo approccio ci ha permesso di ottenere un dataset composto per circa il 70% da immagini contenenti oggetti da identificare e per il 30% da immagini vuote. L'obiettivo è ottenere un training della rete più coerente ed efficace.\n\nInoltre, abbiamo corretto alcuni errori nel preprocessing originale, che impedivano di escludere i chunk con dimensioni inferiori a una certa soglia, errori nei path della working space ed altri.\n\nLa scelta di utilizzare chunk più piccoli si basa sulla considerazione che suddividere le immagini in parti di dimensioni ridotte consente di massimizzare la probabilità di includere tutte le label presenti nel dataset originale. Inoltre, ciò facilita la visualizzazione degli oggetti da individuare, sia per l'algoritmo che per un osservatore umano.\n\nAbbiamo infine deciso di escludere i chunk con dimensioni comprese nell'intervallo [300x300, 320x320), poiché rappresentavano una quantità trascurabile rispetto al totale. Gestirli avrebbe richiesto ulteriori scelte progettuali, come l'applicazione di tecniche di stretching sia sulle immagini sia sulle coordinate geometriche delle label, con un impatto complessivo marginale sull'efficacia del modello.\n\nNel seguente codice sono inoltre presenti molte operazioni di debug e di check per evitare che errori nella fase di preprocessing si ripercuotano sul successivo training.","metadata":{}},{"cell_type":"markdown","source":"## Setup","metadata":{}},{"cell_type":"code","source":"#Data sources\nDATA_FLDR_NM = 'Data'\nIN_DATASET_NM = 'xview-dataset'\nIMAGE_FLDR_NM = 'train_images'\nIN_LABELS_FLDR_NM = 'train_labels'\nLABELS_XML_NM = 'xView_train.geojson'\n\n#Output folders and file names\nOUT_DATASET_NM = 'xview-yolo-dataset'\nCLASS_MAP_JSON_NM = 'xView_class_map.json'\nOUT_COCO_JSON_NM = 'COCO_annotations.json'\nOUT_IMAGE_FLDR_NM = 'images'\nOUT_CFG_FLDR_NM = 'YOLO_cfg'\nOUT_DATAFRAME_NM = 'xview_labels.parquet'\nYAML_NM = 'xview_yolo.yaml'\nCHUNK_WIDTH = 320  # width of the images being created\nCHUNK_HEIGHT = 320\nMIN_CHUNK_HEIGHT = 320 # no images will be kept if the image chunk is smaller than this\nMIN_CHUNK_WIDTH = 320\nIMAGE_WRITING = True #True to re-perform image cropping, False just to regenerated other data\nTEST_FRACTION = 0.1\nJPEG_COMPRESSION = 95 # For the saved files\nVAL_FRACTION = 0.1\nRANDOM_SEED = 2023\nDEBUG = False\n\nin_dataset_pth = Path('/kaggle/input/xview-dataset')\nout_dataset_pth = Path('/kaggle/working/')\nfuture_ds_img_fldr = Path(f'/kaggle/working/{OUT_IMAGE_FLDR_NM}')\nfuture_ds_cfg_fldr = Path(f'/kaggle/working/{OUT_CFG_FLDR_NM}')\n\nlabels_json_pth = in_dataset_pth / IN_LABELS_FLDR_NM / LABELS_XML_NM\nimg_fldr_pth = in_dataset_pth / IMAGE_FLDR_NM / IMAGE_FLDR_NM\nsave_images_fldr_pth = out_dataset_pth / OUT_IMAGE_FLDR_NM \nout_data_parquet_pth = out_dataset_pth / OUT_DATAFRAME_NM\nout_json_map_pth = out_dataset_pth / CLASS_MAP_JSON_NM \nclass_map_pth = out_dataset_pth / CLASS_MAP_JSON_NM\ncfg_fldr_pth = out_dataset_pth / OUT_CFG_FLDR_NM\ncoco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\nyolo_yaml_pth = cfg_fldr_pth / YAML_NM\ntrain_txt_pth = cfg_fldr_pth / 'train.txt'\nval_txt_pth = cfg_fldr_pth / 'val.txt'\ntest_txt_pth = cfg_fldr_pth / 'test.txt'\n\ndef make_empty_dir(directory):\n    if directory.is_dir():\n        shutil.rmtree(directory)\n    os.makedirs(directory)\n\nmake_empty_dir(cfg_fldr_pth)\nif IMAGE_WRITING:\n    make_empty_dir(save_images_fldr_pth)\n\nrandom.seed(RANDOM_SEED)\n\nprint(f'The input images are found at {cfg_fldr_pth}')\nprint(f'The input labels are found at  {labels_json_pth}')\nprint(f'Configuration files will be saved to {cfg_fldr_pth}')\nprint(f'YOLO image files will be saved to {save_images_fldr_pth}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:21.266829Z","iopub.execute_input":"2024-12-06T08:01:21.267286Z","iopub.status.idle":"2024-12-06T08:01:21.279682Z","shell.execute_reply.started":"2024-12-06T08:01:21.267256Z","shell.execute_reply":"2024-12-06T08:01:21.278490Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Helper Functions","metadata":{}},{"cell_type":"code","source":"# Estrae i bounding box da un DataFrame, eventualmente filtrandoli per una lista di classi\ndef get_boxes(in_df, class_lst=[]):\n    if class_lst:\n        in_df = in_df[in_df['TYPE_ID'].isin(class_lst)]     # Filtra il DataFrame per le classi specificate\n    unique_images = in_df.IMAGE_ID.unique().tolist()        # Ottiene una lista unica di ID immagine\n    boxs = {}\n\n    for image in tqdm_notebook(unique_images):\n        mask = in_df['IMAGE_ID'] == image                                  # Seleziona solo le righe relative a una specifica immagine\n        masked = in_df[mask][['TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX']]  # Estrae solo le colonne richieste\n        boxs[image] = masked.values.tolist()                               # Converte i valori in lista e li salva nel dizionario\n    return boxs\n\n\n# Stampa le prime n righe di un file di testo\ndef print_first_n_lines(file_path, n):\n    try:\n        with open(file_path, 'r') as file:\n            for line_num, line in enumerate(file, 1):\n                if line_num > n:                  \n                    break\n                print(line.strip()) \n    except FileNotFoundError:\n        print('Unable to open file')        \n\n\n# Carica un'immagine per la visualizzazione (convertita da BGR a RGB)\ndef load_image(file_pth):\n    image_obj = cv2.imread(file_pth)                        \n    image_obj = cv2.cvtColor(image_obj, cv2.COLOR_BGR2RGB)  \n    return image_obj\n\n\n# Carica un'immagine per la sola elaborazione (BGR)\ndef load_bgr_image(file_pth):\n    image_obj = cv2.imread(file_pth)  \n    return image_obj\n\n\n# Mostra una lista di immagini con i bounding box disegnati sopra\ndef display_images(image_lst, boxes_dictionary, image_fldr, max_images=6, no_cols=1, text=False, class_map={}):\n    total_ims = len(image_lst)\n    display_ims = min(max_images, total_ims)\n    no_rows = display_ims // no_cols + (display_ims % no_cols > 0)                   # Calcola il numero di righe necessarie\n    fig, axs = plt.subplots(no_rows, no_cols, figsize=(10, 10*no_rows/no_cols*3/4))  # Crea il layout della griglia\n    axs = axs.flatten()                                                              # Appiattisce l'array degli assi\n\n    for k, img_nm in enumerate(image_lst[:display_ims]):\n        image_path = str(image_fldr / img_nm)  \n        img = load_image(image_path)  \n\n        # Disegna i bounding box sull'immagine\n        if img_nm in boxes_dictionary:\n            for box in boxes_dictionary[img_nm]:\n                box_id, x_min, y_min, x_max, y_max = box\n                x_min, y_min, x_max, y_max = int(x_min), int(y_max), int(x_max), int(y_min)\n                cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0,255,0), 3)      # Disegna il rettangolo\n                if text:\n                    if class_map:\n                        box_label = class_map[box_id]                                 # Mappa la classe\n                    else:\n                        box_label = str(box_id)\n                    cv2.putText(img, box_label, (x_min, y_max-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (36,255,12), 4)  # Scrive il testo\n\n        axs[k].set_title(f\"Image {img_nm}\", fontsize=12)\n        axs[k].imshow(img)\n        axs[k].set_axis_off()\n\n    plt.tight_layout()\n    plt.show()\n    return\n\n\n# Converte le coordinate YOLO in coordinate per OpenCV ((left, top), (right, bottom))\ndef get_corners(x_cen, y_cen, an_width, an_height, im_width, im_height):\n    x_cen, y_cen, an_width, an_height = float(x_cen), float(y_cen), float(an_width), float(an_height)\n    # Calcolo dei margini\n    left = (x_cen - an_width/2)*im_width            \n    top = (y_cen - an_height/2)*im_height           \n    right = (x_cen + an_width/2)*im_width           \n    bottom = (y_cen + an_height/2)*im_height        \n    return int(left), int(top), int(right), int(bottom)\n\n\n# Mostra immagini con bounding box definiti in formato YOLO\ndef display_yolo_images(image_lst, image_fldr, max_images=6, no_cols=1, text=False, class_map={}):\n    total_ims = len(image_lst)\n    display_ims = min(max_images, total_ims)\n    no_rows = display_ims // no_cols + (display_ims % no_cols > 0)\n    _, axs = plt.subplots(no_rows, no_cols, figsize=(10, 10*no_rows/no_cols*3/4))\n    axs = axs.flatten()\n\n    for k, img_nm in enumerate(image_lst[:display_ims]):\n        image_path = image_fldr / img_nm\n        text_fn = image_path.stem + '.txt'     # Costruisce il nome del file dei bounding box\n        boxes_path = image_fldr / text_fn\n        img = load_image(str(image_path))  \n        im_h, im_w, _ = img.shape  \n        with open(boxes_path) as text_file:\n            annotations = [line.rstrip().split() for line in text_file]  \n\n        # Disegna i bounding box\n        for ann in annotations:\n            class_id = ann[0]\n            x_centre, y_centre, w, h = ann[1], ann[2], ann[3], ann[4]\n            x_min, y_min, x_max, y_max = get_corners(x_centre, y_centre, w, h, im_w, im_h)\n            cv2.rectangle(img, (x_min, y_min), (x_max, y_max), (0,255,0), 3)\n            if text:\n                if class_map:\n                    box_label = class_map[int(class_id)]\n                else:\n                    box_label = str(class_id)\n                cv2.putText(img, box_label, (x_min, y_max-10), cv2.FONT_HERSHEY_SIMPLEX, 2, (36,255,12), 4)\n\n        axs[k].set_title(f\"Image {img_nm}\", fontsize=12)\n        axs[k].imshow(img)\n        axs[k].set_axis_off()\n\n    plt.tight_layout()\n    plt.show()\n    return\n\n\n# Trova i bounding box contenuti in una sezione dell'immagine e li restituisce in formato YOLO\ndef match_boxes(box_list, chnk_lims):\n    boxes_lists = []\n    le, to = chnk_lims[0], chnk_lims[1]                    # Limiti del chunk (left, top)\n    w, h = chnk_lims[2], chnk_lims[3]                      # Larghezza e altezza del chunk\n    for box in box_list:\n        o_left, o_top, o_right, o_bottom = box[1], box[2], box[3], box[4]\n        left, right = (o_left - le)/w, (o_right - le)/w    # Normalizza rispetto ai limiti del chunk\n        top, bottom = (o_top - to)/h, (o_bottom - to)/h\n\n        # Verifica se il bounding box è contenuto nella sezione\n        h_match = (0 <= left < 1) or (0 < right <= 1)\n        v_match = (0 <= top < 1) or (0 < bottom <= 1)\n\n        if v_match and h_match:\n            clipped = np.clip([left, top, right, bottom], a_min=0, a_max=1)  # Clippa i valori tra 0 e 1\n            l, t, r, b = clipped[0], clipped[1], clipped[2], clipped[3]\n            bounding_box = [str(box[0]),\n                            str(round((l + r)/2, 5)),\n                            str(round((t + b)/2, 5)),\n                            str(round(r - l, 5)),\n                            str(round(b - t, 5))]       # Formatta in YOLO\n            boxes_lists.append(bounding_box)\n    return boxes_lists","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:21.282051Z","iopub.execute_input":"2024-12-06T08:01:21.282395Z","iopub.status.idle":"2024-12-06T08:01:21.313176Z","shell.execute_reply.started":"2024-12-06T08:01:21.282364Z","shell.execute_reply":"2024-12-06T08:01:21.311963Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Data Extraction and Cleaning","metadata":{}},{"cell_type":"code","source":"# Apre un file JSON contenente annotazioni e carica i dati\nwith open(labels_json_pth, 'r') as infile:\n    data = json.load(infile)                        # Carica il file JSON in un dizionario\n    keys = list(data.keys())                        # Estrazioni delle chiavi del dizionario\n\n# Estrae la lista delle annotazioni (features) dal JSON\nfeature_list = data['features']\n\n# Definisce le colonne per il DataFrame\nCOLUMNS = ['IMAGE_ID', 'TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX', 'LONG', 'LAT']\n\ndata = []\nfor feature in tqdm_notebook(feature_list):  \n    properties = feature['properties']               # Estrae le proprietà del feature (dizionario)\n    img_id = properties['image_id']                  # Identificativo immagine\n    type_id = properties['type_id']                  # Tipo di oggetto annotato\n    bbox = properties['bounds_imcoords'].split(\",\")  # Coordinate del bounding box\n\n    geometry = feature['geometry']  \n    coords = geometry['coordinates'][0]              # Lista di coordinate (lista di liste)\n\n    # Calcola il punto centrale geografico \n    long = coords[0][0] / 2 + coords[2][0] / 2       # Media delle longitudini dei vertici opposti\n    lat = coords[0][1] / 2 + coords[1][1] / 2        # Media delle latitudini dei vertici opposti\n\n    # Crea una riga con tutte le informazioni rilevanti\n    one_row = [img_id, type_id, bbox[0], bbox[1], bbox[2], bbox[3], long, lat]\n    data.append(one_row)  \n\n# Conta il numero di istanze totali nel dataset\ninstances = len(data)\nprint(f'Ci sono {instances} istanze degli ogetti nel dataset originale')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:21.314409Z","iopub.execute_input":"2024-12-06T08:01:21.314885Z","iopub.status.idle":"2024-12-06T08:01:41.219783Z","shell.execute_reply.started":"2024-12-06T08:01:21.314852Z","shell.execute_reply":"2024-12-06T08:01:41.218684Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Estrazione delle colonne di interesse:","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(data, columns = COLUMNS)\ndf[['XMIN', 'YMIN', 'XMAX', 'YMAX']] = df[['XMIN', 'YMIN', 'XMAX', 'YMAX']].apply(pd.to_numeric)\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:41.221428Z","iopub.execute_input":"2024-12-06T08:01:41.221877Z","iopub.status.idle":"2024-12-06T08:01:43.472829Z","shell.execute_reply.started":"2024-12-06T08:01:41.221819Z","shell.execute_reply":"2024-12-06T08:01:43.471800Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rimozione di 2 annotation errate per le class labels ([EDA](https://www.kaggle.com/code/ollypowell/xview-dataset-eda))","metadata":{}},{"cell_type":"code","source":"df = df[(df.TYPE_ID != 75) & (df.TYPE_ID != 82)]   # removing erroneous labels\nprint(f'{instances - len(df)} rows removed, leaving {len(df)} rows')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:43.474167Z","iopub.execute_input":"2024-12-06T08:01:43.474566Z","iopub.status.idle":"2024-12-06T08:01:43.554219Z","shell.execute_reply.started":"2024-12-06T08:01:43.474495Z","shell.execute_reply":"2024-12-06T08:01:43.553088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:43.555375Z","iopub.execute_input":"2024-12-06T08:01:43.555716Z","iopub.status.idle":"2024-12-06T08:01:43.568389Z","shell.execute_reply.started":"2024-12-06T08:01:43.555684Z","shell.execute_reply":"2024-12-06T08:01:43.567282Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rimozione dell'immagine 1395, poiché inesistente","metadata":{}},{"cell_type":"code","source":"old_length = len(df)\ndf = df[df.IMAGE_ID != '1395.tif']\nprint(f'{old_length - len(df)} rows removed, leaving {len(df)}')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:43.570025Z","iopub.execute_input":"2024-12-06T08:01:43.570348Z","iopub.status.idle":"2024-12-06T08:01:43.742245Z","shell.execute_reply.started":"2024-12-06T08:01:43.570318Z","shell.execute_reply":"2024-12-06T08:01:43.741149Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Inoltre, è utile convertire gli ID dei tipi in una sequenza continua da 0 a 59 per le 60 categorie. Le label originali della competizione non erano organizzate in questo modo. Il dizionario riportato di seguito rappresenta la mappatura originale:","metadata":{}},{"cell_type":"code","source":"old_dict = {\n    11:'Fixed-wing Aircraft', 12:'Small Aircraft', 13:'Passenger/Cargo Plane', 15:'Helicopter',\n    17:'Passenger Vehicle', 18:'Small Car', 19:'Bus', 20:'Pickup Truck', 21:'Utility Truck',\n    23:'Truck', 24:'Cargo Truck', 25:'Truck Tractor w/ Box Trailer', 26:'Truck Tractor',27:'Trailer',\n    28:'Truck Tractor w/ Flatbed Trailer', 29:'Truck Tractor w/ Liquid Tank', 32:'Crane Truck',\n    33:'Railway Vehicle', 34:'Passenger Car', 35:'Cargo/Container Car', 36:'Flat Car', 37:'Tank car',\n    38:'Locomotive', 40:'Maritime Vessel', 41:'Motorboat', 42:'Sailboat', 44:'Tugboat', 45:'Barge',\n    47:'Fishing Vessel', 49:'Ferry', 50:'Yacht', 51:'Container Ship', 52:'Oil Tanker',\n    53:'Engineering Vehicle', 54:'Tower crane', 55:'Container Crane', 56:'Reach Stacker',\n    57:'Straddle Carrier', 59:'Mobile Crane', 60:'Dump Truck', 61:'Haul Truck', 62:'Scraper/Tractor',\n    63:'Front loader/Bulldozer', 64:'Excavator', 65:'Cement Mixer', 66:'Ground Grader', 71:'Hut/Tent',\n    72:'Shed', 73:'Building', 74:'Aircraft Hangar', 76:'Damaged Building', 77:'Facility', 79:'Construction Site',\n    83:'Vehicle Lot', 84:'Helipad', 86:'Storage Tank', 89:'Shipping container lot', 91:'Shipping Container',\n    93:'Pylon', 94:'Tower'}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:43.745724Z","iopub.execute_input":"2024-12-06T08:01:43.746064Z","iopub.status.idle":"2024-12-06T08:01:43.754252Z","shell.execute_reply.started":"2024-12-06T08:01:43.746032Z","shell.execute_reply":"2024-12-06T08:01:43.753030Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Di seguito si aggiorna la mappatura delle label","metadata":{}},{"cell_type":"code","source":"old_keys = sorted(list(old_dict.keys()))\nnew_dict = {old_dict[x]:y for y, x in enumerate(old_keys)}\nclass_map_dict = {y:old_dict[x] for y, x in enumerate(old_keys)}\nwith open(out_json_map_pth, \"w\") as json_file:\n    json.dump(class_map_dict, json_file)\nprint(class_map_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:43.755435Z","iopub.execute_input":"2024-12-06T08:01:43.755836Z","iopub.status.idle":"2024-12-06T08:01:43.774215Z","shell.execute_reply.started":"2024-12-06T08:01:43.755771Z","shell.execute_reply":"2024-12-06T08:01:43.772909Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Ora possiamo convertire i vecchi **TYPE_ID** del dataframe nei loro nuovi valori","metadata":{}},{"cell_type":"code","source":"df['TYPE_ID'] = df['TYPE_ID'].apply(lambda x: new_dict[old_dict[x]])\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:43.775782Z","iopub.execute_input":"2024-12-06T08:01:43.776164Z","iopub.status.idle":"2024-12-06T08:01:44.044827Z","shell.execute_reply.started":"2024-12-06T08:01:43.776132Z","shell.execute_reply":"2024-12-06T08:01:44.043711Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Per verificare che i dati vengano caricati correttamente, visualizziamo alcune immagini con eventuali annotazioni relative ai trasporti","metadata":{}},{"cell_type":"code","source":"all_classes = list(class_map_dict.keys())\ntransport_only = [x for x in all_classes if x < 48]\n\nboxes = get_boxes(df, transport_only)\nimages_for_display = random.choices(list(boxes.keys()), k=2)\ndisplay_images(images_for_display, boxes, img_fldr_pth, max_images=2, no_cols=2, text=True, class_map=class_map_dict) #adjust as desired","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:01:44.046087Z","iopub.execute_input":"2024-12-06T08:01:44.046543Z","iopub.status.idle":"2024-12-06T08:02:21.536169Z","shell.execute_reply.started":"2024-12-06T08:01:44.046475Z","shell.execute_reply":"2024-12-06T08:02:21.535047Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Chunk Processing\n- Suddividere i file TIFF di grandi dimensioni in chunk  \n- Salvare questi chunk come file JPG  \n- Verificare se i chunk contengono annotazioni  \n- Riformattare le annotazioni nel formato YOLO: x_center, y_center, width, height (tutto normalizzato)  \n- Scrivere tutte le annotazioni in formato YOLO in un dizionario, utilizzando il nome del file come chiave  ","metadata":{}},{"cell_type":"code","source":"boxes_dict = get_boxes(df)  # Dizionario: {filename:[['TYPE_ID', 'XMIN', 'YMIN', 'XMAX', 'YMAX'],[..],[..],..]}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:02:21.537368Z","iopub.execute_input":"2024-12-06T08:02:21.537720Z","iopub.status.idle":"2024-12-06T08:03:35.914838Z","shell.execute_reply.started":"2024-12-06T08:02:21.537687Z","shell.execute_reply":"2024-12-06T08:03:35.913796Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_image(img_fn, \n                  dir_pth=img_fldr_pth, \n                  boxes=boxes_dict, \n                  out_dir=save_images_fldr_pth, \n                  c_height=CHUNK_HEIGHT, \n                  c_width=CHUNK_WIDTH,  \n                  jpg_q=JPEG_COMPRESSION,\n                  min_h=MIN_CHUNK_HEIGHT,\n                  min_w=MIN_CHUNK_WIDTH,\n                  writing=IMAGE_WRITING\n                 ):\n    \"\"\"\n    Suddivide un'immagine in piccoli chunk, salva i chunk in formato JPEG e converte le annotazioni in formato YOLO.\n\n    Args:\n        img_fn (str): Nome del file immagine da processare.\n        dir_pth (Path): Percorso della directory contenente le immagini di input.\n        boxes (dict): Dizionario che associa ogni immagine a una lista di annotazioni.\n        out_dir (Path): Percorso della directory dove salvare i chunk generati.\n        c_height (int): Altezza dei chunk da creare.\n        c_width (int): Larghezza dei chunk da creare.\n        jpg_q (int): Qualità di compressione JPEG (valore da 0 a 100).\n        min_h (int): Altezza minima per considerare un chunk valido.\n        min_w (int): Larghezza minima per considerare un chunk valido.\n        writing (bool): Se True, salva i chunk generati come file JPEG.\n\n    Returns:\n        tuple: Una tupla contenente:\n            - f_names (list): Lista dei nomi dei file dei chunk generati.\n            - widths (list): Lista delle larghezze dei chunk generati.\n            - heights (list): Lista delle altezze dei chunk generati.\n            - y_boxes (dict): Dizionario che associa i file dei chunk alle annotazioni in formato YOLO.\n    \"\"\"\n    \n    labels_list = boxes[img_fn]\n    img_pth = str(dir_pth / img_fn)\n    im = load_bgr_image(img_pth)\n    full_h, full_w, _ = im.shape\n    y_boxes= {}\n    f_names, widths, heights = [], [], []\n    \n    for r in range(0, full_h, c_height):\n        for c in range(0, full_w, c_width):\n            stem = img_fn.split('.')[0]\n            fn = str(f\"img_{stem}_{r}_{c}.jpg\")\n            out_pth = str(out_dir / fn)\n            width = c_width\n            height = c_height\n            if r + height > full_h:\n                height = full_h - r\n            if c + width > full_w:\n                width = full_w - c\n            big_enough = (height >= min_h) and (width >= min_w)\n            if big_enough:\n                if writing:\n                    cv2.imwrite(out_pth, im[r:r+height, c:c+height,:],  [int(cv2.IMWRITE_JPEG_QUALITY), jpg_q])\n                # Find any boxes occurring in the chunk, and convert to YOLO format\n                chunk_limits = [c, r, width, height]\n                y_boxes[fn] = match_boxes(labels_list, chunk_limits)\n                f_names.append(fn)\n                widths.append(width)\n                heights.append(height)\n    return f_names, widths, heights, y_boxes","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:03:35.916306Z","iopub.execute_input":"2024-12-06T08:03:35.916766Z","iopub.status.idle":"2024-12-06T08:03:35.928673Z","shell.execute_reply.started":"2024-12-06T08:03:35.916720Z","shell.execute_reply":"2024-12-06T08:03:35.927327Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img_fns = df.IMAGE_ID.unique().tolist()\nif DEBUG:\n    img_fns = img_fns[:len(img_fns)//120]\n    df = df[df['IMAGE_ID'].isin(img_fns)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:03:35.930251Z","iopub.execute_input":"2024-12-06T08:03:35.930612Z","iopub.status.idle":"2024-12-06T08:03:36.076634Z","shell.execute_reply.started":"2024-12-06T08:03:35.930572Z","shell.execute_reply":"2024-12-06T08:03:36.075503Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"start_time = time.time()\nnum_threads = mp.cpu_count() \noverall_progress = tqdm_notebook(total=len(img_fns), desc=\"Creating and saving image tiles\")\nyolo_boxes= {}\nfile_names, widths, heights = [], [], []\n\nwith concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n    for f_names, c_widths, c_heights, y_boxes in executor.map(process_image, img_fns):\n        file_names.extend(f_names)\n        widths.extend(c_widths)\n        heights.extend(c_heights)\n        yolo_boxes.update(y_boxes)\n        overall_progress.update(1)\noverall_progress.close()\n\nimage_data = {file_names[i]: [widths[i], heights[i]] for i in range(len(file_names))}\ntime_taken=time.time() - start_time","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:03:36.077729Z","iopub.execute_input":"2024-12-06T08:03:36.078005Z","iopub.status.idle":"2024-12-06T08:06:02.635903Z","shell.execute_reply.started":"2024-12-06T08:03:36.077978Z","shell.execute_reply":"2024-12-06T08:06:02.634494Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## YOLO text files\nIterare attraverso il dizionario, creando un file di testo per ogni immagine con il formato: **classe x y larghezza altezza**, quindi salvare il file di testo completato nella stessa posizione, con lo stesso nome base dell'immagine.","metadata":{}},{"cell_type":"code","source":"all_image_files = os.listdir(save_images_fldr_pth)\nfor image_fn in tqdm_notebook(all_image_files):\n    stem = image_fn.split('.')[0]\n    fn = str (stem) + '.txt'\n    txt_pth = str(save_images_fldr_pth / fn)\n    seperator = ' '\n    with open(txt_pth, 'a') as f:\n        if image_fn in yolo_boxes:\n            for bbox in yolo_boxes[image_fn]:\n                txt = seperator.join(bbox) + '\\n'\n                f.write(txt)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:06:02.637543Z","iopub.execute_input":"2024-12-06T08:06:02.638171Z","iopub.status.idle":"2024-12-06T08:06:07.940831Z","shell.execute_reply.started":"2024-12-06T08:06:02.638132Z","shell.execute_reply":"2024-12-06T08:06:07.939653Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"txt_files = [file for file in os.listdir(save_images_fldr_pth) if file.endswith('.txt')]\nnum_txt_files = len(txt_files)\nprint(f\"Numero di file .txt: {num_txt_files}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:06:07.942560Z","iopub.execute_input":"2024-12-06T08:06:07.943016Z","iopub.status.idle":"2024-12-06T08:06:08.073434Z","shell.execute_reply.started":"2024-12-06T08:06:07.942967Z","shell.execute_reply":"2024-12-06T08:06:08.072351Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"images_with_boxes = [image_fn for image_fn in all_image_files if image_fn in yolo_boxes]\nprint(f\"Numero di immagini con dati in yolo_boxes: {len(images_with_boxes)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:06:08.074951Z","iopub.execute_input":"2024-12-06T08:06:08.075376Z","iopub.status.idle":"2024-12-06T08:06:08.109207Z","shell.execute_reply.started":"2024-12-06T08:06:08.075330Z","shell.execute_reply":"2024-12-06T08:06:08.107900Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"text_paths = [save_images_fldr_pth / x for x in os.listdir(save_images_fldr_pth) if x.endswith(\".txt\")]\ncolumn_names = ['Class_ID', 'x_center', 'y_center', 'width', 'height']\ndata = []\nfor file_path in text_paths:\n    with open(file_path, 'r') as file:\n        for line in file:\n            values = line.strip().split(' ')\n            row_data = {col: val for col, val in zip(column_names, values)}\n            row_data['File_Name'] = file_path.name\n            data.append(row_data)\n\nout_df = pd.DataFrame(data)\nout_df['Class_ID']=out_df['Class_ID'].astype(int)\nout_df['Class_Name'] = out_df['Class_ID'].map(class_map_dict).fillna('unknown')\nout_df = out_df[['File_Name', 'Class_Name', 'Class_ID', 'x_center', 'y_center', 'width', 'height']]\nout_df.to_parquet(out_data_parquet_pth, index=False)\nout_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:06:08.110507Z","iopub.execute_input":"2024-12-06T08:06:08.110935Z","iopub.status.idle":"2024-12-06T08:06:14.886120Z","shell.execute_reply.started":"2024-12-06T08:06:08.110901Z","shell.execute_reply":"2024-12-06T08:06:14.884829Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Rimozione del 66% delle immagini senza label","metadata":{}},{"cell_type":"code","source":"def remove_empty(image_folder, yolo_boxes, image_data):\n    \"\"\"\n    Rimuove il 66% dei file di annotazione vuoti (.txt) e le immagini corrispondenti.\n    Aggiorna anche i dizionari yolo_boxes e image_data per rimuovere le voci corrispondenti.\n    \n    Args:\n        image_folder (str): Percorso della cartella contenente immagini e file .txt.\n        yolo_boxes (dict): Dizionario con annotazioni YOLO.\n        image_data (dict): Dizionario con metadati delle immagini.\n        file_names (list): Lista di nomi file immagine.\n        widths (list): Lista di larghezze delle immagini.\n        heights (list): Lista di altezze delle immagini.\n    \n    Returns:\n        tuple: Dizionari aggiornati (yolo_boxes, image_data, file_names, widths, heights).\n    \"\"\"\n    all_image_files = set(os.listdir(image_folder))  # Set per confronti più veloci\n    empty_files = [] \n\n    # Controlla i file .txt per annotazioni vuote\n    for txt_file in all_image_files:\n        if txt_file.endswith('.txt'):\n            txt_path = os.path.join(image_folder, txt_file)\n            # Controlla se il file è vuoto o contiene solo spazi\n            with open(txt_path, 'r') as file:\n                content = file.read().strip()\n            if not content:  \n                # Determina il file immagine corrispondente\n                image_file = txt_file.replace('.txt', '.jpg')  \n                empty_files.append(image_file)  # Aggiungi immagine alla lista dei file vuoti\n\n    # Seleziona il 66% dei file vuoti da rimuovere\n    num_to_remove = int(len(empty_files) * 0.66)\n    files_to_remove = random.sample(empty_files, num_to_remove)\n\n    # Rimuovi i file .txt e immagini corrispondenti\n    for image_file in files_to_remove:\n        txt_file = image_file.replace('.jpg', '.txt')  \n        txt_path = os.path.join(image_folder, txt_file)\n        image_path = os.path.join(image_folder, image_file)\n\n        if os.path.exists(txt_path):\n            os.remove(txt_path)\n        if os.path.exists(image_path):\n            os.remove(image_path)\n\n    # Aggiorna yolo_boxes eliminando i file rimossi\n    yolo_boxes = {key: value for key, value in yolo_boxes.items() if key not in files_to_remove}\n\n    # Aggiorna image_data eliminando i file rimossi\n    image_data = {key: value for key, value in image_data.items() if key not in files_to_remove}\n\n    # Filtra le liste per escludere i file da rimuovere\n    filtered_file_names = [name for name in file_names if name not in files_to_remove]\n    filtered_widths = [widths[i] for i in range(len(file_names)) if file_names[i] not in files_to_remove]\n    filtered_heights = [heights[i] for i in range(len(file_names)) if file_names[i] not in files_to_remove]\n\n    return yolo_boxes, image_data, filtered_file_names, filtered_widths, filtered_heights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:06:14.888020Z","iopub.execute_input":"2024-12-06T08:06:14.888503Z","iopub.status.idle":"2024-12-06T08:06:14.901838Z","shell.execute_reply.started":"2024-12-06T08:06:14.888454Z","shell.execute_reply":"2024-12-06T08:06:14.900683Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yolo_boxes, image_data, filtered_file_names, filtered_widths, filtered_heights = remove_empty(save_images_fldr_pth, yolo_boxes, image_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:06:14.903167Z","iopub.execute_input":"2024-12-06T08:06:14.903499Z","iopub.status.idle":"2024-12-06T08:09:17.865132Z","shell.execute_reply.started":"2024-12-06T08:06:14.903469Z","shell.execute_reply":"2024-12-06T08:09:17.863981Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verifica il numero di file .txt nel folder\ntxt_files = [f for f in os.listdir(save_images_fldr_pth) if f.endswith('.txt')]\nprint(f\"Numero di file .txt nel folder: {len(txt_files)}\")\n# Conta il numero di file immagine (per esempio file .jpg)\nimage_files = [f for f in os.listdir(save_images_fldr_pth) if f.endswith('.jpg')]\nnum_images = len(image_files)\nprint(f\"Numero di immagini nel folder: {num_images}\")\nimages_with_boxes = [image_fn for image_fn in all_image_files if image_fn in yolo_boxes]\nprint(f\"Numero di immagini con dati in yolo_boxes: {len(images_with_boxes)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:17.866831Z","iopub.execute_input":"2024-12-06T08:09:17.867285Z","iopub.status.idle":"2024-12-06T08:09:18.054828Z","shell.execute_reply.started":"2024-12-06T08:09:17.867239Z","shell.execute_reply":"2024-12-06T08:09:18.053757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from itertools import islice\n\n# Stampa i primi 5 elementi\nfor key, value in islice(image_data.items(), 5):\n    print(f\"{key}: {value}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:18.056103Z","iopub.execute_input":"2024-12-06T08:09:18.056417Z","iopub.status.idle":"2024-12-06T08:09:18.061916Z","shell.execute_reply.started":"2024-12-06T08:09:18.056387Z","shell.execute_reply":"2024-12-06T08:09:18.060795Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_file_names = len(image_data) # Il numero di chiavi corrisponde al numero di file_names (per ora)\nnum_widths = len([value[0] for value in image_data.values()])  # Conta tutte le larghezze\nnum_heights = len([value[1] for value in image_data.values()])  # Conta tutte le altezze\n\nprint(f\"Il numero di immagini uniche è: {num_file_names}\")\nprint(f\"Il numero di larghezze registrate è: {num_widths}\")\nprint(f\"Il numero di altezze registrate è: {num_heights}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:18.063180Z","iopub.execute_input":"2024-12-06T08:09:18.064023Z","iopub.status.idle":"2024-12-06T08:09:18.083258Z","shell.execute_reply.started":"2024-12-06T08:09:18.063991Z","shell.execute_reply":"2024-12-06T08:09:18.081927Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"filenames = [x for x in os.listdir(save_images_fldr_pth) if x.endswith(\".jpg\")]\nimage_list = random.choices(filenames, k=4)\ndisplay_yolo_images(image_list, save_images_fldr_pth, max_images=4, no_cols=2, text=True,  class_map=class_map_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:18.084620Z","iopub.execute_input":"2024-12-06T08:09:18.084961Z","iopub.status.idle":"2024-12-06T08:09:19.001622Z","shell.execute_reply.started":"2024-12-06T08:09:18.084931Z","shell.execute_reply":"2024-12-06T08:09:19.000393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#without text labels\nfilenames = [x for x in os.listdir(save_images_fldr_pth) if x.endswith(\".jpg\")]\nimage_list = random.choices(filenames, k=4)\ndisplay_yolo_images(image_list, save_images_fldr_pth, max_images=4, no_cols=2, text=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:19.009267Z","iopub.execute_input":"2024-12-06T08:09:19.009679Z","iopub.status.idle":"2024-12-06T08:09:19.841748Z","shell.execute_reply.started":"2024-12-06T08:09:19.009643Z","shell.execute_reply":"2024-12-06T08:09:19.840612Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting","metadata":{}},{"cell_type":"code","source":"total_images = len(filenames)\nindices = list(range(total_images))\nrandom.shuffle(indices)\n\ntrain_fraction = 1 - TEST_FRACTION - VAL_FRACTION\ntrain_sp = int(np.floor(train_fraction * len(indices))) # The training-validation split\nvalid_sp = int(np.floor(VAL_FRACTION * len(indices))) + train_sp # The validation-test split\ntrain_idx, val_idx, test_idx = indices[:train_sp], indices[train_sp:valid_sp], indices[valid_sp:]\n\nprint(' Training set size: \\t', len(train_idx))\nprint(' Validation set size: \\t', len(val_idx))\nprint(' Test set size: \\t', len(test_idx))\nprint(' Total dataset: \\t', total_images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:19.843264Z","iopub.execute_input":"2024-12-06T08:09:19.843690Z","iopub.status.idle":"2024-12-06T08:09:19.890481Z","shell.execute_reply.started":"2024-12-06T08:09:19.843647Z","shell.execute_reply":"2024-12-06T08:09:19.889455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Write 3 text files into the Data folder with the file paths: train.txt, val.txt, test.txt  These are lists of absolute filepaths to the images, one line each path.  They can reside anywhere just so long as the relative paths in xview_yolo.yaml points to them.","metadata":{}},{"cell_type":"code","source":"files = ['train.txt', 'val.txt', 'test.txt']\nsplits = [train_idx, val_idx, test_idx]\n\nfor fn, split in zip(files, splits):\n    txt_pth = cfg_fldr_pth / fn\n    with open(txt_pth, 'a') as f:\n        for ind in split:\n            f.write(str(future_ds_img_fldr / filenames[ind]) + '\\n')\n        print(f'{fn[:-4]} file written to {txt_pth}, with {len(split) } samples')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:19.891752Z","iopub.execute_input":"2024-12-06T08:09:19.892072Z","iopub.status.idle":"2024-12-06T08:09:20.153652Z","shell.execute_reply.started":"2024-12-06T08:09:19.892042Z","shell.execute_reply":"2024-12-06T08:09:20.152591Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## YAML File\nWrite a .yaml file pointing to the text file locations, and determining class names, number of categories location.\nThis is good practice, it means I don't need to move all the image files around just to change the training splits.\nAlso the .yml file gets updated automatically if anybody changes something like the number of classes.","metadata":{}},{"cell_type":"code","source":"config = {'train': str(future_ds_cfg_fldr / files[0]),\n          'val': str(future_ds_cfg_fldr / files[1]),\n          'test': str(future_ds_cfg_fldr / files[2]),\n          'nc': len(class_map_dict),\n          'names': class_map_dict\n          }\n\nwith open(yolo_yaml_pth, \"w\") as file:\n    yaml.dump(config, file, default_style=None, default_flow_style=False, sort_keys=False)\nprint(f'yaml file written to {yolo_yaml_pth}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.154936Z","iopub.execute_input":"2024-12-06T08:09:20.155255Z","iopub.status.idle":"2024-12-06T08:09:20.168696Z","shell.execute_reply.started":"2024-12-06T08:09:20.155224Z","shell.execute_reply":"2024-12-06T08:09:20.167329Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Splitting Check\nJust checking the first few lines of the train.txt file","metadata":{}},{"cell_type":"code","source":"for split in ['train', 'val', 'test']:\n    print(f'{split} text file')\n    print_first_n_lines(cfg_fldr_pth / f'{split}.txt', 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.170374Z","iopub.execute_input":"2024-12-06T08:09:20.170821Z","iopub.status.idle":"2024-12-06T08:09:20.190265Z","shell.execute_reply.started":"2024-12-06T08:09:20.170761Z","shell.execute_reply":"2024-12-06T08:09:20.189006Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And the .yaml file","metadata":{}},{"cell_type":"code","source":"print_first_n_lines(yolo_yaml_pth, 10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.191742Z","iopub.execute_input":"2024-12-06T08:09:20.192159Z","iopub.status.idle":"2024-12-06T08:09:20.204067Z","shell.execute_reply.started":"2024-12-06T08:09:20.192115Z","shell.execute_reply":"2024-12-06T08:09:20.202925Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And a couple of annotations files","metadata":{}},{"cell_type":"code","source":"txt_fnames = [save_images_fldr_pth / x for x in os.listdir(save_images_fldr_pth) if x.endswith(\".txt\")]\ntext_list = random.choices(txt_fnames, k=2)\nprint(text_list)\nfor text_f in text_list:\n    print(f'Reading {text_f}')\n    print_first_n_lines(text_f, 3)  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.205752Z","iopub.execute_input":"2024-12-06T08:09:20.206211Z","iopub.status.idle":"2024-12-06T08:09:20.470124Z","shell.execute_reply.started":"2024-12-06T08:09:20.206164Z","shell.execute_reply":"2024-12-06T08:09:20.468955Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(text_list)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.471402Z","iopub.execute_input":"2024-12-06T08:09:20.471764Z","iopub.status.idle":"2024-12-06T08:09:20.477366Z","shell.execute_reply.started":"2024-12-06T08:09:20.471731Z","shell.execute_reply":"2024-12-06T08:09:20.476263Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And the csv file","metadata":{}},{"cell_type":"code","source":"out_data = pd.read_parquet(out_data_parquet_pth)\nout_data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.478657Z","iopub.execute_input":"2024-12-06T08:09:20.478978Z","iopub.status.idle":"2024-12-06T08:09:20.766662Z","shell.execute_reply.started":"2024-12-06T08:09:20.478947Z","shell.execute_reply":"2024-12-06T08:09:20.765616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Conta il numero di immagini con nomi unici\nnum_immagini_uniche = out_data['File_Name'].nunique()\nprint(f\"Il numero di immagini uniche è: {num_immagini_uniche}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.767963Z","iopub.execute_input":"2024-12-06T08:09:20.768262Z","iopub.status.idle":"2024-12-06T08:09:20.830692Z","shell.execute_reply.started":"2024-12-06T08:09:20.768235Z","shell.execute_reply":"2024-12-06T08:09:20.829578Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"And the `.json`","metadata":{}},{"cell_type":"code","source":"with open(out_json_map_pth, \"r\") as json_file:\n    loaded_dict = json.load(json_file)\nprint(loaded_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.831903Z","iopub.execute_input":"2024-12-06T08:09:20.832205Z","iopub.status.idle":"2024-12-06T08:09:20.845057Z","shell.execute_reply.started":"2024-12-06T08:09:20.832176Z","shell.execute_reply":"2024-12-06T08:09:20.844042Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## YOLO to COCO\n\nPoiché non richiede molto sforzo in questo momento, riformatterò il dataframe nella geometria del formato COCO e scriverò un file `.json` in formato COCO per coloro che necessitano di tale formato. Il formato COCO è spiegato [qui](https://cocodataset.org/#format-data). A livello superiore, abbiamo principalmente bisogno di questi tre oggetti:\n\n- **images:**  \n  `{\"id\": int, \"width\": int, \"height\": int, \"file_name\": str, }`  \n\n- **annotations:**  \n  `{\"id\": int, \"image_id\": int, \"category_id\": int, \"area\": float, \"bbox\": [x, y, width, height]}`  \n\n- **categories:**  \n  `[{\"id\": int, \"name\": str}]`","metadata":{}},{"cell_type":"markdown","source":"Copiamo il DataFrame YOLO, per estrarre le larghezze delle immagini e creare la categoria BBox","metadata":{}},{"cell_type":"code","source":"num_file_names = len(image_data) # Il numero di chiavi corrisponde al numero di file_names (per ora)\nnum_widths = len([value[0] for value in image_data.values()])  # Conta tutte le larghezze\nnum_heights = len([value[1] for value in image_data.values()])  # Conta tutte le altezze\n\nprint(f\"Il numero di immagini uniche è: {num_file_names}\")\nprint(f\"Il numero di larghezze registrate è: {num_widths}\")\nprint(f\"Il numero di altezze registrate è: {num_heights}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.846432Z","iopub.execute_input":"2024-12-06T08:09:20.846955Z","iopub.status.idle":"2024-12-06T08:09:20.859803Z","shell.execute_reply.started":"2024-12-06T08:09:20.846920Z","shell.execute_reply":"2024-12-06T08:09:20.858623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_data = {'width': filtered_widths, 'height': filtered_heights, 'file_name': filtered_file_names} # Ricreo il dizionario con 3 chiavi ma utilizzando le liste filtraten dopo l'eliminazione fatta prima\nim_df = pd.DataFrame(image_data)\nim_df['id'] = im_df['file_name'].str.replace(r'\\D', '', regex=True).astype(int)\nim_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:20.861031Z","iopub.execute_input":"2024-12-06T08:09:20.861323Z","iopub.status.idle":"2024-12-06T08:09:21.030540Z","shell.execute_reply.started":"2024-12-06T08:09:20.861294Z","shell.execute_reply":"2024-12-06T08:09:21.029443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_file_names = len(image_data['file_name'])  # Numero di file rimanenti\nnum_widths = len(image_data['width'])         # Numero di larghezze rimanenti\nnum_heights = len(image_data['height'])       # Numero di altezze rimanenti\n\nprint(f\"Il numero di immagini uniche è: {num_file_names}\")\nprint(f\"Il numero di larghezze registrate è: {num_widths}\")\nprint(f\"Il numero di altezze registrate è: {num_heights}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:21.032128Z","iopub.execute_input":"2024-12-06T08:09:21.032578Z","iopub.status.idle":"2024-12-06T08:09:21.039378Z","shell.execute_reply.started":"2024-12-06T08:09:21.032514Z","shell.execute_reply":"2024-12-06T08:09:21.038331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_images_in_im_df = len(im_df)\nprint(f\"Numero di immagini in im_df: {num_images_in_im_df}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:21.041106Z","iopub.execute_input":"2024-12-06T08:09:21.041611Z","iopub.status.idle":"2024-12-06T08:09:21.057492Z","shell.execute_reply.started":"2024-12-06T08:09:21.041565Z","shell.execute_reply":"2024-12-06T08:09:21.056370Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def row_to_dict(row):\n    return {\n        'id': row['id'],\n        'width': row['width'],\n        'height':row['height'],\n        'file_name':row['file_name']\n    }\n\nim_list = im_df.apply(lambda row: row_to_dict(row), axis=1).tolist()\n[print(val) for val in im_list[:4]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:21.058854Z","iopub.execute_input":"2024-12-06T08:09:21.059217Z","iopub.status.idle":"2024-12-06T08:09:21.688436Z","shell.execute_reply.started":"2024-12-06T08:09:21.059173Z","shell.execute_reply":"2024-12-06T08:09:21.687356Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Merge the images dataframe with the annotations to work out the absolute pixel values, plus a bit more re-organising.","metadata":{}},{"cell_type":"code","source":"annotations_df = out_data.copy()\nannotations_df['image_id'] = annotations_df['File_Name'].str.replace(r'\\D', '', regex=True).astype(int)\nannotations_df= annotations_df.rename(columns={'height': 'h', 'width': 'w'})\nan_df = annotations_df.merge(im_df, left_on='image_id', right_on='id', how='left')\nan_df['x_center']= (an_df['x_center'].astype(np.float64)*an_df['width']).round(decimals=0)\nan_df['y_center']= (an_df['y_center'].astype(np.float64)*an_df['height']).round(decimals=0)\nan_df['w']= (an_df['w'].astype(np.float64)*an_df['width']).round(decimals=0)\nan_df['h']= (an_df['h'].astype(np.float64)*an_df['height']).round(decimals=0)\nan_df['Class_ID']= an_df['Class_ID'].astype(int)\nan_df = an_df.drop(columns=['File_Name', 'file_name', 'width', 'height', 'id'])\nan_df['left'] = (an_df['x_center'] - an_df['w']/2).round(decimals=0)\nan_df['top'] =  (an_df['y_center'] - an_df['h']/2).round(decimals=0)\nan_df['bbox'] = ('[' + an_df['left'].astype(str) + ', ' \n              + an_df['top'].astype(str) + ', ' \n              + an_df['w'].astype(str) + ', '\n              + an_df['h'].astype(str) + ']')\nan_df['area'] = an_df['w'] * an_df['h']\nan_df = an_df.drop(columns=['x_center', 'y_center', 'w', 'h', 'left', 'top', 'Class_Name'])\nan_df.reset_index(inplace=True)\nan_df.rename(columns={'index': 'id'}, inplace=True)\nan_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:21.689802Z","iopub.execute_input":"2024-12-06T08:09:21.690199Z","iopub.status.idle":"2024-12-06T08:09:26.219634Z","shell.execute_reply.started":"2024-12-06T08:09:21.690167Z","shell.execute_reply":"2024-12-06T08:09:26.218451Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def row_to_dict(row):\n    return {\n        'id': row['id'],\n        'image_id' : row['image_id'],\n        'category_id': row['Class_ID'],\n        'area':row['area'],\n        'bbox':row['bbox']\n    }\n\nan_list = an_df.apply(lambda row: row_to_dict(row), axis=1).tolist()\nprint(an_list[:4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:26.220899Z","iopub.execute_input":"2024-12-06T08:09:26.221224Z","iopub.status.idle":"2024-12-06T08:09:36.960918Z","shell.execute_reply.started":"2024-12-06T08:09:26.221194Z","shell.execute_reply":"2024-12-06T08:09:36.959464Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The category mapping is just about in a convenient format already","metadata":{}},{"cell_type":"code","source":"cat_list = [{key:val} for key,val in class_map_dict.items()]\nprint(cat_list[:4])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:36.962452Z","iopub.execute_input":"2024-12-06T08:09:36.962932Z","iopub.status.idle":"2024-12-06T08:09:36.981261Z","shell.execute_reply.started":"2024-12-06T08:09:36.962883Z","shell.execute_reply":"2024-12-06T08:09:36.979828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now I just need to combine the top level objects, and save to `.json`","metadata":{}},{"cell_type":"code","source":"out_json_data = {'images': im_list, 'annotations': an_list, 'categories': cat_list}\nwith open(coco_json_pth, 'w') as json_file:\n    json.dump(out_json_data, json_file, indent=4)\n    \nfor key, value in out_json_data.items():\n    print(key, value[:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:36.982720Z","iopub.execute_input":"2024-12-06T08:09:36.983113Z","iopub.status.idle":"2024-12-06T08:09:44.132438Z","shell.execute_reply.started":"2024-12-06T08:09:36.983062Z","shell.execute_reply":"2024-12-06T08:09:44.131400Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Image Sizes","metadata":{}},{"cell_type":"code","source":"def check_image_sizes(directory_path):\n    size_counts = defaultdict(int)\n\n    # Ottieni la lista dei file nella cartella\n    files = [f for f in os.listdir(directory_path) if f.endswith(('.jpg'))]\n\n    # Aggiungi una barra di progresso per iterare sui file\n    for filename in tqdm(files, desc=\"Processing images\"):\n        img_path = os.path.join(directory_path, filename)\n        with Image.open(img_path) as img:\n            size = img.size  # (width, height)\n            size_counts[size] += 1\n\n    # Crea gruppi per le dimensioni richieste\n    size_groups = {\n        'Smaller than 320x320': [],\n        '320x320': [],\n        'Larger than 320x320': [],\n    }\n\n    # Aggiungi le dimensioni agli appropriate gruppi\n    for size, count in size_counts.items():\n        width, height = size\n        if width < 320 and height < 320:\n            size_groups['Smaller than 320x320'].append((size, count))\n        elif width == 320 and height == 320:\n            size_groups['320x320'].append((size, count))\n        elif width > 320 and height > 320:\n            size_groups['Larger than 320x320'].append((size, count))\n\n    # Ordina le dimensioni per area (larghezza * altezza) in ordine decrescente\n    for group, items in size_groups.items():\n        sorted_items = sorted(items, key=lambda x: x[0][0] * x[0][1], reverse=True)  # ordina per area\n        size_groups[group] = sorted_items\n\n    # Stampa i gruppi con il numero di immagini per dimensione e il totale per intervallo\n    for group, items in size_groups.items():\n        total = sum(count for _, count in items)\n        print(f\"{group} (Totale: {total} immagini):\")\n        for size, count in items:\n            print(f\"  Dimensione {size}: {count} immagini\")\n        print()\n\n# Esegui la funzione con il percorso della cartella\ncheck_image_sizes(save_images_fldr_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:09:44.133939Z","iopub.execute_input":"2024-12-06T08:09:44.134269Z","iopub.status.idle":"2024-12-06T08:10:01.805698Z","shell.execute_reply.started":"2024-12-06T08:09:44.134238Z","shell.execute_reply":"2024-12-06T08:10:01.804530Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open(coco_json_pth, 'r') as f:\n    coco_data = json.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:10:01.807194Z","iopub.execute_input":"2024-12-06T08:10:01.807572Z","iopub.status.idle":"2024-12-06T08:10:03.447464Z","shell.execute_reply.started":"2024-12-06T08:10:01.807499Z","shell.execute_reply":"2024-12-06T08:10:03.446128Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def check_image_size(image, img_id, coco_data):\n    # Trova le dimensioni dell'immagine nel JSON\n    image_info = next((img for img in coco_data['images'] if img['id'] == img_id), None)\n    if image_info:\n        width, height = image_info['width'], image_info['height']\n        img_width, img_height = image.size\n        # Lancia un'eccezione solo se le dimensioni non corrispondono\n        assert img_width == width and img_height == height, (\n            f\"Dimensioni errate: JSON ({width}, {height}), immagine ({img_width}, {img_height})\"\n        )\n    else:\n        raise ValueError(f\"Immagine con ID {img_id} non trovata nel JSON.\")\n\ndef check_all_images(folder_path, coco_data):\n    folder_path = Path(folder_path)\n    errors_found = False  # Flag per tenere traccia degli errori\n    check_count = 0  # Conta il numero di immagini verificate\n    \n    # Itera attraverso tutti i file nella cartella\n    for image_path in folder_path.iterdir():\n        if image_path.is_file() and image_path.suffix in ['.jpg']:  # Controlla solo file immagine\n            check_count += 1  # Incrementa il contatore delle immagini\n            # Trova l'ID corrispondente basato sul nome file\n            img_id = int(''.join(filter(str.isdigit, image_path.stem)))  # Estrae i numeri dal nome\n            try:\n                with Image.open(image_path) as img:\n                    check_image_size(img, img_id, coco_data)\n            except (AssertionError, ValueError) as e:\n                errors_found = True\n                print(f\"Errore per immagine {image_path.name}: {e}\")\n            except Exception as e:\n                errors_found = True\n                print(f\"Errore generico per immagine {image_path.name}: {e}\")\n\n    # Stampa il risultato finale\n    if not errors_found:\n        print(f\"Check completato, nessun errore trovato. Numero di immagini verificate: {check_count}\")\n    else:\n        print(f\"Check completato con errori. Numero di immagini verificate: {check_count}\")\n\n# Percorso alla directory delle immagini\ncheck_all_images(save_images_fldr_pth, coco_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:10:03.448972Z","iopub.execute_input":"2024-12-06T08:10:03.449294Z","iopub.status.idle":"2024-12-06T08:11:31.486073Z","shell.execute_reply.started":"2024-12-06T08:10:03.449265Z","shell.execute_reply":"2024-12-06T08:11:31.484939Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Check Labels","metadata":{}},{"cell_type":"code","source":"def check_empty_txt_files(directory_path):\n    # Ottieni tutti i file .txt nella cartella\n    txt_files = [f for f in os.listdir(directory_path) if f.endswith(\".txt\")]\n    \n    empty_files_count = 0\n    total_lines = 0\n    non_empty_files_count = 0\n    \n    # Controlla se ogni file è vuoto\n    for txt_file in txt_files:\n        file_path = os.path.join(directory_path, txt_file)\n        if os.path.getsize(file_path) == 0:\n            empty_files_count += 1\n        else:\n            non_empty_files_count += 1\n            with open(file_path, 'r') as f:\n                lines = f.readlines()\n                total_lines += len(lines)\n    \n    # Calcola la media delle righe per i file non vuoti\n    avg_lines = total_lines / non_empty_files_count if non_empty_files_count > 0 else 0\n    \n    # Stampa il numero di file vuoti e la media delle righe nei file non vuoti\n    print(f\"Numero di file .txt vuoti: {empty_files_count}\")\n    print(f\"Numero di file .txt non vuoti: {non_empty_files_count}\")\n    print(f\"Media delle righe per file non vuoto: {avg_lines:.2f}\")\n\ncheck_empty_txt_files(save_images_fldr_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:11:31.487427Z","iopub.execute_input":"2024-12-06T08:11:31.487762Z","iopub.status.idle":"2024-12-06T08:11:32.914371Z","shell.execute_reply.started":"2024-12-06T08:11:31.487732Z","shell.execute_reply":"2024-12-06T08:11:32.913280Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Category Distribution","metadata":{}},{"cell_type":"code","source":"with open(coco_json_pth, 'r') as f:\n    coco_data = json.load(f)\n\n# Crea un dizionario per mappare category_id a categoria\ncategory_mapping = {str(index): list(category.values())[0] for index, category in enumerate(coco_data['categories'])}\n\n# Estrai i category_id dalle annotazioni\ncategory_ids = [annotation['category_id'] for annotation in coco_data['annotations']]\n\n# Conta le occorrenze di ogni category_id\ncategory_counts = Counter(category_ids)\n\n# Gruppi delle categorie\ncategory_groups = {\n    \"Aircraft\": [0, 1, 2, 3],\n    \"Passenger Vehicle\": [4, 5, 6, 53],\n    \"Truck\": [7, 8, 9, 10, 11, 12, 13, 14, 15],\n    \"Railway Vehicle\": [17, 18, 19, 20, 21, 22],\n    \"Maritime Vessel\": [23, 24, 25, 26, 27, 28, 29, 30, 31, 32],\n    \"Engineering Vehicle\": [16, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45],\n    \"Building\": [46, 47, 48, 49, 50, 51, 52, 59],\n    \"Helipad\": [54],\n    \"Storage Tank\": [55],\n    \"Shipping Container\": [56, 57],\n    \"Pylon\": [58],\n}\n\n# Crea un dizionario per le categorie aggregate con le loro occorrenze\ngrouped_occurrences = {}\nfor group_name, category_ids in category_groups.items():\n    # Somma le occorrenze per le categorie di ogni gruppo\n    grouped_occurrences[group_name] = sum(category_counts[cat_id] for cat_id in category_ids)\n\n# Ordina le categorie raggruppate per occorrenze in ordine decrescente\ngrouped_occurrences = dict(sorted(grouped_occurrences.items(), key=lambda item: item[1], reverse=True))\n\n# Prepara i dati per il grafico\ngroups = list(grouped_occurrences.keys())\noccurrences = list(grouped_occurrences.values())\n\n\n# Crea il grafico a barre\nplt.figure(figsize=(10, 6))\nplt.barh(groups, occurrences, color='skyblue')\nplt.xlabel('Numero di Occorrenze')\nplt.ylabel('Gruppi di Categoria')\nplt.title('Distribuzione delle Occorrenze per Gruppo di Categoria')\nplt.tight_layout()\n\n# Mostra il grafico\nplt.show()\n\n# Stampare le occorrenze per ciascun group e i relativi ID\nsorted_groups = sorted(category_groups.items(), key=lambda item: sum(category_counts.get(cat_id, 0) for cat_id in item[1]))\n\nfor group, category_ids in sorted_groups:\n    # Calcola il numero totale di occorrenze per il gruppo\n    total_count = sum(category_counts.get(cat_id, 0) for cat_id in category_ids)\n    \n    print(f\"Gruppo: {group}, Occorrenze Totali: {total_count}\")\n    \n    for cat_id in category_ids:\n        category_name = category_mapping[str(cat_id)]\n        count = category_counts.get(cat_id, 0)\n        print(f\"  category_id: {cat_id}, Categoria: {category_name}, Occorrenze: {count}\")\n    \n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:11:32.915870Z","iopub.execute_input":"2024-12-06T08:11:32.916209Z","iopub.status.idle":"2024-12-06T08:11:35.145689Z","shell.execute_reply.started":"2024-12-06T08:11:32.916178Z","shell.execute_reply":"2024-12-06T08:11:35.144662Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"new_coco_json_pth = out_dataset_pth / 'COCO_annotations_new.json'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:11:35.146963Z","iopub.execute_input":"2024-12-06T08:11:35.147268Z","iopub.status.idle":"2024-12-06T08:11:35.152181Z","shell.execute_reply.started":"2024-12-06T08:11:35.147238Z","shell.execute_reply":"2024-12-06T08:11:35.151045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Carica il file COCO originale\nwith open(coco_json_pth, 'r') as f:\n    coco_data = json.load(f)\n\n# Creare nuove categorie nel formato richiesto\nnew_categories = [{str(idx): group} for idx, group in enumerate(category_groups.keys())]\n\n# Mappatura inversa dei gruppi (vecchio category_id -> nuovo group_id)\ngroup_mapping = {}\nfor group_id, (group_name, category_ids) in enumerate(category_groups.items(), start=0):\n    for cat_id in category_ids:\n        group_mapping[cat_id] = group_id\n\n# Aggiorna i category_id nelle annotazioni\nfor annotation in coco_data[\"annotations\"]:\n    original_id = annotation[\"category_id\"]\n    annotation[\"category_id\"] = group_mapping.get(original_id, -1)  # Usa -1 per eventuali category_id non mappati\n\n# Verifica annotazioni non mappate\nunmapped = [ann for ann in coco_data[\"annotations\"] if ann[\"category_id\"] == -1]\nif unmapped:\n    print(f\"Attenzione: {len(unmapped)} annotazioni con category_id non mappati.\")\n\n# Aggiorna il dizionario delle categorie\ncoco_data[\"categories\"] = new_categories\n\n# Salva il file COCO modificato\nnew_coco_json_pth = Path(out_dataset_pth) / 'COCO_annotations_new.json'\nwith open(new_coco_json_pth, \"w\") as f:\n    json.dump(coco_data, f, indent=4)\n\nprint(f\"File COCO modificato salvato in {new_coco_json_pth}.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:11:35.153409Z","iopub.execute_input":"2024-12-06T08:11:35.153801Z","iopub.status.idle":"2024-12-06T08:11:44.124219Z","shell.execute_reply.started":"2024-12-06T08:11:35.153768Z","shell.execute_reply":"2024-12-06T08:11:44.123069Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Carica il file COCO modificato\nwith open(new_coco_json_pth, 'r') as f:\n    coco_data = json.load(f)\n\n# Crea un dizionario per mappare category_id a nome della categoria dal nuovo formato\ncategory_mapping = {\n    int(list(category.keys())[0]): list(category.values())[0]\n    for category in coco_data[\"categories\"]\n}\n\n# Estrai i category_id dalle annotazioni\ncategory_ids = [annotation[\"category_id\"] for annotation in coco_data[\"annotations\"]]\n\n# Conta le occorrenze di ogni category_id\ncategory_counts = Counter(category_ids)\n\n# Associa i nomi delle categorie alle loro occorrenze\ncategory_occurrences = {\n    cat_id: (category_mapping[cat_id], count)\n    for cat_id, count in category_counts.items()\n    if cat_id in category_mapping\n}\n\n# Ordina le categorie per occorrenze in ordine decrescente\ncategory_occurrences = dict(sorted(category_occurrences.items(), key=lambda item: item[1][1], reverse=True))\n\n# Prepara i dati per il grafico\ncategories = [f\"{cat_id} - {name}\" for cat_id, (name, _) in category_occurrences.items()]\noccurrences = [count for _, (_, count) in category_occurrences.items()]\n\n# Crea il grafico a barre\nplt.figure(figsize=(10, 8))\nplt.barh(categories, occurrences, color=\"skyblue\")\nplt.xlabel(\"Numero di Occorrenze\")\nplt.ylabel(\"Categorie\")\nplt.title(\"Distribuzione delle Occorrenze per Categoria\")\nplt.tight_layout()\n\n# Mostra il grafico\nplt.show()\n\n# Stampa le occorrenze per ogni categoria con ID\nfor cat_id, (name, count) in category_occurrences.items():\n    print(f\"Categoria ID: {cat_id}, Nome: {name}, Occorrenze: {count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:11:44.125907Z","iopub.execute_input":"2024-12-06T08:11:44.126364Z","iopub.status.idle":"2024-12-06T08:11:46.314438Z","shell.execute_reply.started":"2024-12-06T08:11:44.126317Z","shell.execute_reply":"2024-12-06T08:11:46.313420Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import zipfile\nimport os\n\nworking_dir = \"/kaggle/working\"\n\n# Nome del file zip da creare\nzip_file_name = \"our-xview-dataset.zip\"\n\n# Elenco di file e cartelle da includere nello zip\nitems_to_zip = [\n    \"COCO_annotations.json\",\n    \"YOLO_cfg\",  # Cartella\n    \"images\",    # Cartella\n    \"xView_class_map.json\",\n    \"xview_labels.parquet\"\n]\n\n# Funzione per aggiungere file e cartelle allo zip\ndef zip_folder(zipf, folder_path, base_folder=\"\"):\n    for root, _, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            arcname = os.path.relpath(file_path, base_folder)\n            zipf.write(file_path, arcname)\n\n# Creazione dello zip\nwith zipfile.ZipFile(zip_file_name, 'w', compression=zipfile.ZIP_DEFLATED) as zipf:\n    for item in items_to_zip:\n        if os.path.exists(item):  # Verifica che il file o la cartella esista\n            if os.path.isdir(item):  # Se è una cartella, aggiungi tutto il contenuto\n                zip_folder(zipf, item, working_dir)\n            else:  # Se è un file, aggiungilo direttamente\n                zipf.write(item)\n        else:\n            print(f\"Elemento non trovato: {item}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:52:01.181864Z","iopub.execute_input":"2024-12-06T08:52:01.182350Z","iopub.status.idle":"2024-12-06T08:53:12.175733Z","shell.execute_reply.started":"2024-12-06T08:52:01.182317Z","shell.execute_reply":"2024-12-06T08:53:12.174377Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Directory da pulire\nworking_dir = \"/kaggle/working\"\n\n# Nome del file da escludere\nexclude_file = \"our-xview-dataset.zip\"\n\n# Scorri tutti gli elementi nella directory\nfor item_name in os.listdir(working_dir):\n    item_path = os.path.join(working_dir, item_name)\n    \n    # Controlla se è un file e non è quello da escludere\n    if os.path.isfile(item_path) and item_name != exclude_file:\n        os.remove(item_path)\n        print(f\"Eliminato file: {item_path}\")\n    \n    # Controlla se è una directory e la elimina\n    elif os.path.isdir(item_path):\n        shutil.rmtree(item_path)\n        print(f\"Eliminata cartella: {item_path}\")\n\nprint(\"Pulizia completata!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-06T08:57:36.227360Z","iopub.execute_input":"2024-12-06T08:57:36.227785Z","iopub.status.idle":"2024-12-06T08:57:39.805043Z","shell.execute_reply.started":"2024-12-06T08:57:36.227752Z","shell.execute_reply":"2024-12-06T08:57:39.803599Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# **Modelli**\nModelli scelti:\n* [R-CNN con backbone AlexNet](https://medium.com/@selfouly/r-cnn-3a9beddfd55a)\n* [SPPNet con backbone ZF-5](https://arxiv.org/pdf/1406.4729)\n* [Faster R-CNN con backbone ResNet50](https://medium.com/@fractal.ai/guide-to-build-faster-rcnn-in-pytorch-42d47cb0ecd3)","metadata":{}}]}