{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10118002,"sourceType":"datasetVersion","datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"pip install --upgrade pip setuptools","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T03:43:36.789185Z","iopub.execute_input":"2024-12-11T03:43:36.791067Z","iopub.status.idle":"2024-12-11T03:44:00.485934Z","shell.execute_reply.started":"2024-12-11T03:43:36.791026Z","shell.execute_reply":"2024-12-11T03:44:00.484992Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (24.0)\nCollecting pip\n  Downloading pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (70.0.0)\nCollecting setuptools\n  Downloading setuptools-75.6.0-py3-none-any.whl.metadata (6.7 kB)\nDownloading pip-24.3.1-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading setuptools-75.6.0-py3-none-any.whl (1.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: setuptools, pip\n  Attempting uninstall: setuptools\n    Found existing installation: setuptools 70.0.0\n    Uninstalling setuptools-70.0.0:\n      Successfully uninstalled setuptools-70.0.0\n  Attempting uninstall: pip\n    Found existing installation: pip 24.0\n    Uninstalling pip-24.0:\n      Successfully uninstalled pip-24.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nconda 24.5.0 requires packaging>=23.0, but you have packaging 21.3 which is incompatible.\njupyterlab 4.3.1 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nthinc 8.3.2 requires numpy<2.1.0,>=2.0.0; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed pip-24.3.1 setuptools-75.6.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Librerie standard\nimport os\nimport random\nimport time\nimport re\nimport shutil\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nfrom itertools import islice\nfrom concurrent.futures import ProcessPoolExecutor\n\n# Librerie per il trattamento delle immagini\nimport cv2\nimport imageio.v3 as imageio\nfrom PIL import Image, ImageOps\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\n\n# Librerie per il machine learning e deep learning\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as func\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn\nfrom torchvision.transforms import functional as TF\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Librerie per la gestione dei dati\nimport pandas as pd\nimport json\nimport orjson\nimport ast\n\n# Librerie per il progresso e il monitoraggio\nfrom tqdm import tqdm\n\nimport warnings\n\nfrom collections import defaultdict\nfrom sklearn.metrics import accuracy_score\nimport torch\nimport torch.optim as optim\nfrom torch.amp import GradScaler, autocast\nfrom torchmetrics.detection.mean_ap import MeanAveragePrecision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:38.118783Z","iopub.execute_input":"2024-12-11T09:24:38.119629Z","iopub.status.idle":"2024-12-11T09:24:38.126498Z","shell.execute_reply.started":"2024-12-11T09:24:38.119585Z","shell.execute_reply":"2024-12-11T09:24:38.125525Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"#Output folders and file names\nCOCO_JSON_NM = 'COCO_annotations_new.json'\nOUT_COCO_JSON_NM = 'mod_COCO_annotations_new.json'\nOUT_IMAGE_FLDR_NM = 'images'\nOUT_CFG_FLDR_NM = 'YOLO_cfg'\nRANDOM_SEED = 2023\n\nin_dataset_pth = Path('/kaggle/input/our-xview-dataset')\nout_dataset_pth = Path('/kaggle/working/')\nimg_fldr = Path(f'/kaggle/input/our-xview-dataset/{OUT_IMAGE_FLDR_NM}')\ncfg_fldr_pth = Path(f'/kaggle/input/our-xview-dataset/{OUT_CFG_FLDR_NM}')\n\ncoco_json_pth = in_dataset_pth / COCO_JSON_NM\nnew_coco_json_pth = out_dataset_pth / OUT_COCO_JSON_NM\ntrain_txt_pth = cfg_fldr_pth / 'train.txt'\nval_txt_pth = cfg_fldr_pth / 'val.txt'\ntest_txt_pth = cfg_fldr_pth / 'test.txt'\n\n#DATASET\ntrain_path = '/kaggle/working/train.json'\ntest_path = '/kaggle/working/test.json'\nval_path = '/kaggle/working/val.json'\n\nrandom.seed(RANDOM_SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:38.127338Z","iopub.execute_input":"2024-12-11T09:24:38.127652Z","iopub.status.idle":"2024-12-11T09:24:38.145607Z","shell.execute_reply.started":"2024-12-11T09:24:38.127613Z","shell.execute_reply":"2024-12-11T09:24:38.144851Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Pulizia dell'output per cartelle specifiche\ndef clean_output(output_dir):\n    if output_dir.exists() and output_dir.is_dir():\n        for item in output_dir.iterdir():\n            if item.is_dir():\n                shutil.rmtree(item)  # Rimuove la sotto-cartella\n            else:\n                item.unlink()  # Rimuove il file\n        print(f\"Cartella {output_dir} pulita.\")\n    else:\n        print(f\"Cartella {output_dir} non trovata. Nessuna azione necessaria.\")\n\n# Pulisce la cartella di output prima di avviare il processo\nclean_output(out_dataset_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:38.147261Z","iopub.execute_input":"2024-12-11T09:24:38.147611Z","iopub.status.idle":"2024-12-11T09:24:38.161074Z","shell.execute_reply.started":"2024-12-11T09:24:38.147574Z","shell.execute_reply":"2024-12-11T09:24:38.160398Z"}},"outputs":[{"name":"stdout","text":"Cartella /kaggle/working pulita.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Sopprime i warning specifici del modulo skimage\nwarnings.filterwarnings(\"ignore\", \n    message=\"Applying `local_binary_pattern` to floating-point images may give unexpected results.*\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:38.871882Z","iopub.execute_input":"2024-12-11T09:24:38.872559Z","iopub.status.idle":"2024-12-11T09:24:38.877142Z","shell.execute_reply.started":"2024-12-11T09:24:38.872523Z","shell.execute_reply":"2024-12-11T09:24:38.876146Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Background Labels","metadata":{}},{"cell_type":"code","source":"def process_custom_coco_json(input_path, output_path):\n    \"\"\"\n    Funzione per processare un JSON COCO in formato personalizzato.\n    \"\"\"\n    # Leggi il JSON dal file di input\n    with open(input_path, 'r') as f:\n        data = json.load(f)\n\n    # Ottieni e correggi il formato delle categorie\n    raw_categories = data.get('categories', [])\n    categories = []\n\n    for category in tqdm(raw_categories, desc=\"Processing Categories\"):\n        for id_str, name in category.items():\n            try:\n                categories.append({\"id\": int(id_str), \"name\": name})\n            except ValueError:\n                print(f\"Errore nel parsing della categoria: {category}\")\n\n    # Trova la categoria \"Aircraft\" con ID 0\n    aircraft_category = next((cat for cat in categories if cat['id'] == 0 and cat['name'] == \"Aircraft\"), None)\n    if aircraft_category:\n        aircraft_category['id'] = 11  # Cambia l'ID della categoria \"Aircraft\" a 11\n\n    # Aggiungi la categoria \"background\" con ID 0 se non esiste\n    if not any(cat['id'] == 0 for cat in categories):\n        categories.append({\"id\": 0, \"name\": \"background\"})\n\n    # Preprocessa le annotazioni in un dizionario per immagini\n    image_annotations_dict = {}\n    for annotation in tqdm(data.get('annotations', []), desc=\"Building Image Annotations Dictionary\"):\n        image_id = annotation['image_id']\n        if image_id not in image_annotations_dict:\n            image_annotations_dict[image_id] = []\n        image_annotations_dict[image_id].append(annotation)\n\n    # Lista di nuove annotazioni da aggiungere per immagini senza bbox\n    new_annotations = []\n\n    # Elenco di annotazioni da rimuovere\n    annotations_to_remove = []\n\n    for annotation in tqdm(data.get('annotations', []), desc=\"Processing Annotations\"):\n        if annotation['category_id'] == 0:  # Se è Aircraft\n            annotation['category_id'] = 11\n        \n        # Converte il formato del bbox\n        if isinstance(annotation['bbox'], str):\n            annotation['bbox'] = json.loads(annotation['bbox'])\n        \n        x, y, width, height = annotation['bbox']\n        xmin = x\n        xmax = x + width\n        ymin = y\n        ymax = y + height\n        \n        # Verifica che xmin < xmax e ymin < ymax\n        if xmin >= xmax or ymin >= ymax:\n            annotations_to_remove.append(annotation['id'])\n        else:\n            annotation['bbox'] = [xmin, xmax, ymin, ymax]\n\n    # Rimuovi le annotazioni non valide\n    data['annotations'] = [ann for ann in data['annotations'] if ann['id'] not in annotations_to_remove]\n\n    # Verifica se ci sono immagini senza annotazioni (usando il dizionario delle annotazioni)\n    for image in tqdm(data.get('images', []), desc=\"Processing Images\"):\n        if image['id'] not in image_annotations_dict:  # Se l'immagine non ha annotazioni\n            # Aggiungi la categoria \"background\"\n            new_annotation = {\n                'id': len(data['annotations']) + len(new_annotations),\n                'image_id': image['id'],\n                'category_id': 0,  # Categoria background con ID 0\n                'area': image['width'] * image['height'],\n                'bbox': [0.0, image['width'], 0.0, image['height']],  # Background con bbox che copre tutta l'immagine\n                'iscrowd': 0\n            }\n            new_annotations.append(new_annotation)\n\n    # Aggiungi le nuove annotazioni al JSON originale\n    data['annotations'].extend(new_annotations)\n\n    # Aggiorna le categorie nel JSON\n    data['categories'] = categories\n\n    # Scrivi il JSON modificato nel file di output\n    with open(output_path, 'w') as f:\n        json.dump(data, f, indent=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:41.691868Z","iopub.execute_input":"2024-12-11T09:24:41.692173Z","iopub.status.idle":"2024-12-11T09:24:41.704083Z","shell.execute_reply.started":"2024-12-11T09:24:41.692146Z","shell.execute_reply":"2024-12-11T09:24:41.703236Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"process_custom_coco_json(coco_json_pth, new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:43.243878Z","iopub.execute_input":"2024-12-11T09:24:43.244517Z","iopub.status.idle":"2024-12-11T09:24:58.524943Z","shell.execute_reply.started":"2024-12-11T09:24:43.244481Z","shell.execute_reply":"2024-12-11T09:24:58.523974Z"}},"outputs":[{"name":"stderr","text":"Processing Categories: 100%|██████████| 11/11 [00:00<00:00, 89761.37it/s]\nBuilding Image Annotations Dictionary: 100%|██████████| 670213/670213 [00:00<00:00, 2446103.72it/s]\nProcessing Annotations: 100%|██████████| 670213/670213 [00:03<00:00, 194994.47it/s]\nProcessing Images: 100%|██████████| 45891/45891 [00:00<00:00, 847384.31it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def count_bboxes_per_category(json_path):\n    \"\"\"\n    Funzione che conta il numero di bounding box per ciascuna categoria in un file JSON formato COCO.\n    \n    :param json_path: Percorso al file JSON.\n    :return: Dizionario con i nomi delle categorie come chiavi e il conteggio dei bounding box come valori.\n    \"\"\"\n    # Leggi il JSON dal file\n    with open(json_path, 'r') as f:\n        data = json.load(f)\n    \n    # Ottieni mapping delle categorie (id -> nome)\n    category_mapping = {cat['id']: cat['name'] for cat in data.get('categories', [])}\n    \n    # Conta i bounding box per ciascun category_id\n    bbox_counts = defaultdict(int)\n    for annotation in data.get('annotations', []):\n        category_id = annotation['category_id']\n        bbox_counts[category_id] += 1\n    \n    # Converti il conteggio usando i nomi delle categorie\n    bbox_counts_named = {category_mapping[cat_id]: count for cat_id, count in bbox_counts.items()}\n\n    return bbox_counts_named","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:58.526426Z","iopub.execute_input":"2024-12-11T09:24:58.526708Z","iopub.status.idle":"2024-12-11T09:24:58.532293Z","shell.execute_reply.started":"2024-12-11T09:24:58.526681Z","shell.execute_reply":"2024-12-11T09:24:58.531409Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"bbox_counts = count_bboxes_per_category(new_coco_json_pth)\n\n# Stampa i risultati\nfor category, count in bbox_counts.items():\n    print(f\"Categoria: {category}, Numero di bbox: {count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:24:58.533273Z","iopub.execute_input":"2024-12-11T09:24:58.533658Z","iopub.status.idle":"2024-12-11T09:25:01.934731Z","shell.execute_reply.started":"2024-12-11T09:24:58.533615Z","shell.execute_reply":"2024-12-11T09:25:01.933821Z"}},"outputs":[{"name":"stdout","text":"Categoria: Building, Numero di bbox: 384942\nCategoria: Passenger Vehicle, Numero di bbox: 225097\nCategoria: Railway Vehicle, Numero di bbox: 4233\nCategoria: Truck, Numero di bbox: 34377\nCategoria: Aircraft, Numero di bbox: 1708\nCategoria: Engineering Vehicle, Numero di bbox: 5473\nCategoria: Storage Tank, Numero di bbox: 2033\nCategoria: Shipping Container, Numero di bbox: 5391\nCategoria: Maritime Vessel, Numero di bbox: 6329\nCategoria: Pylon, Numero di bbox: 470\nCategoria: Helipad, Numero di bbox: 152\nCategoria: background, Numero di bbox: 13692\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Splitting","metadata":{}},{"cell_type":"code","source":"def split(json_file, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1):\n    # Carica il JSON\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    \n    # Ottieni la lista delle immagini\n    images = data['images']\n    \n    # Mescola casualmente gli ID delle immagini\n    random.shuffle(images)\n    \n    # Calcola i limiti per train, validation, e test\n    total_images = len(images)\n    total_annotations = len(data['annotations'])\n    train_end = int(total_images * train_ratio)\n    val_end = int(total_images * (train_ratio + val_ratio))\n    \n    # Suddividi le immagini nei rispettivi set\n    train_images = images[:train_end]\n    val_images = images[train_end:val_end]\n    test_images = images[val_end:]\n    \n    # Raggruppa gli ID delle immagini per i rispettivi set\n    train_image_ids = {image['id'] for image in train_images}\n    val_image_ids = {image['id'] for image in val_images}\n    test_image_ids = {image['id'] for image in test_images}\n    \n    # Filtra le annotazioni per i rispettivi set di immagini\n    train_annotations = []\n    val_annotations = []\n    test_annotations = []\n    \n    for annotation in data['annotations']:\n        if annotation['image_id'] in train_image_ids:\n            train_annotations.append(annotation)\n        elif annotation['image_id'] in val_image_ids:\n            val_annotations.append(annotation)\n        elif annotation['image_id'] in test_image_ids:\n            test_annotations.append(annotation)\n    \n    # Crea i nuovi JSON per train, validation, e test\n    train_data = {'images': train_images, 'annotations': train_annotations, 'categories': data['categories']}\n    val_data = {'images': val_images, 'annotations': val_annotations, 'categories': data['categories']}\n    test_data = {'images': test_images, 'annotations': test_annotations, 'categories': data['categories']}\n    \n    # Salva i file JSON\n    with open('train.json', 'w') as f:\n        json.dump(train_data, f, indent=4)\n    \n    with open('val.json', 'w') as f:\n        json.dump(val_data, f, indent=4)\n    \n    with open('test.json', 'w') as f:\n        json.dump(test_data, f, indent=4)\n    \n    # Controlla la proporzione delle immagini e delle annotazioni\n    check_split_proportions(total_images, total_annotations, len(train_images), len(val_images), len(test_images), \n                            len(train_annotations), len(val_annotations), len(test_annotations), \n                            train_ratio, val_ratio, test_ratio, train_annotations, val_annotations, test_annotations, data['categories'])\n\n\ndef check_split_proportions(total_images, total_annotations, train_count, val_count, test_count, \n                            train_bbox_count, val_bbox_count, test_bbox_count, \n                            train_ratio, val_ratio, test_ratio, \n                            train_annotations, val_annotations, test_annotations, categories):\n    # Percentuali per immagini\n    train_image_percentage = (train_count / total_images) * 100\n    val_image_percentage = (val_count / total_images) * 100\n    test_image_percentage = (test_count / total_images) * 100\n    \n    # Percentuali per bbox\n    train_bbox_percentage = (train_bbox_count / total_annotations) * 100\n    val_bbox_percentage = (val_bbox_count / total_annotations) * 100\n    test_bbox_percentage = (test_bbox_count / total_annotations) * 100\n    \n    print(f\"Totale immagini: {total_images}\")\n    print(f\"Totale annotazioni (bbox): {total_annotations}\")\n    print(f\"Train: {train_count} immagini ({train_image_percentage:.2f}%) ({train_bbox_count} bbox) ({train_bbox_percentage:.2f}%)\")\n    print(f\"Val: {val_count} immagini ({val_image_percentage:.2f}%) ({val_bbox_count} bbox) ({val_bbox_percentage:.2f}%)\")\n    print(f\"Test: {test_count} immagini ({test_image_percentage:.2f}%) ({test_bbox_count} bbox) ({test_bbox_percentage:.2f}%)\")\n    \n    # Calcola il numero di annotazioni per categoria nei vari set\n    category_count_train = defaultdict(int)\n    category_count_val = defaultdict(int)\n    category_count_test = defaultdict(int)\n    \n    for annotation in train_annotations:\n        category_count_train[annotation['category_id']] += 1\n    for annotation in val_annotations:\n        category_count_val[annotation['category_id']] += 1\n    for annotation in test_annotations:\n        category_count_test[annotation['category_id']] += 1\n    \n    # Stampa le proporzioni per categoria\n    print(\"\\nProporzioni per categoria:\")\n    for category in categories:\n        category_id = category['id']\n        category_name = category['name']\n        \n        # Conta il numero di annotazioni per categoria in ogni set\n        train_cat_count = category_count_train.get(category_id, 0)\n        val_cat_count = category_count_val.get(category_id, 0)\n        test_cat_count = category_count_test.get(category_id, 0)\n        \n        # Calcola la percentuale di annotazioni per categoria\n        total_cat_annotations = train_cat_count + val_cat_count + test_cat_count\n        if total_cat_annotations > 0:\n            train_cat_percentage = (train_cat_count / total_cat_annotations) * 100\n            val_cat_percentage = (val_cat_count / total_cat_annotations) * 100\n            test_cat_percentage = (test_cat_count / total_cat_annotations) * 100\n        else:\n            train_cat_percentage = val_cat_percentage = test_cat_percentage = 0.0\n        \n        print(f\"{category_name}:\")\n        print(f\"  Train: {train_cat_count} annotazioni ({train_cat_percentage:.2f}%)\")\n        print(f\"  Val: {val_cat_count} annotazioni ({val_cat_percentage:.2f}%)\")\n        print(f\"  Test: {test_cat_count} annotazioni ({test_cat_percentage:.2f}%)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:25:01.936510Z","iopub.execute_input":"2024-12-11T09:25:01.936792Z","iopub.status.idle":"2024-12-11T09:25:01.951207Z","shell.execute_reply.started":"2024-12-11T09:25:01.936765Z","shell.execute_reply":"2024-12-11T09:25:01.950389Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Chiamata della funzione\nsplit(new_coco_json_pth)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:25:01.952287Z","iopub.execute_input":"2024-12-11T09:25:01.952610Z","iopub.status.idle":"2024-12-11T09:25:14.713086Z","shell.execute_reply.started":"2024-12-11T09:25:01.952583Z","shell.execute_reply":"2024-12-11T09:25:14.712256Z"}},"outputs":[{"name":"stdout","text":"Totale immagini: 45891\nTotale annotazioni (bbox): 683897\nTrain: 36712 immagini (80.00%) (544927 bbox) (79.68%)\nVal: 4589 immagini (10.00%) (67281 bbox) (9.84%)\nTest: 4590 immagini (10.00%) (71689 bbox) (10.48%)\n\nProporzioni per categoria:\nAircraft:\n  Train: 1335 annotazioni (78.16%)\n  Val: 194 annotazioni (11.36%)\n  Test: 179 annotazioni (10.48%)\nPassenger Vehicle:\n  Train: 177753 annotazioni (78.97%)\n  Val: 23340 annotazioni (10.37%)\n  Test: 24004 annotazioni (10.66%)\nTruck:\n  Train: 27410 annotazioni (79.73%)\n  Val: 3489 annotazioni (10.15%)\n  Test: 3478 annotazioni (10.12%)\nRailway Vehicle:\n  Train: 3248 annotazioni (76.73%)\n  Val: 525 annotazioni (12.40%)\n  Test: 460 annotazioni (10.87%)\nMaritime Vessel:\n  Train: 5131 annotazioni (81.07%)\n  Val: 570 annotazioni (9.01%)\n  Test: 628 annotazioni (9.92%)\nEngineering Vehicle:\n  Train: 4379 annotazioni (80.01%)\n  Val: 526 annotazioni (9.61%)\n  Test: 568 annotazioni (10.38%)\nBuilding:\n  Train: 308131 annotazioni (80.05%)\n  Val: 36460 annotazioni (9.47%)\n  Test: 40351 annotazioni (10.48%)\nHelipad:\n  Train: 124 annotazioni (81.58%)\n  Val: 15 annotazioni (9.87%)\n  Test: 13 annotazioni (8.55%)\nStorage Tank:\n  Train: 1640 annotazioni (80.67%)\n  Val: 216 annotazioni (10.62%)\n  Test: 177 annotazioni (8.71%)\nShipping Container:\n  Train: 4402 annotazioni (81.65%)\n  Val: 527 annotazioni (9.78%)\n  Test: 462 annotazioni (8.57%)\nPylon:\n  Train: 382 annotazioni (81.28%)\n  Val: 52 annotazioni (11.06%)\n  Test: 36 annotazioni (7.66%)\nbackground:\n  Train: 10992 annotazioni (80.28%)\n  Val: 1367 annotazioni (9.98%)\n  Test: 1333 annotazioni (9.74%)\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, coco_json_file, img_dir, aug=False):\n        \"\"\"\n        Inizializza il dataset personalizzato.\n        Args:\n        - coco_json_file: Il file JSON contenente le annotazioni.\n        - img_dir: La cartella delle immagini.\n        - aug: Booleano per attivare o meno l'augmentazione.\n        \"\"\"\n        # Carica il file JSON delle annotazioni\n        with open(coco_json_file, 'r') as f:\n            coco_data = json.load(f)\n\n        # Crea una struttura per le annotazioni\n        self.image_annotations = {}\n        self.image_bboxes = {}\n\n        # Estrai le classi (categorie) dal file JSON\n        self.classes = {}\n        for category in coco_data['categories']:\n            self.classes[category['id']] = category['name']\n\n        # Aggiungi la mappa di annotazioni valide\n        for annotation in coco_data['annotations']:\n            image_id = annotation['image_id']\n            category_id = annotation['category_id']\n            bbox = annotation['bbox']  # Formato [x_min, y_min, width, height]\n            x_min, y_min, width, height = bbox\n            x_max = x_min + width\n            y_max = y_min + height\n            # Modifica il formato del bbox in [x_min, x_max, y_min, y_max]\n            annotation['bbox'] = [x_min, x_max, y_min, y_max]\n\n            if image_id not in self.image_annotations:\n                self.image_annotations[image_id] = []\n                self.image_bboxes[image_id] = []\n\n            self.image_annotations[image_id].append(category_id)\n            self.image_bboxes[image_id].append(annotation['bbox'])\n\n        # Mappa per associare ID immagine a file_name\n        self.image_info = {\n            image['id']: image['file_name']\n            for image in coco_data['images']\n        }\n\n        # Filtra le immagini con annotazioni valide\n        self.img_dir = img_dir\n        self.image_paths = []\n        self.image_ids = []\n        for image_id, file_name in self.image_info.items():\n            if image_id in self.image_annotations:  # Considera solo immagini con annotazioni\n                img_path = os.path.join(img_dir, file_name)\n                if os.path.exists(img_path):  # Assicura che il file esista\n                    self.image_paths.append(img_path)\n                    self.image_ids.append(image_id)\n\n        # Trasformazioni di base e di augmentation\n        self.base_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n        ])\n\n        self.aug_transform = transforms.Compose([\n            transforms.Resize((224, 224)),\n            transforms.ToTensor(),\n        ])\n\n        self.aug = aug\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        # Estrai il nome dell'immagine e l'ID corrispondente\n        img_path = self.image_paths[index]\n        img_id = self.image_ids[index]\n\n        # Carica l'immagine\n        image = Image.open(img_path).convert('RGB')\n        original_width, original_height = image.size\n\n        # Applica le trasformazioni\n        if self.aug:\n            image_tensor = self.aug_transform(image)\n        else:\n            image_tensor = self.base_transform(image)\n\n        # Estrai le annotazioni e i bounding boxes\n        categories = self.image_annotations.get(img_id, [])\n        bboxes = self.image_bboxes.get(img_id, [])\n\n        # Controllo di fallback per annotazioni mancanti\n        if not bboxes:  \n            raise ValueError(f\"L'immagine {img_path} è stata erroneamente inclusa senza annotazioni valide.\")\n\n        # Converte da formato [x_min, x_max, y_min, y_max] a formato tensor\n        scale_x = 224 / original_width\n        scale_y = 224 / original_height\n\n        # Scaling dei bounding boxes\n        scaled_bboxes = []\n        for bbox in bboxes:\n            x_min, x_max, y_min, y_max = bbox\n\n            scaled_bboxes.append(torch.tensor([\n                float(x_min) * scale_x,  # x_min\n                float(x_max) * scale_x,  # x_max\n                float(y_min) * scale_y,  # y_min\n                float(y_max) * scale_y   # y_max\n            ], dtype=torch.float32))\n\n        target = {\n            \"boxes\": torch.stack(scaled_bboxes),\n            \"labels\": torch.tensor(categories, dtype=torch.int64)\n        }\n\n        return image_tensor, target","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:25:14.714307Z","iopub.execute_input":"2024-12-11T09:25:14.714636Z","iopub.status.idle":"2024-12-11T09:25:14.727070Z","shell.execute_reply.started":"2024-12-11T09:25:14.714606Z","shell.execute_reply":"2024-12-11T09:25:14.726241Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def collate_fn(batch):\n    \"\"\"\n    Funzione di collation per il DataLoader, utile per il batching di immagini e annotazioni.\n    La funzione restituirà un batch di immagini e un batch di target, formattato correttamente per Faster R-CNN.\n    \n    Args:\n    - batch: lista di tuple (image, target)\n    \n    Returns:\n    - images: batch di immagini\n    - targets: lista di dizionari contenenti le annotazioni per ogni immagine\n    \"\"\"\n    # Separa immagini e target\n    images, targets = zip(*batch)\n\n    # Converte la lista di immagini in un batch di immagini\n    images = list(images)\n\n    # Restituisci il batch\n    return images, list(targets)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:25:14.728166Z","iopub.execute_input":"2024-12-11T09:25:14.728456Z","iopub.status.idle":"2024-12-11T09:25:14.740323Z","shell.execute_reply.started":"2024-12-11T09:25:14.728430Z","shell.execute_reply":"2024-12-11T09:25:14.739515Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Creazione dei dataset\ntrain_dataset = CustomDataset(train_path, img_fldr,  aug=True)\nvalid_dataset = CustomDataset(val_path, img_fldr, aug=False)  \ntest_dataset = CustomDataset(test_path, img_fldr, aug=False)  \n\n# Creazione dei DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)\nval_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)\ntest_loader = DataLoader(test_dataset, batch_size=2, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:25:14.741445Z","iopub.execute_input":"2024-12-11T09:25:14.741743Z","iopub.status.idle":"2024-12-11T09:28:05.885067Z","shell.execute_reply.started":"2024-12-11T09:25:14.741718Z","shell.execute_reply":"2024-12-11T09:28:05.884382Z"}},"outputs":[],"execution_count":15},{"cell_type":"markdown","source":"## Check DataLoader","metadata":{}},{"cell_type":"code","source":"def validate_dataloader(dataloader):\n    \"\"\"\n    Valida un DataLoader verificando che ogni immagine abbia un target associato\n    e che nessun target sia `None` o vuoto.\n    \n    Args:\n    - dataloader: Il DataLoader da verificare.\n    \n    Returns:\n    - error_messages: Lista di messaggi di errore. Vuota se tutti i dati sono validi.\n    \"\"\"\n    error_messages = []\n    for batch_idx, (images, targets) in enumerate(dataloader):\n        for idx, target in enumerate(targets):\n            if target is None:\n                error_messages.append(f\"Batch {batch_idx}, Immagine {idx}: Target è None.\")\n            elif target[\"boxes\"].numel() == 0 or target[\"labels\"].numel() == 0:\n                error_messages.append(\n                    f\"Batch {batch_idx}, Immagine {idx}: Target è vuoto o mancano 'boxes'/'labels'.\"\n                )\n    return error_messages","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:39:12.189222Z","iopub.execute_input":"2024-12-11T02:39:12.189694Z","iopub.status.idle":"2024-12-11T02:39:12.195106Z","shell.execute_reply.started":"2024-12-11T02:39:12.189642Z","shell.execute_reply":"2024-12-11T02:39:12.194297Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Validazione del DataLoader di training\ntrain_errors = validate_dataloader(train_loader)\n\nif train_errors:\n    print(\"Errori nel DataLoader di training:\")\n    for error in train_errors:\n        print(error)\nelse:\n    print(\"Tutti i target nel DataLoader di training sono validi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:39:12.196104Z","iopub.execute_input":"2024-12-11T02:39:12.196352Z","iopub.status.idle":"2024-12-11T02:41:51.571177Z","shell.execute_reply.started":"2024-12-11T02:39:12.196315Z","shell.execute_reply":"2024-12-11T02:41:51.570161Z"}},"outputs":[{"name":"stdout","text":"Tutti i target nel DataLoader di training sono validi.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"# Validazione del DataLoader di training\nval_errors = validate_dataloader(val_loader)\n\nif val_errors:\n    print(\"Errori nel DataLoader di validation:\")\n    for error in val_errors:\n        print(error)\nelse:\n    print(\"Tutti i target nel DataLoader di validation sono validi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:41:51.572489Z","iopub.execute_input":"2024-12-11T02:41:51.572779Z","iopub.status.idle":"2024-12-11T02:42:11.383776Z","shell.execute_reply.started":"2024-12-11T02:41:51.572750Z","shell.execute_reply":"2024-12-11T02:42:11.382694Z"}},"outputs":[{"name":"stdout","text":"Tutti i target nel DataLoader di validation sono validi.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# Validazione del DataLoader di training\ntest_errors = validate_dataloader(test_loader)\n\nif test_errors:\n    print(\"Errori nel DataLoader di test:\")\n    for error in test_errors:\n        print(error)\nelse:\n    print(\"Tutti i target nel DataLoader di test sono validi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:42:11.385249Z","iopub.execute_input":"2024-12-11T02:42:11.385705Z","iopub.status.idle":"2024-12-11T02:42:31.474412Z","shell.execute_reply.started":"2024-12-11T02:42:11.385654Z","shell.execute_reply":"2024-12-11T02:42:31.473163Z"}},"outputs":[{"name":"stdout","text":"Tutti i target nel DataLoader di test sono validi.\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"def count_images_and_targets(dataloader):\n    \"\"\"\n    Conta il numero totale di immagini e target in un DataLoader.\n    \"\"\"\n    num_images = 0\n    num_targets = 0\n\n    for images, targets in dataloader:\n        # Conta le immagini nel batch\n        num_images += len(images)\n        \n        # Conta i target per ogni immagine (numero di oggetti)\n        for target in targets:\n            num_targets += len(target[\"boxes\"])  # Ogni immagine ha un numero di bounding boxes\n    \n    return num_images, num_targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:42:31.475873Z","iopub.execute_input":"2024-12-11T02:42:31.476593Z","iopub.status.idle":"2024-12-11T02:42:31.481944Z","shell.execute_reply.started":"2024-12-11T02:42:31.476559Z","shell.execute_reply":"2024-12-11T02:42:31.480949Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"num_images_train, num_targets_train = count_images_and_targets(train_loader)\n\nprint(f\"Numero totale di immagini per il train: {num_images_train}\")\nprint(f\"Numero totale di target per il train: {num_targets_train}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:42:31.483367Z","iopub.execute_input":"2024-12-11T02:42:31.483704Z","iopub.status.idle":"2024-12-11T02:44:17.581125Z","shell.execute_reply.started":"2024-12-11T02:42:31.483667Z","shell.execute_reply":"2024-12-11T02:44:17.579987Z"}},"outputs":[{"name":"stdout","text":"Numero totale di immagini per il train: 36686\nNumero totale di target per il train: 544927\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"num_images_val, num_targets_val = count_images_and_targets(val_loader)\n\nprint(f\"Numero totale di immagini per il validation: {num_images_val}\")\nprint(f\"Numero totale di target per il validation: {num_targets_val}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:44:17.582883Z","iopub.execute_input":"2024-12-11T02:44:17.583816Z","iopub.status.idle":"2024-12-11T02:44:30.852271Z","shell.execute_reply.started":"2024-12-11T02:44:17.583766Z","shell.execute_reply":"2024-12-11T02:44:30.851265Z"}},"outputs":[{"name":"stdout","text":"Numero totale di immagini per il validation: 4585\nNumero totale di target per il validation: 67281\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"num_images_test, num_targets_test = count_images_and_targets(test_loader)\n\nprint(f\"Numero totale di immagini per il test: {num_images_test}\")\nprint(f\"Numero totale di target per il test: {num_targets_test}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:44:30.853663Z","iopub.execute_input":"2024-12-11T02:44:30.853960Z","iopub.status.idle":"2024-12-11T02:44:44.381742Z","shell.execute_reply.started":"2024-12-11T02:44:30.853931Z","shell.execute_reply":"2024-12-11T02:44:44.380708Z"}},"outputs":[{"name":"stdout","text":"Numero totale di immagini per il test: 4583\nNumero totale di target per il test: 71689\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"print(f\"Numero totale di immagini: {num_images_train + num_images_val +num_images_test}\")\nprint(f\"Numero totale di target: {num_targets_train + num_targets_val +num_targets_test}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T02:44:44.383178Z","iopub.execute_input":"2024-12-11T02:44:44.383509Z","iopub.status.idle":"2024-12-11T02:44:44.388721Z","shell.execute_reply.started":"2024-12-11T02:44:44.383479Z","shell.execute_reply":"2024-12-11T02:44:44.387892Z"}},"outputs":[{"name":"stdout","text":"Numero totale di immagini: 45854\nNumero totale di target: 683897\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"# Modello Faster R-CNN (Resnet50)","metadata":{}},{"cell_type":"code","source":"def compute_class_weights(dataset):\n    # Conta la frequenza di ogni classe nel dataset\n    class_counts = np.zeros(len(dataset.classes))  \n    \n    # Usa tqdm per monitorare il progresso mentre si itera sul dataset\n    for _, targets in tqdm(dataset, desc=\"Calcolo frequenze delle classi\", leave=False):\n        # Controlla se targets è None\n        if targets is None:\n            print(\"ERRORE TARGET NONE\")\n            continue\n        \n        # Assicurati che 'labels' sia un array e itera su di esso\n        if 'labels' in targets:\n            for target in targets['labels']:  \n                class_counts[target] += 1\n\n    # Calcola i pesi per le classi \n    total_count = sum(class_counts)  \n\n    # Calcola i pesi inversamente proporzionali alla frequenza\n    class_weights = np.divide(total_count, class_counts)\n\n    return class_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:28:05.886180Z","iopub.execute_input":"2024-12-11T09:28:05.886476Z","iopub.status.idle":"2024-12-11T09:28:05.891760Z","shell.execute_reply.started":"2024-12-11T09:28:05.886449Z","shell.execute_reply":"2024-12-11T09:28:05.890909Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def train_and_validate(model, train_loader, val_loader, optimizer, device, class_weights=None, \n                       num_epochs=10, num_classes=12, accumulation_steps=4):\n    \"\"\"\n    Funzione di training e validazione per Faster R-CNN.\n    \"\"\"\n    # Scaler per mixed precision training\n    scaler = GradScaler()\n    model.to(device)\n\n    train_losses = []\n    val_losses = []\n    train_mAPs = []\n    val_mAPs = []\n\n    # Converte class_weights in tensor e sposta sul dispositivo\n    if class_weights is not None:\n        class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)\n\n    for epoch in range(num_epochs):\n        print(f\"\\nEpoca {epoch + 1}/{num_epochs}\")\n\n        # --------------------\n        # Training\n        # --------------------\n        model.train()\n        total_train_loss = 0.0\n        all_train_preds = []\n        all_train_targets = []\n\n        optimizer.zero_grad()\n        train_loop = tqdm(train_loader, desc=\"Training\", leave=False)\n\n        for i, (images, targets) in enumerate(train_loop):\n            images = [img.to(device) for img in images]\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n            with autocast('cuda'):\n                # Forward pass\n                loss_dict = model(images, targets)\n            \n                total_weighted_loss = 0\n                total_weight = 0\n            \n                # Itera su tutte le perdite\n                for key, loss in loss_dict.items():\n                    if isinstance(loss, torch.Tensor):\n                        if key == 'loss_classifier' and class_weights is not None:\n                            # Applica i pesi delle classi solo alla loss_classifier\n                            labels = torch.cat([t['labels'] for t in targets])  # Ottieni le etichette\n                            weighted_loss = loss * class_weights[labels]  # Pesi basati sulle etichette\n                            total_weighted_loss += weighted_loss.sum()  # Somma la perdita pesata\n                            total_weight += class_weights[labels].sum()  # Somma i pesi per il calcolo totale\n                        else:\n                            # Entra qui per loss_box_reg, loss_objectness e loss_rpn_box_reg\n                            total_weighted_loss += loss.sum()  # Somma la perdita normale\n                            total_weight += loss.numel()  # Somma il numero di elementi\n            \n                losses = total_weighted_loss / total_weight  # Calcola la perdita totale normalizzata\n\n            # Backward pass con gradient scaling\n            scaler.scale(losses).backward()\n        \n            # Gradient accumulation\n            if (i + 1) % accumulation_steps == 0 or (i + 1) == len(train_loader):\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n        \n            total_train_loss += losses.item() * accumulation_steps\n            train_loop.set_postfix(loss=losses.item() * accumulation_steps)\n            \n            # Raccoglie predizioni per calcolo mAP\n            model.eval()\n            with torch.no_grad():\n                outputs = model(images)\n                all_train_preds.extend([{k: v.cpu() for k, v in t.items()} for t in outputs])\n                all_train_targets.extend([{k: v.cpu() for k, v in t.items()} for t in targets])\n            model.train()\n\n        avg_train_loss = total_train_loss / len(train_loader)\n        train_losses.append(avg_train_loss)\n        print(f\"Perdita media di training: {avg_train_loss:.4f}\")\n\n        train_map = calculate_map(all_train_preds, all_train_targets, num_classes=num_classes)\n        train_mAPs.append(train_map)\n        print(f\"mAP di training: {train_map:.4f}\")\n\n        # --------------------\n        # Validazione\n        # --------------------\n        model.eval()\n        total_val_loss = 0.0\n        all_val_preds = []\n        all_val_targets = []\n        \n        val_loop = tqdm(val_loader, desc=\"Validazione\", leave=False)\n        with torch.no_grad():\n            for images, targets in val_loop:\n                images = [img.to(device) for img in images]\n                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n        \n                with autocast('cuda'):\n                    # Forward pass\n                    loss_dict = model(images, targets)\n        \n                    total_weighted_loss = 0\n                    total_weight = 0\n                    for key, loss in loss_dict.items():\n                        if isinstance(loss, torch.Tensor):\n                            if key == 'loss_classifier' and class_weights is not None:\n                                # Applica i pesi delle classi solo alla loss_classifier\n                                labels = torch.cat([t['labels'] for t in targets])  # Ottieni le etichette\n                                weighted_loss = loss * class_weights[labels]  # Pesi basati sulle etichette\n                                total_weighted_loss += weighted_loss.sum()  # Somma la perdita pesata\n                                total_weight += class_weights[labels].sum()  # Somma i pesi per il calcolo totale\n                            else:\n                                total_weighted_loss += loss.sum()  # Somma la perdita normale\n                                total_weight += loss.numel()  # Somma il numero di elementi\n    \n                    losses = total_weighted_loss / total_weight  # Calcola la perdita totale normalizzata\n        \n                total_val_loss += losses.item()\n        \n                # Predizioni per calcolo mAP\n                outputs = model(images)\n                all_val_preds.extend([{k: v.cpu() for k, v in t.items()} for t in outputs])\n                all_val_targets.extend([{k: v.cpu() for k, v in t.items()} for t in targets])\n        \n        avg_val_loss = total_val_loss / len(val_loader)\n        val_losses.append(avg_val_loss)\n        print(f\"Perdita media di validazione: {avg_val_loss:.4f}\")\n        \n        val_map = calculate_map(all_val_preds, all_val_targets, num_classes=num_classes)\n        val_mAPs.append(val_map)\n        print(f\"mAP di validazione: {val_map:.4f}\")\n\n        # --------------------\n        # Salvataggio del modello\n        # --------------------\n        torch.save(model.state_dict(), f\"model_epoch_{epoch + 1}.pth\")\n        print(f\"Modello salvato: model_epoch_{epoch + 1}.pth\")\n\n    return train_losses, val_losses, train_mAPs, val_mAPs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T11:09:12.540745Z","iopub.execute_input":"2024-12-11T11:09:12.541096Z","iopub.status.idle":"2024-12-11T11:09:12.558923Z","shell.execute_reply.started":"2024-12-11T11:09:12.541067Z","shell.execute_reply":"2024-12-11T11:09:12.558191Z"}},"outputs":[],"execution_count":118},{"cell_type":"code","source":"def plot_metrics(losses_per_epoch, train_accuracies, val_accuracies, num_epochs):\n    \"\"\"\n    Funzione per plottare le metriche di training e validazione.\n    \"\"\"\n    epochs_range = range(1, num_epochs + 1)\n\n    plt.figure(figsize=(12, 8))\n\n    # Loss plot\n    plt.subplot(2, 1, 1)\n    plt.plot(epochs_range, losses_per_epoch, label='Training Loss', color='blue')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.title('Training Loss per Epoca')\n\n    # Accuracy plot\n    plt.subplot(2, 1, 2)\n    plt.plot(epochs_range, train_accuracies, label='Accuracy (Training)', color='green')\n    plt.plot(epochs_range, val_accuracies, label='Accuracy (Validation)', color='orange')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n    plt.title('Accuracy per Epoca')\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:28:05.925232Z","iopub.execute_input":"2024-12-11T09:28:05.925572Z","iopub.status.idle":"2024-12-11T09:28:05.937743Z","shell.execute_reply.started":"2024-12-11T09:28:05.925544Z","shell.execute_reply":"2024-12-11T09:28:05.936906Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def test_model(model, test_loader, device):\n    \"\"\"\n    Funzione per il testing del modello Faster R-CNN.\n    \n    Args:\n    - model: il modello Faster R-CNN.\n    - test_loader: DataLoader per il test set.\n    - device: dispositivo su cui eseguire (es. 'cuda' o 'cpu').\n    \n    Returns:\n    - predictions: lista delle predizioni per ogni batch (include 'boxes', 'labels', 'scores').\n    \"\"\"\n    model.to(device)\n    model.eval()\n    predictions = []\n    \n    print(\"\\nInizio testing...\")\n    test_loop = tqdm(test_loader, desc=\"Testing\", leave=False)\n    \n    with torch.no_grad():\n        for images, _ in test_loop:  # Durante il test, i target possono essere ignorati\n            images = [img.to(device) for img in images]\n            preds = model(images)\n            \n            # Predizioni di ciascun batch (contenente 'boxes', 'labels', 'scores')\n            # Le predizioni sono in un formato di lista di dizionari\n            for pred in preds:\n                predictions.append({\n                    'boxes': pred['boxes'].cpu().numpy(),\n                    'labels': pred['labels'].cpu().numpy(),\n                    'scores': pred['scores'].cpu().numpy()\n                })\n            \n            # Aggiungi aggiornamenti su quante predizioni sono state processate\n            test_loop.set_postfix(processed=len(predictions))\n\n    print(\"Testing completato.\")\n    return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:28:05.939021Z","iopub.execute_input":"2024-12-11T09:28:05.939637Z","iopub.status.idle":"2024-12-11T09:28:05.947819Z","shell.execute_reply.started":"2024-12-11T09:28:05.939598Z","shell.execute_reply":"2024-12-11T09:28:05.946989Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# Carica il modello Faster R-CNN con ResNet50 e FPN\nmodel = fasterrcnn_resnet50_fpn(weights=None)\n\nnum_classes = 12\n\n# Modifica il numero di classi in output\nin_features = model.roi_heads.box_predictor.cls_score.in_features\nmodel.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n\n# Congela i layer della backbone (ResNet50)\nfor param in model.backbone.parameters():\n    param.requires_grad = False\n\n# Imposta il dispositivo (GPU o CPU)\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Configurazione training\nnum_epochs = 2\noptimizer = optim.AdamW(model.parameters(), lr=1e-7)\n\n# Sposta il modello su GPU o CPU\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:28:05.948635Z","iopub.execute_input":"2024-12-11T09:28:05.948905Z","iopub.status.idle":"2024-12-11T09:28:07.633134Z","shell.execute_reply.started":"2024-12-11T09:28:05.948880Z","shell.execute_reply":"2024-12-11T09:28:07.632259Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 211MB/s]\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"FasterRCNN(\n  (transform): GeneralizedRCNNTransform(\n      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n  )\n  (backbone): BackboneWithFPN(\n    (body): IntermediateLayerGetter(\n      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n      (relu): ReLU(inplace=True)\n      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n      (layer1): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): FrozenBatchNorm2d(256, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer2): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(512, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer3): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (3): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (4): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (5): Bottleneck(\n          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n      (layer4): Sequential(\n        (0): Bottleneck(\n          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n          (relu): ReLU(inplace=True)\n          (downsample): Sequential(\n            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n          )\n        )\n        (1): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n        (2): Bottleneck(\n          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n          (relu): ReLU(inplace=True)\n        )\n      )\n    )\n    (fpn): FeaturePyramidNetwork(\n      (inner_blocks): ModuleList(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (1): Conv2dNormActivation(\n          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (2): Conv2dNormActivation(\n          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (3): Conv2dNormActivation(\n          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n        )\n      )\n      (layer_blocks): ModuleList(\n        (0-3): 4 x Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n        )\n      )\n      (extra_blocks): LastLevelMaxPool()\n    )\n  )\n  (rpn): RegionProposalNetwork(\n    (anchor_generator): AnchorGenerator()\n    (head): RPNHead(\n      (conv): Sequential(\n        (0): Conv2dNormActivation(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n          (1): ReLU(inplace=True)\n        )\n      )\n      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): RoIHeads(\n    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n    (box_head): TwoMLPHead(\n      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n    (box_predictor): FastRCNNPredictor(\n      (cls_score): Linear(in_features=1024, out_features=12, bias=True)\n      (bbox_pred): Linear(in_features=1024, out_features=48, bias=True)\n    )\n  )\n)"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"# Calcola i pesi delle classi\nclass_weights = compute_class_weights(train_loader.dataset)\n\nprint(class_weights)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T09:28:07.634172Z","iopub.execute_input":"2024-12-11T09:28:07.634470Z","iopub.status.idle":"2024-12-11T09:34:21.316022Z","shell.execute_reply.started":"2024-12-11T09:28:07.634444Z","shell.execute_reply":"2024-12-11T09:34:21.314983Z"}},"outputs":[{"name":"stderr","text":"                                                                                      ","output_type":"stream"},{"name":"stdout","text":"[4.95748726e+01 3.06564165e+00 1.98805910e+01 1.67773091e+02\n 1.06202884e+02 1.24440968e+02 1.76849132e+00 4.39457258e+03\n 3.32272561e+02 1.23790777e+02 1.42651047e+03 4.08185019e+02]\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_losses, val_losses, train_mAPs, val_mAPs = train_and_validate(model, train_loader, val_loader, optimizer, device, class_weights, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T10:58:10.773341Z","iopub.execute_input":"2024-12-11T10:58:10.774050Z","iopub.status.idle":"2024-12-11T10:58:26.331022Z","shell.execute_reply.started":"2024-12-11T10:58:10.774014Z","shell.execute_reply":"2024-12-11T10:58:26.329625Z"}},"outputs":[{"name":"stdout","text":"\nEpoca 1/2\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 0/18343 [00:00<?, ?it/s, loss=13.6]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 1, 1, 6, 1, 1, 1, 1, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 6, 1, 1, 1, 1, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 6, 1, 1, 1, 1, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 6, 1, 1, 1, 1, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685,\n        1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 1/18343 [00:00<2:33:53,  1.99it/s, loss=8.14]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0],\n       device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0],\n       device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0],\n       device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 0],\n       device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 3/18343 [00:01<1:49:45,  2.78it/s, loss=3.43]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 3/18343 [00:01<1:49:45,  2.78it/s, loss=3.27]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 3.0656, 1.7685, 1.7685, 1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 3.0656, 1.7685, 1.7685, 1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 3.0656, 1.7685, 1.7685, 1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 3.0656, 1.7685, 1.7685, 1.7685],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 5/18343 [00:01<1:40:30,  3.04it/s, loss=3.32]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 5/18343 [00:01<1:40:30,  3.04it/s, loss=20.8]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 6/18343 [00:02<1:39:37,  3.07it/s, loss=13.9]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6,\n        1, 1, 1, 2, 1, 1, 5, 1, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,  19.8806,   3.0656,   3.0656, 124.4410,   3.0656,\n          1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6,\n        1, 1, 1, 2, 1, 1, 5, 1, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,  19.8806,   3.0656,   3.0656, 124.4410,   3.0656,\n          1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6,\n        1, 1, 1, 2, 1, 1, 5, 1, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,  19.8806,   3.0656,   3.0656, 124.4410,   3.0656,\n          1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 6, 6,\n        1, 1, 1, 2, 1, 1, 5, 1, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 2, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   1.7685,   1.7685,   1.7685,   3.0656,\n          3.0656,   3.0656,  19.8806,   3.0656,   3.0656, 124.4410,   3.0656,\n          1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685,\n          1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,\n         19.8806,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685,   1.7685],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 7/18343 [00:02<1:39:23,  3.07it/s, loss=9.02]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1,\n        6, 1, 6, 1, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 3.0656, 1.7685,\n        1.7685, 1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1,\n        6, 1, 6, 1, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 3.0656, 1.7685,\n        1.7685, 1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1,\n        6, 1, 6, 1, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 3.0656, 1.7685,\n        1.7685, 1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6, 1,\n        6, 1, 6, 1, 1, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 1.7685, 3.0656, 3.0656, 1.7685,\n        1.7685, 1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 8/18343 [00:02<1:39:17,  3.08it/s, loss=6.61]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 9/18343 [00:03<1:38:03,  3.12it/s, loss=21.2]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([10,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n         6,  6,  6,  6,  6,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  1,  6,  1,\n         1,  6,  6,  6,  6,  6,  6,  6], device='cuda:0')\nClass weights for classifier: tensor([1426.5105,    3.0656,    3.0656,    3.0656,    3.0656,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    3.0656,\n           3.0656,    3.0656,    3.0656,    3.0656,    3.0656,    1.7685,\n           1.7685,    1.7685,    1.7685,    3.0656,    1.7685,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([10,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n         6,  6,  6,  6,  6,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  1,  6,  1,\n         1,  6,  6,  6,  6,  6,  6,  6], device='cuda:0')\nClass weights for classifier: tensor([1426.5105,    3.0656,    3.0656,    3.0656,    3.0656,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    3.0656,\n           3.0656,    3.0656,    3.0656,    3.0656,    3.0656,    1.7685,\n           1.7685,    1.7685,    1.7685,    3.0656,    1.7685,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([10,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n         6,  6,  6,  6,  6,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  1,  6,  1,\n         1,  6,  6,  6,  6,  6,  6,  6], device='cuda:0')\nClass weights for classifier: tensor([1426.5105,    3.0656,    3.0656,    3.0656,    3.0656,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    3.0656,\n           3.0656,    3.0656,    3.0656,    3.0656,    3.0656,    1.7685,\n           1.7685,    1.7685,    1.7685,    3.0656,    1.7685,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([10,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n         6,  6,  6,  6,  6,  1,  1,  1,  1,  1,  1,  6,  6,  6,  6,  1,  6,  1,\n         1,  6,  6,  6,  6,  6,  6,  6], device='cuda:0')\nClass weights for classifier: tensor([1426.5105,    3.0656,    3.0656,    3.0656,    3.0656,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685,    1.7685,    1.7685,    1.7685,    3.0656,\n           3.0656,    3.0656,    3.0656,    3.0656,    3.0656,    1.7685,\n           1.7685,    1.7685,    1.7685,    3.0656,    1.7685,    3.0656,\n           3.0656,    1.7685,    1.7685,    1.7685,    1.7685,    1.7685,\n           1.7685,    1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 10/18343 [00:03<1:37:42,  3.13it/s, loss=8.58]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 1,\n        1, 1, 6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 2, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,  3.0656,  3.0656],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 1,\n        1, 1, 6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 2, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,  3.0656,  3.0656],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 1,\n        1, 1, 6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 2, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,  3.0656,  3.0656],\n       device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 6, 1, 1, 1, 1, 1, 1, 6, 6, 1,\n        1, 1, 6, 1, 6, 1, 6, 1, 1, 6, 6, 6, 2, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  3.0656,\n         3.0656,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,  3.0656,  3.0656],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 11/18343 [00:03<1:37:11,  3.14it/s, loss=6.6] ","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 6, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 2, 2, 2, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6,\n        9], device='cuda:0')\nClass weights for classifier: tensor([  3.0656,   1.7685,  19.8806,  19.8806,  19.8806,  19.8806,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,  19.8806,  19.8806,  19.8806,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685, 123.7908],\n       device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 2, 2, 2, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6,\n        9], device='cuda:0')\nClass weights for classifier: tensor([  3.0656,   1.7685,  19.8806,  19.8806,  19.8806,  19.8806,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,  19.8806,  19.8806,  19.8806,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685, 123.7908],\n       device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 2, 2, 2, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6,\n        9], device='cuda:0')\nClass weights for classifier: tensor([  3.0656,   1.7685,  19.8806,  19.8806,  19.8806,  19.8806,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,  19.8806,  19.8806,  19.8806,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685, 123.7908],\n       device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 2, 2, 2, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6,\n        9], device='cuda:0')\nClass weights for classifier: tensor([  3.0656,   1.7685,  19.8806,  19.8806,  19.8806,  19.8806,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,  19.8806,  19.8806,  19.8806,   1.7685,   1.7685,\n          1.7685,   1.7685,   1.7685,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   1.7685, 123.7908],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 12/18343 [00:04<1:37:38,  3.13it/s, loss=25.3]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 3.0656,\n        3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 1.7685, 1.7685, 3.0656, 3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 3.0656,\n        3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 1.7685, 1.7685, 3.0656, 3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 3.0656,\n        3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 1.7685, 1.7685, 3.0656, 3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 6, 1, 1, 1, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 3.0656,\n        3.0656, 3.0656, 3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 3.0656,\n        3.0656, 1.7685, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        3.0656, 3.0656, 1.7685, 1.7685, 3.0656, 3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 13/18343 [00:04<1:37:28,  3.13it/s, loss=3.34]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 1, 6, 6, 2, 9, 9, 0], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   3.0656,   1.7685,   1.7685,  19.8806, 123.7908, 123.7908,\n         49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 6, 6, 2, 9, 9, 0], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   3.0656,   1.7685,   1.7685,  19.8806, 123.7908, 123.7908,\n         49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 6, 6, 2, 9, 9, 0], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   3.0656,   1.7685,   1.7685,  19.8806, 123.7908, 123.7908,\n         49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 6, 6, 2, 9, 9, 0], device='cuda:0')\nClass weights for classifier: tensor([  1.7685,   3.0656,   1.7685,   1.7685,  19.8806, 123.7908, 123.7908,\n         49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 14/18343 [00:04<1:36:58,  3.15it/s, loss=20.2]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 6, 6, 6,\n        6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 6, 6, 6,\n        6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 6, 6, 6,\n        6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 6, 6, 6,\n        6, 1, 6, 6, 6, 6, 6, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 15/18343 [00:05<1:37:31,  3.13it/s, loss=18.1]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 16/18343 [00:05<1:37:52,  3.12it/s, loss=8.47]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n        1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n        1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n        1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1,\n        1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 18/18343 [00:05<1:36:53,  3.15it/s, loss=3.23]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([ 8, 10, 10,  6], device='cuda:0')\nClass weights for classifier: tensor([ 332.2726, 1426.5105, 1426.5105,    1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([ 8, 10, 10,  6], device='cuda:0')\nClass weights for classifier: tensor([ 332.2726, 1426.5105, 1426.5105,    1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([ 8, 10, 10,  6], device='cuda:0')\nClass weights for classifier: tensor([ 332.2726, 1426.5105, 1426.5105,    1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([ 8, 10, 10,  6], device='cuda:0')\nClass weights for classifier: tensor([ 332.2726, 1426.5105, 1426.5105,    1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 18/18343 [00:06<1:36:53,  3.15it/s, loss=3.31]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 19/18343 [00:06<1:36:25,  3.17it/s, loss=14.8]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([5, 0], device='cuda:0')\nClass weights for classifier: tensor([124.4410,  49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([5, 0], device='cuda:0')\nClass weights for classifier: tensor([124.4410,  49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([5, 0], device='cuda:0')\nClass weights for classifier: tensor([124.4410,  49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([5, 0], device='cuda:0')\nClass weights for classifier: tensor([124.4410,  49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 20/18343 [00:06<1:36:14,  3.17it/s, loss=3.82]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 6, 6, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685, 1.7685,\n        1.7685, 1.7685, 1.7685, 3.0656, 3.0656, 3.0656, 3.0656, 1.7685, 1.7685,\n        3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 21/18343 [00:06<1:36:05,  3.18it/s, loss=9.03]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([8, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([332.2726,   3.0656,   3.0656,   1.7685,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([8, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([332.2726,   3.0656,   3.0656,   1.7685,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([8, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([332.2726,   3.0656,   3.0656,   1.7685,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([8, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n       device='cuda:0')\nClass weights for classifier: tensor([332.2726,   3.0656,   3.0656,   1.7685,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,\n          3.0656,   3.0656,   3.0656,   3.0656,   3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 23/18343 [00:07<1:35:55,  3.18it/s, loss=3.42]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 23/18343 [00:07<1:35:55,  3.18it/s, loss=3.33]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685],\n       device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 24/18343 [00:07<1:36:40,  3.16it/s, loss=9.92]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n        49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n        49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n        49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n        49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 25/18343 [00:08<1:36:29,  3.16it/s, loss=8.41]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 27/18343 [00:08<1:35:32,  3.20it/s, loss=3.34]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 2, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 19.8806,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 2, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 19.8806,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 2, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 19.8806,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 2, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 19.8806,  3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 27/18343 [00:08<1:35:32,  3.20it/s, loss=7.62]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  3.0656,  1.7685,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  3.0656,  1.7685,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  3.0656,  1.7685,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 1, 6, 1, 6, 1, 1, 6, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  3.0656,  1.7685,  3.0656,\n         3.0656,  3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 28/18343 [00:09<1:35:49,  3.19it/s, loss=13.8]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([7, 7, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([4.3946e+03, 4.3946e+03, 1.7685e+00, 1.7685e+00, 1.7685e+00],\n       device='cuda:0')\nLabels for loss_classifier: tensor([7, 7, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([4.3946e+03, 4.3946e+03, 1.7685e+00, 1.7685e+00, 1.7685e+00],\n       device='cuda:0')\nLabels for loss_classifier: tensor([7, 7, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([4.3946e+03, 4.3946e+03, 1.7685e+00, 1.7685e+00, 1.7685e+00],\n       device='cuda:0')\nLabels for loss_classifier: tensor([7, 7, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([4.3946e+03, 4.3946e+03, 1.7685e+00, 1.7685e+00, 1.7685e+00],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 30/18343 [00:09<1:34:56,  3.21it/s, loss=3.44]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 30/18343 [00:09<1:34:56,  3.21it/s, loss=15.9]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 2, 1, 1, 1, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 2, 1, 1, 1, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 2, 1, 1, 1, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 1, 2, 1, 1, 1, 6, 6, 6, 6, 6, 2, 6,\n        6, 6, 6, 6, 6, 1, 6, 1, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,  3.0656,\n         3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 19.8806,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 31/18343 [00:10<1:36:01,  3.18it/s, loss=3.53]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 49.5749],\n       device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 49.5749],\n       device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 49.5749],\n       device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685, 49.5749],\n       device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 32/18343 [00:10<1:36:39,  3.16it/s, loss=3.32]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 33/18343 [00:10<1:36:00,  3.18it/s, loss=13.2]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([2, 2, 2, 6, 6, 6, 1, 2, 5, 2, 5, 1, 6, 6, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n        2, 1, 2, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806,  19.8806,  19.8806,   1.7685,   1.7685,   1.7685,   3.0656,\n         19.8806, 124.4410,  19.8806, 124.4410,   3.0656,   1.7685,   1.7685,\n         19.8806,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,  19.8806,\n          3.0656,   3.0656,   3.0656,  19.8806,   3.0656,  19.8806,   3.0656,\n          3.0656,   3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([2, 2, 2, 6, 6, 6, 1, 2, 5, 2, 5, 1, 6, 6, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n        2, 1, 2, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806,  19.8806,  19.8806,   1.7685,   1.7685,   1.7685,   3.0656,\n         19.8806, 124.4410,  19.8806, 124.4410,   3.0656,   1.7685,   1.7685,\n         19.8806,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,  19.8806,\n          3.0656,   3.0656,   3.0656,  19.8806,   3.0656,  19.8806,   3.0656,\n          3.0656,   3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([2, 2, 2, 6, 6, 6, 1, 2, 5, 2, 5, 1, 6, 6, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n        2, 1, 2, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806,  19.8806,  19.8806,   1.7685,   1.7685,   1.7685,   3.0656,\n         19.8806, 124.4410,  19.8806, 124.4410,   3.0656,   1.7685,   1.7685,\n         19.8806,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,  19.8806,\n          3.0656,   3.0656,   3.0656,  19.8806,   3.0656,  19.8806,   3.0656,\n          3.0656,   3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([2, 2, 2, 6, 6, 6, 1, 2, 5, 2, 5, 1, 6, 6, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1,\n        2, 1, 2, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806,  19.8806,  19.8806,   1.7685,   1.7685,   1.7685,   3.0656,\n         19.8806, 124.4410,  19.8806, 124.4410,   3.0656,   1.7685,   1.7685,\n         19.8806,   3.0656,   3.0656,   3.0656,   3.0656,   3.0656,  19.8806,\n          3.0656,   3.0656,   3.0656,  19.8806,   3.0656,  19.8806,   3.0656,\n          3.0656,   3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 34/18343 [00:11<1:36:31,  3.16it/s, loss=7.76]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 1, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 35/18343 [00:11<1:37:04,  3.14it/s, loss=9.49]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 1, 2, 1, 1, 1, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 2, 1, 1, 1, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 2, 1, 1, 1, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 2, 1, 1, 1, 1, 1, 1], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,\n         3.0656], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 36/18343 [00:11<1:37:47,  3.12it/s, loss=8.94]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n        49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n        49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n        49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n        49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 37/18343 [00:12<1:38:17,  3.10it/s, loss=13.2]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 38/18343 [00:12<1:37:55,  3.12it/s, loss=17.4]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 1, 1, 1, 1, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 2, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,\n         3.0656,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  1.7685,  1.7685,\n         3.0656,  3.0656,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 1, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 2, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,\n         3.0656,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  1.7685,  1.7685,\n         3.0656,  3.0656,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 1, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 2, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,\n         3.0656,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  1.7685,  1.7685,\n         3.0656,  3.0656,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 1, 1, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 1, 2, 1, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 1, 6, 1, 6, 1, 6, 6, 6, 6, 6, 6, 1, 6, 6, 6, 1, 1, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,\n         3.0656,  1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  3.0656,  3.0656,  3.0656, 19.8806,  3.0656,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  3.0656,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  3.0656,  1.7685,  1.7685,  1.7685,\n         3.0656,  3.0656,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 39/18343 [00:12<1:38:21,  3.10it/s, loss=3.19]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([1.7685, 1.7685, 1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 40/18343 [00:13<1:38:06,  3.11it/s, loss=12.8]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 1, 1, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([1, 1, 1, 1, 0], device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  3.0656,  3.0656,  3.0656, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 41/18343 [00:13<1:37:13,  3.14it/s, loss=3.41]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\nLabels for loss_classifier: tensor([0, 0], device='cuda:0')\nClass weights for classifier: tensor([49.5749, 49.5749], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 42/18343 [00:13<1:36:50,  3.15it/s, loss=3.21]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([2, 5, 5], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806, 124.4410, 124.4410], device='cuda:0')\nLabels for loss_classifier: tensor([2, 5, 5], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806, 124.4410, 124.4410], device='cuda:0')\nLabels for loss_classifier: tensor([2, 5, 5], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806, 124.4410, 124.4410], device='cuda:0')\nLabels for loss_classifier: tensor([2, 5, 5], device='cuda:0')\nClass weights for classifier: tensor([ 19.8806, 124.4410, 124.4410], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 43/18343 [00:13<1:36:28,  3.16it/s, loss=3.18]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([5, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([124.4410,   1.7685,   1.7685,   1.7685,   1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([5, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([124.4410,   1.7685,   1.7685,   1.7685,   1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([5, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([124.4410,   1.7685,   1.7685,   1.7685,   1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([5, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([124.4410,   1.7685,   1.7685,   1.7685,   1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 44/18343 [00:14<1:36:42,  3.15it/s, loss=3.43]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 6], device='cuda:0')\nClass weights for classifier: tensor([49.5749,  3.0656,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 45/18343 [00:14<1:36:56,  3.15it/s, loss=8.58]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 6, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806, 19.8806,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 6, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806, 19.8806,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 6, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806, 19.8806,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([1, 6, 6, 6, 6, 6, 6, 6, 6, 2, 1, 1, 1, 1, 2, 2, 2, 2, 2, 6, 6, 6],\n       device='cuda:0')\nClass weights for classifier: tensor([ 3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685, 19.8806,  3.0656,  3.0656,  3.0656,  3.0656, 19.8806, 19.8806,\n        19.8806, 19.8806, 19.8806,  1.7685,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|          | 46/18343 [00:14<1:36:51,  3.15it/s, loss=8.43]","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 1, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656, 19.8806,  3.0656,  3.0656,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 1, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656, 19.8806,  3.0656,  3.0656,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 1, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656, 19.8806,  3.0656,  3.0656,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 6, 6, 6, 6, 6, 6, 1, 1, 2, 1, 1, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  3.0656,\n         3.0656, 19.8806,  3.0656,  3.0656,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"                                                                         ","output_type":"stream"},{"name":"stdout","text":"Class weights: tensor([4.9575e+01, 3.0656e+00, 1.9881e+01, 1.6777e+02, 1.0620e+02, 1.2444e+02,\n        1.7685e+00, 4.3946e+03, 3.3227e+02, 1.2379e+02, 1.4265e+03, 4.0819e+02],\n       device='cuda:0')\nShape of class_weights: torch.Size([12])\nLabels for loss_classifier: tensor([6, 1, 6, 1, 2, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  1.7685,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 6, 1, 2, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  1.7685,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 6, 1, 2, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  1.7685,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\nLabels for loss_classifier: tensor([6, 1, 6, 1, 2, 6, 6, 6, 6, 6, 1, 1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 1, 1, 6, 6, 6, 6, 6,\n        6, 6, 6, 6, 6], device='cuda:0')\nClass weights for classifier: tensor([ 1.7685,  3.0656,  1.7685,  3.0656, 19.8806,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  3.0656,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  3.0656,  3.0656,  1.7685,  1.7685,  1.7685,  1.7685,  1.7685,\n         1.7685,  1.7685,  1.7685,  1.7685,  1.7685], device='cuda:0')\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses, train_mAPs, val_mAPs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[115], line 79\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[0;34m(model, train_loader, val_loader, optimizer, device, class_weights, num_epochs, num_classes, accumulation_steps)\u001b[0m\n\u001b[1;32m     77\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 79\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m     all_train_preds\u001b[38;5;241m.\u001b[39mextend([{k: v\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m outputs])\n\u001b[1;32m     81\u001b[0m     all_train_targets\u001b[38;5;241m.\u001b[39mextend([{k: v\u001b[38;5;241m.\u001b[39mcpu() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m t\u001b[38;5;241m.\u001b[39mitems()} \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m targets])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/generalized_rcnn.py:104\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[0;34m(self, images, targets)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(features, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m    103\u001b[0m     features \u001b[38;5;241m=\u001b[39m OrderedDict([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m\"\u001b[39m, features)])\n\u001b[0;32m--> 104\u001b[0m proposals, proposal_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrpn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m detections, detector_losses \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroi_heads(features, proposals, images\u001b[38;5;241m.\u001b[39mimage_sizes, targets)\n\u001b[1;32m    106\u001b[0m detections \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39mpostprocess(detections, images\u001b[38;5;241m.\u001b[39mimage_sizes, original_image_sizes)  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/rpn.py:371\u001b[0m, in \u001b[0;36mRegionProposalNetwork.forward\u001b[0;34m(self, images, features, targets)\u001b[0m\n\u001b[1;32m    367\u001b[0m objectness, pred_bbox_deltas \u001b[38;5;241m=\u001b[39m concat_box_prediction_layers(objectness, pred_bbox_deltas)\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# apply pred_bbox_deltas to anchors to obtain the decoded proposals\u001b[39;00m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# note that we detach the deltas because Faster R-CNN do not backprop through\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# the proposals\u001b[39;00m\n\u001b[0;32m--> 371\u001b[0m proposals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbox_coder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_bbox_deltas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43manchors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m proposals \u001b[38;5;241m=\u001b[39m proposals\u001b[38;5;241m.\u001b[39mview(num_images, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m    373\u001b[0m boxes, scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_proposals(proposals, objectness, images\u001b[38;5;241m.\u001b[39mimage_sizes, num_anchors_per_level)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/_utils.py:178\u001b[0m, in \u001b[0;36mBoxCoder.decode\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box_sum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    177\u001b[0m     rel_codes \u001b[38;5;241m=\u001b[39m rel_codes\u001b[38;5;241m.\u001b[39mreshape(box_sum, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 178\u001b[0m pred_boxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrel_codes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_boxes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m box_sum \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    180\u001b[0m     pred_boxes \u001b[38;5;241m=\u001b[39m pred_boxes\u001b[38;5;241m.\u001b[39mreshape(box_sum, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchvision/models/detection/_utils.py:216\u001b[0m, in \u001b[0;36mBoxCoder.decode_single\u001b[0;34m(self, rel_codes, boxes)\u001b[0m\n\u001b[1;32m    213\u001b[0m pred_h \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mexp(dh) \u001b[38;5;241m*\u001b[39m heights[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# Distance from center to box's corner.\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m c_to_c_h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_ctr_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpred_h\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m pred_h\n\u001b[1;32m    217\u001b[0m c_to_c_w \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m0.5\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mpred_ctr_x\u001b[38;5;241m.\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mpred_w\u001b[38;5;241m.\u001b[39mdevice) \u001b[38;5;241m*\u001b[39m pred_w\n\u001b[1;32m    219\u001b[0m pred_boxes1 \u001b[38;5;241m=\u001b[39m pred_ctr_x \u001b[38;5;241m-\u001b[39m c_to_c_w\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":116},{"cell_type":"code","source":"plot_metrics(losses, train_accs, val_accs, num_epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T03:50:35.840054Z","iopub.status.idle":"2024-12-11T03:50:35.840399Z","shell.execute_reply.started":"2024-12-11T03:50:35.840245Z","shell.execute_reply":"2024-12-11T03:50:35.840262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Chiamata alla funzione di test\npredictions = test_model(model=model, test_loader=test_loader, device=device)\n\n# Puoi fare qualcosa con le predizioni, come visualizzarle o calcolare metriche\nprint(f\"Numero di predizioni ottenute: {len(predictions)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T03:50:35.841929Z","iopub.status.idle":"2024-12-11T03:50:35.842389Z","shell.execute_reply.started":"2024-12-11T03:50:35.842165Z","shell.execute_reply":"2024-12-11T03:50:35.842188Z"}},"outputs":[],"execution_count":null}]}