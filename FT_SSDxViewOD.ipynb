{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"markdown","source":"### download di YOLOv5 dalla repository github","metadata":{}},{"cell_type":"code","source":"pip install -U ultralytics\npip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### import librerie","metadata":{}},{"cell_type":"code","source":"import os\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, txt_file, img_dir, utils, aug=False):\n        \"\"\"\n        Dataset personalizzato per SSD che carica immagini e region proposals.\n        \n        Args:\n            txt_file (str): File di testo con i percorsi delle immagini.\n            img_dir (str): Directory contenente le immagini.\n            utils: Funzioni di utilità caricate con torch.hub (nvidia_ssd_processing_utils).\n            transforms (callable, optional): Trasformazioni da applicare alle immagini.\n        \"\"\"\n        # Caricamento dei percorsi delle immagini\n        with open(txt_file, 'r') as f:\n            self.image_paths = [line.strip() for line in f.readlines()]\n        \n        self.img_dir = img_dir  # Directory delle immagini\n        self.utils = utils  # Utilità di preprocessing (prepare_input, prepare_tensor)\n        self.aug = aug  # Trasformazioni aggiuntive opzionali\n        self.transform = transforms.Compose([\n            transforms.Resize((320, 320)),\n            transforms.ToTensor(),\n        ]) # trasformazione di base da applicare a tutte le immagini\n        \n    def __len__(self):\n        \"\"\"\n        Restituisce il numero di immagini nel dataset.\n        \"\"\"\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        # Ottieni il percorso dell'immagine\n        img_name = os.path.basename(self.image_paths[index])\n        img_path = os.path.join(self.img_dir, img_name)\n        \n        if not os.path.exists(img_path):\n            raise FileNotFoundError(f\"Immagine non trovata: {img_path}\")\n        \n        # Carica l'immagine\n        image = Image.open(img_path).convert('RGB')\n        \n        # Preprocessa l'immagine usando utils.prepare_input\n        processed_image = self.utils.prepare_input([img_path])  # Restituisce lista di tensori\n        \n        # Converte in tensore\n        image_tensor = self.utils.prepare_tensor(processed_image)\n        \n        # Applica trasformazioni opzionali\n        if self.aug:\n            image_tensor = self.transform(image_tensor)\n        \n        # Restituisci il tensore dell'immagine\n        return {\n            \"image\": image_tensor,  # Tensore preprocessato per SSD\n            \"path\": img_path        # Percorso originale per riferimento\n        }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def collate_fn(batch):\n\n    # Estrai le immagini e i percorsi dal batch\n    images = [item[\"image\"] for item in batch]\n    paths = [item[\"path\"] for item in batch]\n    \n    # Combina i tensori delle immagini in un unico tensore\n    # (assumendo che tutte le immagini abbiano la stessa dimensione dopo il preprocessing)\n    images_tensor = torch.cat(images, dim=0)\n    \n    return {\n        \"images\": images_tensor,  # Batch di immagini come tensore\n        \"paths\": paths            # Percorsi originali delle immagini\n    }\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Creazione dei dataset\ntrain_dataset = CustomDataset(train_txt_pth, images_fldr_pth, utils, aug=True) \nvalid_dataset = CustomDataset(val_txt_pth, images_fldr_pth, utils, aug=False)  \ntest_dataset = CustomDataset(test_txt_pth, images_fldr_pth, utils, aug=False)  \n\n# Creazione dei DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"# PER IL MODELLO YOLO\nclass YoloModel(nn.Module):\n    def __init__(self, num_classes):\n        super(YoloModel, self).__init__()\n\n        ## Model -> per info https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD\n        self.yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes = 12,  autoshape = False, pretrained=True)\n\n    def forward(self, images):\n\n        # Calcola le previsioni con il modello SSD\n        predictions = self.yolo_model(images)  # Output grezzo del modello SSD\n        \n        return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SSDModel(nn.Module):\n    def __init__(self, num_classes):\n        super(SSDModel, self).__init__()\n\n        ## Model -> per info https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD\n        self.ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd') # modello pre-addestrato su dataset COCO\n        self.utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n\n    def forward(self, images):\n\n        # Calcola le previsioni con il modello SSD\n        predictions = self.ssd_model(images)  # Output grezzo del modello SSD\n        \n        return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, val_loader, criterion, optimizer=None, device='cuda'):\n        \"\"\"\n        Inizializza la classe Trainer.\n        \n        Args:\n            model: Il modello SSD.\n            train_loader: DataLoader per il training set.\n            val_loader: DataLoader per il validation set.\n            criterion: Funzione di perdita.\n            optimizer: Ottimizzatore (opzionale, di default Adam).\n            device: Dispositivo per il calcolo ('cuda' o 'cpu').\n        \"\"\"\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.criterion = criterion\n        self.optimizer = optimizer if optimizer else Adam(model.parameters(), lr=1e-4)\n        self.device = device\n    \n    def train_one_epoch(self, epoch):\n        \"\"\"\n        Esegue un'epoca di addestramento.\n        \"\"\"\n        self.model.train()\n        running_loss = 0.0\n        pbar = tqdm(self.train_loader, desc=f\"Training Epoch {epoch}\")\n        \n        for images, targets in pbar:\n            images, targets = images.to(self.device), targets.to(self.device)\n            \n            # Forward pass\n            predictions = self.model(images)\n            \n            # Calcolo della perdita\n            loss = self.criterion(predictions, targets)\n            \n            # Backward pass e ottimizzazione\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            running_loss += loss.item()\n            pbar.set_postfix({\"loss\": running_loss / len(self.train_loader)})\n        \n        return running_loss / len(self.train_loader)\n    \n    def validate_one_epoch(self, epoch):\n        \"\"\"\n        Esegue un'epoca di validazione.\n        \"\"\"\n        self.model.eval()\n        running_loss = 0.0\n        pbar = tqdm(self.val_loader, desc=f\"Validation Epoch {epoch}\")\n        \n        with torch.no_grad():\n            for images, targets in pbar:\n                images, targets = images.to(self.device), targets.to(self.device)\n                \n                # Forward pass\n                predictions = self.model(images)\n                \n                # Calcolo della perdita\n                loss = self.criterion(predictions, targets)\n                running_loss += loss.item()\n                \n                pbar.set_postfix({\"val_loss\": running_loss / len(self.val_loader)})\n        \n        return running_loss / len(self.val_loader)\n    \n    def fit(self, epochs):\n        \"\"\"\n        Esegue l'addestramento e la validazione per un dato numero di epoche.\n        \"\"\"\n        train_losses = []\n        val_losses = []\n        \n        for epoch in range(1, epochs + 1):\n            train_loss = self.train_one_epoch(epoch)\n            val_loss = self.validate_one_epoch(epoch)\n            \n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n            \n            print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n        \n        return train_losses, val_losses","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ssd_model.to('cuda')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Inizializza il tuo modello\nnum_classes = 12  \nssd = SSDModel(num_classes)\n\n# Addestra il modello, con validazione ad ogni epoca\nssd.train(train_loader, val_loader, num_epochs=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}