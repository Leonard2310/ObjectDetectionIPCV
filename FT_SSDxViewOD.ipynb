{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10118002,"sourceType":"datasetVersion","datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"markdown","source":"### import librerie","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\n\nimport json\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n\nimport ast","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install triton","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"# file contenente i path delle immagini del dataset\ntxt_file = \"/kaggle/input/our-xview-dataset/xView_class_map.json\"\nimg_dir = \"/kaggle/input/our-xview-dataset/images\"\n\nannotation_file = \"/kaggle/input/our-xview-dataset/COCO_annotations_new.json\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils', trust_repo=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport numpy as np\n\ndef visualize_dataset_element(dataset, idx):\n    # Estrai l'elemento dal dataset\n    image_tensor, boxes_tensor, labels_tensor = dataset[idx]\n    \n    # Converti il tensore dell'immagine in un formato che matplotlib può visualizzare\n    # Il tensore è in formato (C, H, W), quindi dobbiamo convertirlo in (H, W, C)\n    image = image_tensor.permute(1, 2, 0).numpy()\n    \n    # Rescale l'immagine (perché il modello SSD può usare valori normalizzati tra [0, 1])\n    image = np.clip(image, 0, 1)\n\n    # Crea una figura per visualizzare l'immagine\n    fig, ax = plt.subplots(1, figsize=(12, 9))\n    ax.imshow(image)\n\n    # Estrai i bounding box e le etichette\n    boxes = boxes_tensor.numpy()\n    labels = labels_tensor.numpy()\n\n    # Visualizza i bounding box\n    for box, label in zip(boxes, labels):\n        # I bounding box sono [xmin, ymin, xmax, ymax]\n        xmin, ymin, xmax, ymax = box\n        width = xmax - xmin\n        height = ymax - ymin\n        \n        # Aggiungi un rettangolo per ogni bounding box\n        rect = patches.Rectangle((xmin, ymin), width, height, linewidth=2, edgecolor='r', facecolor='none')\n        ax.add_patch(rect)\n\n        # Aggiungi l'etichetta del bounding box\n        ax.text(xmin, ymin, f'Class {int(label)}', color='yellow', fontsize=12, bbox=dict(facecolor='red', alpha=0.5))\n    \n    # Mostra l'immagine con i bounding box\n    plt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define transformations\nfrom torchvision.transforms import Compose, ToTensor\n\n# Dataset and Dataloader\ntrain_dataset = SSDDataset(image_dir, annotations_file, transform=ToTensor())\n#val_dataset = CustomDataset(annotation_file, img_dir, transforms=train_transforms)\n\ntrain_loader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=utils.collate_fn)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n\ndef visualize_dataset_element(dataset, idx):\n    \"\"\"\n    Visualizza un elemento specifico del dataset (immagine, bounding box e label).\n    \n    Args:\n        dataset: Istanza del dataset.\n        idx (int): Indice dell'elemento da visualizzare.\n    \"\"\"\n    # Estrai un elemento dal dataset\n    element = dataset[idx]\n    image = element['image']\n    boxes = element['boxes']\n    labels = element['labels']\n\n    print(f\"boxes : {boxes}\")\n    print(f\"labels : {labels}\")\n    \n    # Converti l'immagine per la visualizzazione\n    image = image.permute(1, 2, 0).numpy()  # Da [C, H, W] a [H, W, C]\n    image = (image * 0.229 + 0.485).clip(0, 1)  # De-normalizzazione (assume mean/std standard)\n\n    # Visualizza l'immagine\n    fig, ax = plt.subplots(1, figsize=(12, 8))\n    ax.imshow(image)\n\n    # Aggiungi i bounding box\n    for bbox, label in zip(boxes, labels):\n        x_min, y_min, x_max, y_max = bbox.numpy()\n        rect = patches.Rectangle(\n            (x_min, y_min), x_max - x_min, y_max - y_min,\n            linewidth=2, edgecolor='red', facecolor='none'\n        )\n        ax.add_patch(rect)\n        ax.text(\n            x_min, y_min - 5, f\"Label: {label.item()}\",\n            color='white', fontsize=12, bbox=dict(facecolor='red', alpha=0.5)\n        )\n\n    plt.axis('off')\n    plt.show()\n\n# Esempio di utilizzo\nvisualize_dataset_element(dataset, idx=5)  # Visualizza l'elemento con indice 5 del dataset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class SSDModel(nn.Module):\n    def __init__(self, num_classes):\n        super(SSDModel, self).__init__()\n\n        self.num_classes = num_classes\n        ## Model -> per info https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD\n        self.model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd') # modello pre-addestrato su dataset COCO\n\n        # FAI L'ANALISI DOPO\n        # Modify the last layers (loc and conf) to handle 'num_classes'\n        for i in range(len(self.model.loc)):\n            in_channels = self.model.loc[i].in_channels\n            # Modify the location (bbox regression) layer\n            self.model.loc[i] = nn.Conv2d(in_channels, 4, kernel_size=3, padding=1)\n        \n        for i in range(len(self.model.conf)):\n            in_channels = self.model.conf[i].in_channels\n            # Modify the classification layer to output 'num_classes + 1' (for background class)\n            self.model.conf[i] = nn.Conv2d(in_channels, self.num_classes, kernel_size=3, padding=1)\n\n\n    def forward(self, images):\n\n        # Calcola le previsioni con il modello SSD\n        predictions = self.ssd_model(images)  # Output grezzo del modello SSD\n        \n        return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initialize model and trainer\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = SSDModel(num_classes=12).to(device)\n\nprint(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"import torch\nimport time\n\nclass Trainer:\n    def __init__(self, model, dataloader, optimizer, loss_fn, device, num_epochs=10, save_path=None):\n        self.model = model\n        self.dataloader = dataloader\n        self.optimizer = optimizer\n        self.loss_fn = loss_fn\n        self.device = device\n        self.num_epochs = num_epochs\n        self.save_path = save_path\n\n    def train_one_epoch(self):\n        self.model.train()\n        running_loss = 0.0\n\n        for images, boxes, labels in self.dataloader:\n            # Assicurati che i dati siano sulla stessa device (CPU o GPU)\n            images = images.to(self.device)\n            boxes = boxes.to(self.device)\n            labels = labels.to(self.device)\n\n            # Inizializza il gradiente\n            self.optimizer.zero_grad()\n\n            # Fai una previsione\n            outputs = self.model(images)\n\n            # Calcola la perdita\n            loss = self.loss_fn(outputs, boxes, labels)\n            running_loss += loss.item()\n\n            # Backpropagation e aggiornamento dei pesi\n            loss.backward()\n            self.optimizer.step()\n\n        # Calcola la perdita media per l'epoca\n        avg_loss = running_loss / len(self.dataloader)\n        return avg_loss\n\n    def train(self):\n        for epoch in range(self.num_epochs):\n            start_time = time.time()\n            avg_loss = self.train_one_epoch()\n\n            elapsed_time = time.time() - start_time\n            print(f\"Epoch {epoch + 1}/{self.num_epochs}, Loss: {avg_loss:.4f}, Time: {elapsed_time:.2f} seconds\")\n\n            # Salvataggio del modello (opzionale)\n            if self.save_path:\n                torch.save(self.model.state_dict(), self.save_path)\n\n    def evaluate(self, dataloader):\n        self.model.eval()\n        running_loss = 0.0\n        with torch.no_grad():\n            for images, boxes, labels in dataloader:\n                # Assicurati che i dati siano sulla stessa device (CPU o GPU)\n                images = images.to(self.device)\n                boxes = boxes.to(self.device)\n                labels = labels.to(self.device)\n\n                # Fai una previsione\n                outputs = self.model(images)\n\n                # Calcola la perdita\n                loss = self.loss_fn(outputs, boxes, labels)\n                running_loss += loss.item()\n\n        # Calcola la perdita media\n        avg_loss = running_loss / len(dataloader)\n        return avg_loss\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Crea l'ottimizzatore (ad esempio, Adam)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n\n# Crea la funzione di perdita\n# Supponiamo che `compute_loss` sia una funzione del modello che restituisce la perdita\ndef loss_fn(outputs, boxes, labels):\n    return model.compute_loss(outputs, boxes, labels)\n\n# Crea il dataloader (supponiamo di avere già il dataset)\ndataloader = DataLoader(dataset, batch_size=4, shuffle=True, collate_fn=utils.collate_fn)\n\n# Inizializza il trainer\ntrainer = Trainer(model, dataloader, optimizer, loss_fn, device, num_epochs=10, save_path=\"ssd_model.pth\")\n\n# Avvia l'addestramento\ntrainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}