{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"markdown","source":"### download di YOLOv5 dalla repository github","metadata":{}},{"cell_type":"code","source":"pip install -U ultralytics\npip install -r https://raw.githubusercontent.com/ultralytics/yolov5/master/requirements.txt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### import librerie","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom tqdm import tqdm","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"# la rete richiede che vengano date in input immagini in forma tensoriale -> per adattare le immagini vengono fornite delle funzioni apposite\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, txt_file, img_dir, utils):\n\n        with open(txt_file, 'r') as f: #salva le region proposals in un file txt con direttamente le info della cartella\n            self.image_paths = [line.strip() for line in f.readlines()] #memorizzo i path delle immagini in una lista\n            \n        self.inputs = [utils.prepare_input(image) for image in self.image_paths] # images = lista di path relativi alle immagini per il training\n        self.tensor = utils.prepare_tensor(inputs)\n\n    def __len__(self): # ritorna il numero di elementi in self.image_paths -> chi è?\n        return len(self.image_paths)\n\n    def __getitem__(self, index): # FINIRE DI COMPLETARE\n        img_name = os.path.basename(self.image_paths[index]) #prendo il path dell'immagine da self.image_paths in base all'indice fornito\n        img_id = int(img_name.replace('_', '').replace('.jpg', '').replace('img', '')) #ricavo l'id dell'immagine -> non l'ho già fatto nell'init?\n        \n        if img_id not in self.image_info: #vedo dal dizionario self.image_info se l'immagine è contenuta nel file COCO \n            raise ValueError(f\"Immagine {img_name} non trovata nel file COCO\")\n    \n        img_path = os.path.join(self.img_dir, img_name) #prendo il path completo dell'immagine unendo il path della cartella con il nome.jpg dell'immagine\n        if not os.path.exists(img_path): #se il path non esiste allora lo segnalo\n            raise ValueError(f\"Immagine non trovata nel percorso: {img_path}\")\n        \n        image = Image.open(img_path).convert('RGB') #apro l'immagine e ne ricavo le dimensioni\n        #original_width, original_height = image.size\n        \n        if self.aug: #se la variabile self.aug è alta allora applico la self.aug_transform altrimenti la self.base_transform _> HA SENSO? LE DUE FUNZIONI SONO = !!\n            image_tensor = self.aug_transform(image)\n        else:\n            image_tensor = self.base_transform(image)\n        \n        #POTREBBE ESSERCI UN PROBLEMA NELLA CORRISPONDENZA TRA LABLES E REGION PROPOSALS -> perchè in proposals_tensor non ci sono tutte le region proposals perchè alcune vengono scartate\n        # -> se la corrispondenza è 1 a 1 allora potrebbe convenire dare a _generate_region_proposals(image) sia le labes che l'immagine? -> non è certo perchè \n        # in lables c'è una lista di lable ma non viene specificato dove sono localizzate\n        \n        # restituisce un dizionario\n        return {\n            \"regions\": processed_proposals  # region proposals elaborate, una lista di tensori che rappresentano regioni candidate per il rilevamento\n        } ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"# PER IL MODELLO YOLO\nclass YoloModel(nn.Module):\n    def __init__(self, num_classes):\n        super(YoloModel, self).__init__()\n\n        ## Model -> per info https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD\n        self.yolo_model = torch.hub.load('ultralytics/yolov5', 'yolov5s', classes = 12,  autoshape = False, pretrained=True)\n\n    def forward(self, images):\n\n        # Calcola le previsioni con il modello SSD\n        predictions = self.yolo_model(images)  # Output grezzo del modello SSD\n        \n        return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class SSDModel(nn.Module):\n    def __init__(self, num_classes):\n        super(SSDModel, self).__init__()\n\n        ## Model -> per info https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD\n        self.ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd') # modello pre-addestrato su dataset COCO\n        self.utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils')\n\n    def forward(self, images):\n\n        # Calcola le previsioni con il modello SSD\n        predictions = self.ssd_model(images)  # Output grezzo del modello SSD\n        \n        return predictions","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, val_loader, criterion, optimizer=None, device='cuda'):\n        \"\"\"\n        Inizializza la classe Trainer.\n        \n        Args:\n            model: Il modello SSD.\n            train_loader: DataLoader per il training set.\n            val_loader: DataLoader per il validation set.\n            criterion: Funzione di perdita.\n            optimizer: Ottimizzatore (opzionale, di default Adam).\n            device: Dispositivo per il calcolo ('cuda' o 'cpu').\n        \"\"\"\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.criterion = criterion\n        self.optimizer = optimizer if optimizer else Adam(model.parameters(), lr=1e-4)\n        self.device = device\n    \n    def train_one_epoch(self, epoch):\n        \"\"\"\n        Esegue un'epoca di addestramento.\n        \"\"\"\n        self.model.train()\n        running_loss = 0.0\n        pbar = tqdm(self.train_loader, desc=f\"Training Epoch {epoch}\")\n        \n        for images, targets in pbar:\n            images, targets = images.to(self.device), targets.to(self.device)\n            \n            # Forward pass\n            predictions = self.model(images)\n            \n            # Calcolo della perdita\n            loss = self.criterion(predictions, targets)\n            \n            # Backward pass e ottimizzazione\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            running_loss += loss.item()\n            pbar.set_postfix({\"loss\": running_loss / len(self.train_loader)})\n        \n        return running_loss / len(self.train_loader)\n    \n    def validate_one_epoch(self, epoch):\n        \"\"\"\n        Esegue un'epoca di validazione.\n        \"\"\"\n        self.model.eval()\n        running_loss = 0.0\n        pbar = tqdm(self.val_loader, desc=f\"Validation Epoch {epoch}\")\n        \n        with torch.no_grad():\n            for images, targets in pbar:\n                images, targets = images.to(self.device), targets.to(self.device)\n                \n                # Forward pass\n                predictions = self.model(images)\n                \n                # Calcolo della perdita\n                loss = self.criterion(predictions, targets)\n                running_loss += loss.item()\n                \n                pbar.set_postfix({\"val_loss\": running_loss / len(self.val_loader)})\n        \n        return running_loss / len(self.val_loader)\n    \n    def fit(self, epochs):\n        \"\"\"\n        Esegue l'addestramento e la validazione per un dato numero di epoche.\n        \"\"\"\n        train_losses = []\n        val_losses = []\n        \n        for epoch in range(1, epochs + 1):\n            train_loss = self.train_one_epoch(epoch)\n            val_loss = self.validate_one_epoch(epoch)\n            \n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n            \n            print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n        \n        return train_losses, val_losses","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ssd_model.to('cuda')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}