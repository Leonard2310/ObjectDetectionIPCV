{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10118002,"sourceType":"datasetVersion","datasetId":6242793}],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Library import","metadata":{}},{"cell_type":"markdown","source":"### import librerie","metadata":{}},{"cell_type":"code","source":"import os\nimport numpy as np\n\nimport json\nfrom PIL import Image\nfrom torch.utils.data import Dataset\n\nimport torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torch.optim import Adam\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:44:50.926260Z","iopub.execute_input":"2024-12-08T19:44:50.926958Z","iopub.status.idle":"2024-12-08T19:44:54.303319Z","shell.execute_reply.started":"2024-12-08T19:44:50.926927Z","shell.execute_reply":"2024-12-08T19:44:54.302551Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install triton","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:44:54.304745Z","iopub.execute_input":"2024-12-08T19:44:54.305098Z","iopub.status.idle":"2024-12-08T19:45:09.735558Z","shell.execute_reply.started":"2024-12-08T19:44:54.305066Z","shell.execute_reply":"2024-12-08T19:45:09.734470Z"}},"outputs":[{"name":"stdout","text":"Collecting triton\n  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton) (3.15.1)\nDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton\nSuccessfully installed triton-3.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## Path","metadata":{}},{"cell_type":"code","source":"# file contenente i path delle immagini del dataset\ntxt_file = \"/kaggle/input/our-xview-dataset/xView_class_map.json\"\nimg_dir = \"/kaggle/input/our-xview-dataset/images\"\n\nannotation_file = \"/kaggle/input/our-xview-dataset/COCO_annotations_new.json\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:09.736895Z","iopub.execute_input":"2024-12-08T19:45:09.737208Z","iopub.status.idle":"2024-12-08T19:45:09.741295Z","shell.execute_reply.started":"2024-12-08T19:45:09.737179Z","shell.execute_reply":"2024-12-08T19:45:09.740399Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd_processing_utils', trust_repo=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:09.742365Z","iopub.execute_input":"2024-12-08T19:45:09.742724Z","iopub.status.idle":"2024-12-08T19:45:18.646311Z","shell.execute_reply.started":"2024-12-08T19:45:09.742679Z","shell.execute_reply":"2024-12-08T19:45:18.645637Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:13: UserWarning: pytorch_quantization module not found, quantization will not be available\n  warnings.warn(\n/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:17: UserWarning: pytorch_quantization module not found, quantization will not be available\n  warnings.warn(\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Dataloader","metadata":{}},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, annotations_file, img_dir, utils, aug=False):\n        \"\"\"\n        Args:\n            annotations_file (str): Path al file JSON delle annotazioni (es. formato COCO).\n            img_dir (str): Path alla directory delle immagini.\n            transform (callable, optional): Trasformazioni da applicare alle immagini.\n        \"\"\"\n\n        with open(annotations_file, 'r') as f:\n            self.annotations = json.load(f)\n        self.img_dir = img_dir\n        self.utils = utils\n        self.aug = aug\n\n    def __len__(self):\n        return len(self.annotations['images'])\n\n    def __getitem__(self, idx):\n        # Leggi i dettagli dell'immagine\n        img_info = self.annotations['images'][idx]\n        img_path = f\"{self.img_dir}/{img_info['file_name']}\"\n        image = Image.open(img_path).convert(\"RGB\")\n        \n        # Leggi le annotazioni\n        img_id = img_info['id']\n        annotations = [ann for ann in self.annotations['annotations'] if ann['image_id'] == img_id]\n        bboxes = np.array([ann['bbox'] for ann in annotations], dtype=np.float32)\n        labels = np.array([ann['category_id'] for ann in annotations], dtype=np.int64)\n        \n        # Converti bboxes nel formato richiesto (x_min, y_min, x_max, y_max)\n        bboxes[:, 2:] += bboxes[:, :2]  # width, height -> x_max, y_max\n        \n        target = {\n            'boxes': torch.tensor(bboxes, dtype=torch.float32),\n            'labels': torch.tensor(labels, dtype=torch.int64),\n        }\n        \n        #if self.aug:\n            #image = self.transform(image)\n        \n        return image, target\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:18.648352Z","iopub.execute_input":"2024-12-08T19:45:18.648718Z","iopub.status.idle":"2024-12-08T19:45:18.656165Z","shell.execute_reply.started":"2024-12-08T19:45:18.648691Z","shell.execute_reply":"2024-12-08T19:45:18.655340Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def collate_fn(batch):\n\n    # Estrai le immagini e i percorsi dal batch\n    images = [item[\"image\"] for item in batch]\n    paths = [item[\"path\"] for item in batch]\n    \n    # Combina i tensori delle immagini in un unico tensore\n    # (assumendo che tutte le immagini abbiano la stessa dimensione dopo il preprocessing)\n    images_tensor = torch.cat(images, dim=0)\n    \n    return {\n        \"images\": images_tensor,  # Batch di immagini come tensore\n        \"paths\": paths            # Percorsi originali delle immagini\n    }\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:18.657177Z","iopub.execute_input":"2024-12-08T19:45:18.657434Z","iopub.status.idle":"2024-12-08T19:45:18.694330Z","shell.execute_reply.started":"2024-12-08T19:45:18.657410Z","shell.execute_reply":"2024-12-08T19:45:18.693562Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Creazione dei dataset\ntrain_dataset = CustomDataset(annotation_file, img_dir, utils, aug=True) \nvalid_dataset = CustomDataset(annotation_file, img_dir, utils, aug=False)  \ntest_dataset = CustomDataset(annotation_file, img_dir, utils, aug=False)  \n\n# Creazione dei DataLoader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\nval_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:18.695196Z","iopub.execute_input":"2024-12-08T19:45:18.695434Z","iopub.status.idle":"2024-12-08T19:45:24.082858Z","shell.execute_reply.started":"2024-12-08T19:45:18.695411Z","shell.execute_reply":"2024-12-08T19:45:24.081913Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Network","metadata":{}},{"cell_type":"code","source":"class SSDModel(nn.Module):\n    def __init__(self, num_classes):\n        super(SSDModel, self).__init__()\n\n        ## Model -> per info https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Detection/SSD\n        self.ssd_model = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_ssd') # modello pre-addestrato su dataset COCO\n\n    def forward(self, images):\n\n        # Calcola le previsioni con il modello SSD\n        predictions = self.ssd_model(images)  # Output grezzo del modello SSD\n        \n        return predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:24.083961Z","iopub.execute_input":"2024-12-08T19:45:24.084237Z","iopub.status.idle":"2024-12-08T19:45:24.089080Z","shell.execute_reply.started":"2024-12-08T19:45:24.084212Z","shell.execute_reply":"2024-12-08T19:45:24.088204Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, val_loader, criterion, optimizer=None, device='cuda'):\n        \"\"\"\n        Inizializza la classe Trainer.\n        \n        Args:\n            model: Il modello SSD.\n            train_loader: DataLoader per il training set.\n            val_loader: DataLoader per il validation set.\n            criterion: Funzione di perdita.\n            optimizer: Ottimizzatore (opzionale, di default Adam).\n            device: Dispositivo per il calcolo ('cuda' o 'cpu').\n        \"\"\"\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        self.criterion = criterion\n        self.optimizer = optimizer if optimizer else Adam(model.parameters(), lr=1e-4)\n        self.device = device\n\n    def train_one_epoch(self, epoch):\n        \"\"\"\n        Esegue un'epoca di addestramento.\n        \"\"\"\n        self.model.train()\n        running_loss = 0.0\n        pbar = tqdm(self.train_loader, desc=f\"Training Epoch {epoch}\")\n        \n        for images, targets in pbar:\n            images, targets = images.to(self.device), targets.to(self.device)\n            \n            # Forward pass\n            predictions = self.model(images)\n            \n            # Calcolo della perdita\n            loss = self.criterion(predictions, targets)\n            \n            # Backward pass e ottimizzazione\n            self.optimizer.zero_grad()\n            loss.backward()\n            self.optimizer.step()\n            \n            running_loss += loss.item()\n            pbar.set_postfix({\"loss\": running_loss / len(self.train_loader)})\n        \n        return running_loss / len(self.train_loader)\n    \n    def validate_one_epoch(self, epoch):\n        \"\"\"\n        Esegue un'epoca di validazione.\n        \"\"\"\n        self.model.eval()\n        running_loss = 0.0\n        pbar = tqdm(self.val_loader, desc=f\"Validation Epoch {epoch}\")\n        \n        with torch.no_grad():\n            for images, targets in pbar:\n                images, targets = images.to(self.device), targets.to(self.device)\n                \n                # Forward pass\n                predictions = self.model(images)\n                \n                # Calcolo della perdita\n                loss = self.criterion(predictions, targets)\n                running_loss += loss.item()\n                \n                pbar.set_postfix({\"val_loss\": running_loss / len(self.val_loader)})\n        \n        return running_loss / len(self.val_loader)\n    \n    def fit(self, epochs):\n        \"\"\"\n        Esegue l'addestramento e la validazione per un dato numero di epoche.\n        \"\"\"\n        train_losses = []\n        val_losses = []\n        \n        for epoch in range(1, epochs + 1):\n            train_loss = self.train_one_epoch(epoch)\n            val_loss = self.validate_one_epoch(epoch)\n            \n            train_losses.append(train_loss)\n            val_losses.append(val_loss)\n            \n            print(f\"Epoch {epoch}: Train Loss = {train_loss:.4f}, Val Loss = {val_loss:.4f}\")\n        \n        return train_losses, val_losses\n\n# vedere se è necessario inserire dei checkpoint durante il train","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:24.090067Z","iopub.execute_input":"2024-12-08T19:45:24.090317Z","iopub.status.idle":"2024-12-08T19:45:24.434282Z","shell.execute_reply.started":"2024-12-08T19:45:24.090295Z","shell.execute_reply":"2024-12-08T19:45:24.433569Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"num_classes = 12\nssd_model = SSDModel(num_classes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:45:24.435224Z","iopub.execute_input":"2024-12-08T19:45:24.435469Z","iopub.status.idle":"2024-12-08T19:45:35.102821Z","shell.execute_reply.started":"2024-12-08T19:45:24.435446Z","shell.execute_reply":"2024-12-08T19:45:35.102096Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\nDownloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 172MB/s] \nDownloading checkpoint from https://api.ngc.nvidia.com/v2/models/nvidia/ssd_pyt_ckpt_amp/versions/20.06.0/files/nvidia_ssdpyt_amp_200703.pt\n/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Detection/SSD/ssd/entrypoints.py:201: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  ckpt = torch.load(ckpt_file)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Addestra il modello, con validazione ad ogni epoca\nloss = \nssd_model.train(train_loader, val_loader, loss, optimizer= \"Adam\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-08T19:47:36.498717Z","iopub.execute_input":"2024-12-08T19:47:36.499432Z","iopub.status.idle":"2024-12-08T19:47:36.521160Z","shell.execute_reply.started":"2024-12-08T19:47:36.499396Z","shell.execute_reply":"2024-12-08T19:47:36.519972Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Addestra il modello, con validazione ad ogni epoca\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m ssd_model\u001b[38;5;241m.\u001b[39mtrain(train_loader, val_loader, \u001b[43mcriterion\u001b[49m, optimizer\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdam\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'criterion' is not defined"],"ename":"NameError","evalue":"name 'criterion' is not defined","output_type":"error"}],"execution_count":14},{"cell_type":"markdown","source":"# Testing","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}